WEBVTT

00:16.750 --> 00:18.285
[phone dialing]

00:18.318 --> 00:20.687
[line ringing]

00:20.721 --> 00:23.490
- Levy 911, what is the
address of your emergency?

00:23.524 --> 00:25.025
- There was just a wreck.

00:25.058 --> 00:26.260
A head-on collision
right here--

00:26.293 --> 00:27.628
Oh, my God Almighty.

00:27.661 --> 00:30.697
[phones dialing]

00:30.731 --> 00:32.399
- Hello?

00:32.432 --> 00:34.701
- They just had a bad accident
in front of the BP station.

00:34.735 --> 00:36.403
- I don't know how bad it is,
but it sounded nasty.

00:36.436 --> 00:39.173
- Okay, we've got--we've got
multiple 911 calls, sir.

00:39.206 --> 00:40.741
[phones dialing]

00:40.774 --> 00:43.076
- Yes, ma'am, a little car,
a little sportscar.

00:43.110 --> 00:45.112
- A little black car
and a semi car

00:45.145 --> 00:46.313
went under a semi-truck.

00:46.346 --> 00:47.414
- Come on underneath
the truck.

00:47.447 --> 00:49.082
- Took the top of the car off.

00:49.116 --> 00:50.584
- Okay, are the vehicles
in the road?

00:50.617 --> 00:52.553
- No, vehicle--he went way
off the road.

00:52.586 --> 00:54.755
- Went off into the ditch
and went to the woods.

00:54.788 --> 00:56.623
- Ran off
probably a quarter mile

00:56.657 --> 00:57.791
from where the wreck happened.

00:57.824 --> 00:59.326
- I watched it happen.

00:59.359 --> 01:02.396
- Okay, sir, is there
any obvious injuries?

01:02.429 --> 01:04.765
- I mean, he's dead as hell.

01:04.798 --> 01:06.600
- He--he's dead?

01:06.633 --> 01:09.002
- Yeah, it's kind of obvious.

01:09.036 --> 01:11.572
- A fatal crash
involving a Tesla.

01:11.605 --> 01:12.739
- Tesla.
- Tesla.

01:12.773 --> 01:14.441
- Related to
the Autopilot mode.

01:14.474 --> 01:16.243
- Autopilot mode.
- We've heard warnings

01:16.276 --> 01:17.778
about the dangers
of this technology.

01:17.811 --> 01:19.246
- Tesla is under fire.

01:19.279 --> 01:21.181
- Critics have been
calling for changes

01:21.215 --> 01:22.683
to Tesla's Autopilot software.

01:22.716 --> 01:26.353
- Tweets and retweets
from Tesla CEO Elon Musk,

01:26.386 --> 01:29.423
pointing out that other
auto companies are involved

01:29.456 --> 01:31.525
in far more fatal crashes.

01:31.558 --> 01:35.162
- How did a Tesla on Autopilot
slam into a tractor-trailer?

01:35.195 --> 01:37.464
Why didn't the built-in
safety system stop it?

01:37.497 --> 01:40.734
- Who's to blame:
the driver or the car?

01:48.475 --> 01:52.179
- It is my honor to welcome
to the stage Mr. Elon Musk.

01:52.212 --> 01:55.215
[cheers and applause]

01:59.253 --> 02:01.221
- Welcome, everyone,
to the Model 3 unveil.

02:01.255 --> 02:02.456
[audience shouting]

02:02.489 --> 02:05.726
- For years, Elon Musk
is talked about being

02:05.759 --> 02:09.229
on the verge
of self-driving car technology.

02:09.263 --> 02:11.565
- No hands. No feet. Nothing.

02:11.598 --> 02:15.169
- Elon Musk approaches
this a way a lot of people

02:15.202 --> 02:19.039
in Silicon Valley do: they are
often telling you things

02:19.072 --> 02:20.607
about how the future will be.

02:20.641 --> 02:23.177
- Getting in a car will be like
getting in an elevator.

02:23.210 --> 02:24.678
You just tell it
where you want to go,

02:24.711 --> 02:28.749
and it takes you there
with extreme levels of safety.

02:28.782 --> 02:30.284
And that'll be normal.

02:30.317 --> 02:31.552
[applause]

02:31.585 --> 02:33.420
- Musk is certainly
a visionary.

02:33.453 --> 02:36.423
- "Time" Magazine's Person
of the Year has been released:

02:36.456 --> 02:39.259
Elon Musk,
the Tesla and SpaceX CEO,

02:39.293 --> 02:41.295
for driving society's
most daring

02:41.328 --> 02:43.497
and disruptive
transformations.

02:43.530 --> 02:47.501
- Elon Musk wanted to disrupt
and revolutionize

02:47.534 --> 02:48.735
the auto industry.

02:48.769 --> 02:51.705
And Autopilot
was kind of a halo.

02:51.738 --> 02:54.741
It gave Tesla this image
of the way they like

02:54.775 --> 02:59.112
to be portrayed
as a technology company.

02:59.146 --> 03:01.114
- The difference is that
the stakes are higher

03:01.148 --> 03:02.516
for the technology.

03:02.549 --> 03:06.253
- Whoa. It nearly drove us
into the Subaru there.

03:06.286 --> 03:09.756
- We're talking about
physical cars on the road,

03:09.790 --> 03:11.592
and we're talking
about lives at stake.

03:11.625 --> 03:13.460
- Yet another driver
caught on camera

03:13.493 --> 03:15.195
apparently asleep
at the wheel.

03:15.229 --> 03:18.198
- But will it end the question
of how much control drivers

03:18.232 --> 03:21.268
should really hand over
to the computers in their car?

03:22.669 --> 03:26.106
- Tesla is under a lot more
scrutiny now

03:26.139 --> 03:27.274
than it has been before.

03:27.307 --> 03:29.610
And part of that
is in their marketing.

03:29.643 --> 03:31.278
- The rollout of the latest
version

03:31.311 --> 03:33.247
of its self-driving
technology.

03:33.280 --> 03:38.218
- Wow. Oh, my God! Okay. Okay.

03:38.252 --> 03:40.487
- There's this enormous
gray area

03:40.521 --> 03:42.289
Tesla's willing to explore.

03:42.322 --> 03:44.658
- Ahh!

03:44.691 --> 03:48.529
This is very
uncomfortable so far.

03:48.562 --> 03:51.131
- How much do you push the edge
of the envelope?

03:53.100 --> 03:56.303
- My car should get over here.

03:56.336 --> 03:59.406
Okay, that was--
that was great.

03:59.439 --> 04:00.741
That was really great.

04:00.774 --> 04:02.376
That was one of those times
where I was like,

04:02.409 --> 04:03.443
okay, it can do it.

04:03.477 --> 04:04.545
Like, I know it can do it.

04:04.578 --> 04:06.113
It just needs to do it
every time.

04:06.146 --> 04:11.318
♪ ♪

04:11.351 --> 04:13.787
This technology is eventually

04:13.820 --> 04:16.523
going to enable
the car to drive itself.

04:18.192 --> 04:20.260
And that's what I am testing.

04:20.294 --> 04:23.030
Navigate to the East Greenwich
Super Charger.

04:23.063 --> 04:24.765
What Tesla calls
Early Access Program--

04:24.798 --> 04:27.301
it's a group of owners
that test software,

04:27.334 --> 04:29.203
but it's not public.

04:30.370 --> 04:32.206
You can see
what the car sees here.

04:32.239 --> 04:34.274
It sees the pedestrians.

04:34.308 --> 04:36.577
It sees that
this is a pickup truck

04:36.610 --> 04:38.612
that has come up behind us.

04:42.149 --> 04:44.184
This is a scary street.

04:44.218 --> 04:46.119
See how narrow this is?

04:47.454 --> 04:52.593
See how hesitant it is, though,
while it's going by these cars?

04:52.626 --> 04:56.063
It--it's learning.
It's not there yet.

04:57.631 --> 05:00.567
You know, people believe
that it's gonna happen,

05:00.601 --> 05:02.369
or else you wouldn't
do it, right?

05:04.438 --> 05:06.640
I think that the average
is like 35,000,

05:06.673 --> 05:10.777
36,000 auto deaths a year
in just the United States.

05:10.811 --> 05:13.380
And I think
90-something percent

05:13.413 --> 05:16.016
of those are human error.

05:16.049 --> 05:18.719
I believe that autonomy
is necessary

05:18.752 --> 05:23.490
to end virtually all traffic
deaths in this country.

05:25.292 --> 05:28.428
I think that Elon Musk
is somebody that comes along,

05:28.462 --> 05:30.264
like, once in a generation.

05:30.297 --> 05:33.433
♪ ♪

05:33.467 --> 05:35.102
- Now, Elon Musk, I think,

05:35.135 --> 05:38.238
is a name known to everybody
who thinks about the future.

05:38.272 --> 05:40.607
- Musk's fascination
with technology

05:40.641 --> 05:43.610
dates to his childhood
in South Africa.

05:43.644 --> 05:45.546
- Where I grew up
was extremely violent.

05:45.579 --> 05:47.681
I got punched
in the face many times.

05:47.714 --> 05:50.117
I almost got beaten
to death once.

05:50.150 --> 05:51.385
And I think,
if you have not been punched

05:51.418 --> 05:53.353
in the face with a fist,

05:53.387 --> 05:55.155
you don't know what--you have
no idea what it's like.

05:55.189 --> 05:56.557
- He hated going to school,

05:56.590 --> 05:58.692
because the other kids
liked to follow him home,

05:58.725 --> 06:01.428
and they would throw soda cans
at his head.

06:01.461 --> 06:04.264
So he sought refuge
in computer games,

06:04.298 --> 06:06.033
which got him into coding.

06:06.066 --> 06:08.535
- When you were a kid,
you programmed a game?

06:08.569 --> 06:09.636
Blaster, it's called?

06:09.670 --> 06:11.205
- Yeah, it's a simple game.

06:11.238 --> 06:13.473
- By 17, you were on a plane
from South Africa.

06:13.507 --> 06:14.741
- Yeah. I kind of wanted to be

06:14.775 --> 06:17.010
where the cutting edge
of technology was.

06:18.212 --> 06:20.047
Part of the reason I got
interested in technology--

06:20.080 --> 06:22.115
maybe the reason--
was video games.

06:22.149 --> 06:23.717
I worked at a gaming startup,

06:23.750 --> 06:25.686
which weirdly was called
Rocket Science.

06:25.719 --> 06:26.720
Yeah.

06:26.753 --> 06:29.022
[laughter]

06:29.056 --> 06:30.424
Fate loves irony.

06:32.259 --> 06:36.496
- In summer of '94,
Elon came as a summer intern.

06:36.530 --> 06:38.031
He was kinda introverted,

06:38.065 --> 06:40.701
so he fit right into
the rest of the group.

06:40.734 --> 06:44.338
Very, very interested in world
building, in storytelling.

06:44.371 --> 06:47.074
We thought Elon was gonna be
an entrepreneur, clearly.

06:47.107 --> 06:48.475
- You had a bring stint
at Stanford.

06:48.509 --> 06:50.577
- That's right.
- A Ph. D. in Applied Physics?

06:50.611 --> 06:52.412
- Applied Physics,
Material Science.

06:52.446 --> 06:53.780
But then the Internet
came along,

06:53.814 --> 06:55.716
and it seemed like
I could either do a Ph. D.

06:55.749 --> 06:58.385
and watch the internet happen,
or I could participate

06:58.418 --> 07:01.121
and help build it
in some fashion.

07:01.154 --> 07:03.290
So, I started a company
with my brother

07:03.323 --> 07:05.025
and a friend of mine,
Greg Kouri,

07:05.058 --> 07:06.793
and created Zip2,
where the initial idea

07:06.827 --> 07:08.529
was to create software
that could help

07:08.562 --> 07:10.697
bring the media companies
online.

07:10.731 --> 07:12.533
- You know, it's hard
to remember a time

07:12.566 --> 07:15.536
without the ubiquity of, like,
Google Maps and other things,

07:15.569 --> 07:18.205
and the expectation that,
if you're gonna find anything,

07:18.238 --> 07:20.307
there is a digital path
to finding it.

07:20.340 --> 07:24.077
And none of that existed
in 1995.

07:25.212 --> 07:27.214
I think it was very
forward-thinking.

07:27.247 --> 07:29.783
That's what makes
a great entrepreneur.

07:29.816 --> 07:31.151
- Elon had a very
strong personality,

07:32.319 --> 07:34.621
so sometimes he would get
into arguments with people,

07:34.655 --> 07:37.724
and they would be
pretty intense.

07:37.758 --> 07:40.160
He's not the kind of guy
who went out for beers

07:40.194 --> 07:42.229
with people and saw movies
and things like that.

07:42.262 --> 07:43.730
He basically just worked.

07:43.764 --> 07:47.000
- I started off being the CEO.
But after we got VC funding,

07:47.034 --> 07:51.772
the venture capitalists wanted
to hire a professional CEO.

07:51.805 --> 07:53.407
- Elon was always asking me,

07:53.440 --> 07:55.309
like, what should
his title be?

07:55.342 --> 07:56.643
You know,
what should his role be?

07:56.677 --> 07:58.145
I think, more than anything,

07:58.178 --> 08:00.380
he wanted
to be the face of Zip2.

08:02.216 --> 08:04.117
- Wow. I can't believe
it's actually here.

08:04.151 --> 08:05.719
That's pretty wild, man.

08:05.752 --> 08:07.254
- Elon was clearly, like,

08:07.287 --> 08:09.990
one of the most driven people
I've ever known.

08:10.791 --> 08:14.394
- A year ago, Musk sold
his software company, Zip2.

08:14.428 --> 08:17.664
- He took the $22 million
he made from Zip2.

08:17.698 --> 08:19.266
He obviously
could have retired.

08:19.299 --> 08:22.669
But instead, he just worked
to start his next company,

08:22.703 --> 08:24.338
X.com, which became PayPal.

08:24.371 --> 08:29.510
- The company was sold to eBay
in '02 for $1.5 billion.

08:29.543 --> 08:32.579
- I think Elon wants to make
a dent in the world.

08:32.613 --> 08:35.115
We all have
a finite amount of time.

08:35.148 --> 08:38.352
If you can move the needle,
then why not?

08:38.385 --> 08:40.454
And the capital allowed him
to do things

08:40.487 --> 08:41.655
that were really important.

08:41.688 --> 08:44.124
- After PayPal,
I started debating

08:44.157 --> 08:48.595
between either solar,
electric car, or space.

08:48.629 --> 08:50.397
I thought, like,
nobody is gonna be

08:50.430 --> 08:53.100
crazy enough to do space,
so I better do space.

08:53.133 --> 08:58.338
So, we embarked on that journey
to create SpaceX in 2002.

08:58.372 --> 08:59.740
And in the beginning,
I wouldn't--actually

08:59.773 --> 09:01.241
wouldn't even
let my friends invest

09:01.275 --> 09:02.609
because I didn't want
to lose their money.

09:02.643 --> 09:05.779
- Stage 1.
- We have liftoff indication.

09:05.812 --> 09:07.648
- Before all the drama
of SpaceX,

09:07.681 --> 09:10.651
I think Tesla has
actually been probably 2/3

09:10.684 --> 09:14.321
of my total drama dose
of a time.

09:14.354 --> 09:19.426
♪ ♪

09:19.459 --> 09:22.796
- In 2003, my business partner
at the time, Martin Eberhard,

09:22.829 --> 09:26.433
and I were getting really
concerned about climate change.

09:26.466 --> 09:30.003
We knew that you could
make electric cars.

09:30.037 --> 09:32.172
So we started Tesla Motors.

09:33.707 --> 09:37.277
We began looking
at raising significant money.

09:38.745 --> 09:41.782
We visited Elon
at SpaceX's original office,

09:41.815 --> 09:43.317
and there was a couple
of things

09:43.350 --> 09:45.719
that were really different
about pitching to Elon.

09:45.752 --> 09:48.655
First, he understood
the mission immediately.

09:48.689 --> 09:52.059
- It's very important that we
accelerate the transition away

09:52.092 --> 09:54.795
from gasoline, you know,

09:54.828 --> 09:57.264
for environmental reasons,
for economic reasons,

09:57.297 --> 09:59.233
for national security reasons.

09:59.266 --> 10:01.568
- The other thing is some of
the feedback

10:01.602 --> 10:04.037
that we'd get from the regular
venture community

10:04.071 --> 10:08.609
was that the idea
is just kinda too crazy.

10:08.642 --> 10:11.345
When you're pitching someone
who's building a rocket ship

10:11.378 --> 10:14.114
directly on the other side
of the glass panel,

10:14.147 --> 10:16.283
you know, that you're
in the conference room,

10:16.316 --> 10:17.584
you kinda feel
he's not gonna say

10:17.618 --> 10:19.253
that your idea is too crazy.

10:21.054 --> 10:22.623
- I could have been the CEO
from day one,

10:22.656 --> 10:25.225
but the idea of being CEO
of two startups

10:25.259 --> 10:30.297
at the same time
was not appealing.

10:30.330 --> 10:32.466
- Elon was
Chairman of the Board,

10:32.499 --> 10:34.134
and he would check
in every month.

10:34.168 --> 10:36.303
♪ ♪

10:36.336 --> 10:38.038
One of Elon's things--
he said, you know,

10:38.071 --> 10:40.307
you only get to
introduce the car once.

10:40.340 --> 10:42.743
So you kinda wanna make it
as good as you can get it.

10:42.776 --> 10:45.012
And when we unveiled it,
we did it in Los Angeles.

10:45.612 --> 10:48.215
- We've got a zero-emission
sportscar

10:48.248 --> 10:50.384
that can go head-to-head
with a Ferrari

10:50.417 --> 10:51.418
and a Porsche and win.

10:52.319 --> 10:53.687
- The governor,
Arnold Schwarzenegger,

10:53.720 --> 10:55.422
at the time,
you know, shows up.

10:55.455 --> 10:59.193
And he's kinda big,
and the car's kinda small.

10:59.226 --> 11:00.460
And I was worried that,
you know,

11:00.494 --> 11:02.095
the Governor
might get stuck in the car,

11:02.129 --> 11:04.231
and that would be, like,
a, you know, PR nightmare.

11:04.264 --> 11:05.766
But he really liked it.
In fact, he ended up

11:05.799 --> 11:07.367
ordering one
a little bit later.

11:10.270 --> 11:12.472
But there were a lot
of unexpected challenges

11:12.506 --> 11:14.274
developing,
you know, the Roadster.

11:15.409 --> 11:17.744
And that's when Elon began
to get much more involved,

11:17.778 --> 11:20.647
because, you know,
we were in trouble.

11:20.681 --> 11:25.686
- 2008 was brutal.
Tesla almost went bankrupt.

11:25.719 --> 11:28.222
We closed our financing round

11:28.255 --> 11:30.524
6:00 p. m.,
Christmas Eve, 2008.

11:30.557 --> 11:33.460
It was the last hour of the
last day that it was possible.

11:33.493 --> 11:35.362
And I thought, okay,
I got to bite the bullet

11:35.395 --> 11:38.065
and run the company,

11:40.067 --> 11:41.468
'cause there's just
too much at stake.

11:41.502 --> 11:43.704
♪ ♪

11:43.737 --> 11:47.341
- From the time Elon became
CEO to now,

11:47.374 --> 11:49.209
I mean,
Tesla's changed the way

11:49.243 --> 11:51.111
people think about
electric vehicles.

11:51.144 --> 11:54.448
- "Consumer Reports" says
this is the best car

11:54.481 --> 11:58.018
they've tested in the history
of the magazine.

11:58.051 --> 12:01.622
- When Tesla went public,
that was incredibly important.

12:01.655 --> 12:04.358
He was able to push Tesla
to grow

12:04.391 --> 12:06.293
and become much bigger
much faster

12:06.326 --> 12:08.695
than I think most people
had thought possible.

12:08.729 --> 12:13.200
- Tesla, surpassing a
$1 trillion valuation today.

12:13.233 --> 12:16.003
- Elon Musk is now the
richest person on the planet.

12:16.036 --> 12:17.638
♪ ♪

12:17.671 --> 12:21.141
- His pace of innovation
is kind of unmatched.

12:21.175 --> 12:24.578
He can take more risks
than any human can now,

12:24.611 --> 12:27.381
simply because he has
the resources

12:27.414 --> 12:29.049
that allow him to do things

12:29.082 --> 12:32.719
that would be irresponsible
or insane for anybody else.

12:39.092 --> 12:42.062
[light music]

12:42.095 --> 12:47.634
♪ ♪

12:47.668 --> 12:49.369
- I love the acceleration.

12:49.403 --> 12:51.305
I love the fact
that it's electric.

12:51.338 --> 12:54.341
And I love the fact that
people are interested in Tesla

12:54.374 --> 12:56.143
as a brand
and interested in the car.

12:56.176 --> 12:58.045
I like talking about it.

12:58.078 --> 13:01.114
2012, 2013, when they first
released their Model S,

13:01.148 --> 13:02.649
I thought it was just
a very cool car.

13:02.683 --> 13:05.419
And at the time, you know,
it was pretty revolutionary.

13:05.452 --> 13:07.154
Like, I believed
in their mission.

13:07.187 --> 13:10.324
- Electric car can in fact
be the best car in the world.

13:10.357 --> 13:12.159
[cheers and applause]

13:12.192 --> 13:14.728
- I think I had Elon Musk
up on a pedestal.

13:14.761 --> 13:17.064
You know, he was kind of a hero
at the time.

13:17.097 --> 13:19.366
♪ ♪

13:19.399 --> 13:21.168
I would follow his tweets.

13:21.201 --> 13:23.437
Think I have a mug with his
face on it somewhere at home.

13:24.805 --> 13:27.708
- This was the first one
that I got.

13:27.741 --> 13:29.309
Somebody gave it to me.

13:29.343 --> 13:36.316
The Tesla community is,
I think, rare, for any brand.

13:36.350 --> 13:40.187
I think that any company
would kill

13:40.220 --> 13:46.260
to have that level of fandom
and devotion.

13:46.293 --> 13:47.561
- People that are
the diehard fans,

13:47.594 --> 13:49.096
they have a bunch
of different names.

13:50.464 --> 13:52.299
Like the Musketeers.

13:52.332 --> 13:55.035
And they think whatever
Elon Musk says is,

13:55.068 --> 13:56.336
you know, gold, basically.

13:56.370 --> 13:58.305
- Elon Musk, how much
do I have to beg

13:58.338 --> 14:00.007
to get a selfie with you?

14:00.040 --> 14:02.476
- Sure, I'll do a selfie.

14:02.509 --> 14:04.378
Sure.
If your customers love you,

14:04.411 --> 14:08.182
your odds of success
are dramatically higher.

14:08.215 --> 14:10.651
♪ ♪

14:10.684 --> 14:14.121
- Josh was a real
Tesla enthusiast.

14:14.154 --> 14:17.558
He was very happy
with the decision he made

14:17.591 --> 14:19.459
in buying that car.

14:19.493 --> 14:21.461
That's the last picture of him.
- Yep.

14:21.495 --> 14:23.630
- Right after the vacation.

14:25.532 --> 14:27.067
Before the accident.

14:27.100 --> 14:30.070
[melancholy music]

14:30.103 --> 14:31.238
♪ ♪

14:31.271 --> 14:32.606
I was trying to think about

14:32.639 --> 14:34.575
how I first met Josh
the other day,

14:34.608 --> 14:37.277
the exact timing
that I met him.

14:38.779 --> 14:43.050
Mark Nelson and I were working
on a computer program

14:43.083 --> 14:44.718
for the NAVY EOD forces.

14:44.751 --> 14:47.588
EOD stands for explosive
ordinance disposal.

14:47.621 --> 14:51.124
Most people know it
by bomb disposal.

14:51.158 --> 14:55.662
- I was with a friend of mine
in San Diego, Ken Falke.

14:55.696 --> 15:00.033
And he introduced me
to this young sailor,

15:00.067 --> 15:01.502
Josh Brown.

15:01.535 --> 15:04.404
- From maintenance
to training plans

15:04.438 --> 15:06.173
to whatever it might have been,

15:06.206 --> 15:09.443
this entire detachment
was automated,

15:09.476 --> 15:12.012
thanks to Josh Brown.

15:12.045 --> 15:13.780
- What attracted him to it?

15:13.814 --> 15:16.149
I think it was the excitement.

15:16.183 --> 15:18.318
He liked to be doing things.

15:20.387 --> 15:24.558
- Man, this is actually
a fairly treacherous bottom.

15:24.591 --> 15:27.094
Just in case you doubt
this is me.

15:27.127 --> 15:28.562
Hello, there.

15:28.595 --> 15:32.332
I think that might even get
the motorcycle in there. Bye.

15:32.366 --> 15:34.001
- You get up in the morning
and you decide,

15:34.034 --> 15:36.470
"Well, today, I'm gonna go
for a three-mile run

15:36.503 --> 15:40.374
"and maybe a 1,000-yard swim,
just to kind of get warmed up.

15:40.407 --> 15:42.376
"And then maybe
I'll go diving today

15:42.409 --> 15:45.712
"or go parachuting or,
you know,

15:45.746 --> 15:48.015
go blow something up."

15:48.048 --> 15:49.416
- It's interesting, too.
Like, a lot of people

15:49.449 --> 15:51.251
kind of think, you know,
these people

15:51.285 --> 15:53.253
who go and stand on landmines

15:53.287 --> 15:56.590
and render them safe
have a death wish.

15:56.623 --> 15:59.159
It's just the opposite.
You know, they do it

15:59.193 --> 16:02.496
because they know
that somebody's gotta do it.

16:02.529 --> 16:06.433
- It's a profession
where people just don't have

16:06.466 --> 16:09.670
more than one chance
to make mistakes.

16:09.703 --> 16:11.705
- I used to call him
the professor sometimes,

16:11.738 --> 16:14.641
because, you know, he was just
so up on everything.

16:14.675 --> 16:17.611
Oh, geez.
Car's doing it all itself.

16:17.644 --> 16:20.547
What am I gonna do
with my hands down here?

16:20.581 --> 16:22.282
- His relationship
to technology

16:22.316 --> 16:24.384
was really symbiotic.

16:24.418 --> 16:26.753
I mean,
it was totally connected.

16:26.787 --> 16:29.122
And when he called and said,
"Hey, I got a surprise car

16:29.156 --> 16:30.390
I want to show you,"

16:30.424 --> 16:32.326
I wasn't surprised
when it was a Tesla.

16:32.359 --> 16:34.228
- It was a beautiful
looking car,

16:34.261 --> 16:37.331
and he loved it.

16:37.364 --> 16:39.199
He wanted to know

16:39.233 --> 16:42.035
how everything worked
in that Tesla.

16:42.069 --> 16:44.338
- All right, so this video
is gonna show some driving

16:44.371 --> 16:48.041
in some hills and turns,
so that you can see

16:48.075 --> 16:49.543
how it's gonna react
to different things.

16:49.576 --> 16:52.746
Overall, it actually does
a fantastically good job.

16:52.779 --> 16:54.281
- He and the car, you know,

16:54.314 --> 16:58.118
were a match made
in heaven, you know?

16:58.151 --> 16:59.720
He was perfectly suited

16:59.753 --> 17:03.357
for being on the bleeding
edge of technology.

17:03.390 --> 17:07.294
And, you know, he had done
a lot riskier things,

17:07.327 --> 17:10.097
you know, in his lifetime.

17:10.130 --> 17:12.099
- Well, I made it.

17:12.132 --> 17:14.001
That was--that was
quite sporting.

17:14.034 --> 17:15.402
[laughter]

17:19.406 --> 17:22.376
[tense music]

17:22.409 --> 17:28.115
♪ ♪

17:28.148 --> 17:30.384
- Elon was looking
for somebody to come in

17:30.417 --> 17:33.253
and help him
really leverage his time.

17:33.287 --> 17:35.422
I had had a career
as a serial entrepreneur,

17:35.455 --> 17:36.790
and I said to him
several times,

17:36.823 --> 17:38.225
like,
"I don't think I'm your guy.

17:38.258 --> 17:40.194
You need a big company
car guy."

17:40.227 --> 17:42.362
And he kept saying,
"No, I don't.

17:42.396 --> 17:44.031
I need a fellow entrepreneur."

17:44.064 --> 17:46.166
And then he called me one day
and said,

17:46.200 --> 17:47.467
"I have a question for you."

17:47.501 --> 17:50.170
He said, "Tell me about
the meaning of your work.

17:50.204 --> 17:52.472
You are gonna be able
to change the world at a scale

17:52.506 --> 17:54.107
that you won't be able
to change the world

17:54.141 --> 17:56.610
in your own companies."

17:56.643 --> 17:59.613
And that's what got me
at the end of the day.

17:59.646 --> 18:03.584
- Elon had a very specific way
of motivating people.

18:03.617 --> 18:06.653
And that was he would say
really cool things,

18:06.687 --> 18:08.355
like science fiction things.

18:08.388 --> 18:11.458
And he would make you believe
that you could do it.

18:11.491 --> 18:13.427
- At some point in the future,
like, maybe five

18:13.460 --> 18:15.262
or six years from now,
I think we'll be able

18:15.295 --> 18:18.632
to achieve true
autonomous driving,

18:18.665 --> 18:21.468
where you could literally
get in the car, go to sleep,

18:21.502 --> 18:23.337
and wake up
at your destination.

18:23.370 --> 18:26.273
- He is proposing that
there is a better way.

18:26.306 --> 18:28.509
And I did really believe
in the goals

18:28.542 --> 18:31.512
of the-of the team
and Autopilot.

18:31.545 --> 18:38.185
♪ ♪

18:38.218 --> 18:41.121
- In 2014,
the group was put together

18:41.154 --> 18:43.490
for Autopilot and autonomy.

18:43.524 --> 18:46.326
I was one of
the early team members.

18:46.360 --> 18:48.729
- The naming happened
before I arrived,

18:48.762 --> 18:53.433
but it obviously is
a familiar term in aviation.

18:53.467 --> 18:56.236
You know, a car ought
to be like a plane.

18:56.270 --> 18:58.005
And we trust airplanes
to do this.

18:58.038 --> 18:59.439
We ought to be able
to trust cars.

19:00.240 --> 19:02.442
[beep]
- Please route us through.

19:02.476 --> 19:05.445
- Roger. You're now
under automatic control.

19:05.479 --> 19:06.647
Hands-off steering.

19:06.680 --> 19:08.782
[luxurious music]

19:08.815 --> 19:10.417
- What people need to realize
is this is

19:10.450 --> 19:12.186
a very, very old idea.

19:12.219 --> 19:14.188
♪ ♪

19:14.221 --> 19:16.223
Over, you know,
the past decades,

19:16.256 --> 19:20.460
you've had efforts to build
self-driving cars.

19:20.494 --> 19:23.697
In the 2000s, DARPA,
which is a research arm

19:23.730 --> 19:26.200
of the U. S. Department
of Defense,

19:26.233 --> 19:27.701
put on these contests.

19:27.734 --> 19:29.469
- Welcome to the DARPA
Grand Challenge.

19:29.503 --> 19:30.737
The objective:

19:30.771 --> 19:33.674
create a self-navigating
autonomous vehicle.

19:33.707 --> 19:36.376
- After one of these contests,
Google got interested.

19:36.410 --> 19:40.447
- Google is developing
a robocar that drives itself.

19:40.480 --> 19:42.449
- And over the past ten years,

19:42.482 --> 19:45.219
the self-driving car
industry ramps up.

19:45.252 --> 19:49.122
And Elon Musk of course is not
gonna wanna miss out on that.

19:49.156 --> 19:55.028
♪ ♪

19:55.062 --> 19:56.296
- There was a bit of a mantra

19:56.330 --> 19:59.233
that would explain
Elon's approach.

19:59.266 --> 20:01.134
And that mantra was
that history is changed

20:01.168 --> 20:03.270
by unreasonable men.

20:03.303 --> 20:05.005
We were literally trying
to change

20:05.038 --> 20:07.007
transportation worldwide.

20:08.442 --> 20:09.610
I remember the first time

20:09.643 --> 20:11.178
I walked in
to Tesla's headquarters,

20:11.211 --> 20:13.514
where the Autopilot team sits.

20:13.547 --> 20:18.652
And there was a little sign
on a pillar in that group,

20:18.685 --> 20:20.053
with a number on it.

20:20.087 --> 20:21.288
And I asked one
of the engineers,

20:21.321 --> 20:23.290
"What's that about?"
And he said,

20:23.323 --> 20:24.658
"That's the number of people
that die

20:24.691 --> 20:26.493
"on U. S. highways every year.

20:26.527 --> 20:28.128
"That's why we're here.

20:28.161 --> 20:30.330
We're here to save lives."

20:30.364 --> 20:34.468
- Most other companies working
on self-driving car at the time

20:34.501 --> 20:37.471
were building heavily
on top of lidar.

20:37.504 --> 20:40.207
- Lidar--light detection
and ranging.

20:40.240 --> 20:42.609
By bouncing pulses of light
from a sensor,

20:42.643 --> 20:44.378
the vehicle's
autonomous systems

20:44.411 --> 20:47.648
can figure out how far away
objects are, allowing it to--

20:47.681 --> 20:49.683
- And it can see
through situations

20:49.716 --> 20:52.753
that your cameras
might struggle with.

20:52.786 --> 20:56.590
And that's what is one
of the attractions to lidar.

20:56.623 --> 20:58.025
- It seemed like
the right decision

20:58.058 --> 20:59.760
for a lot of companies,
and for Tesla,

20:59.793 --> 21:02.062
that was just not on the table.

21:03.463 --> 21:07.367
- Lidar was too expensive
and very breakable.

21:07.401 --> 21:10.270
- Margins are thin,
and every little bit matters.

21:10.304 --> 21:13.373
They have to get cars out
into the world today,

21:13.407 --> 21:15.676
and they have to sell them.

21:15.709 --> 21:18.679
- And so the challenge
that we took on was:

21:18.712 --> 21:23.450
could you achieve autonomy
with radar and sonar

21:23.483 --> 21:25.519
and images from cameras?

21:25.552 --> 21:27.087
- So, if you're Elon Musk,

21:27.120 --> 21:29.723
he's gonna turn that
into a positive, right?

21:29.756 --> 21:32.426
He's gonna tell the rest
of the world--the language

21:32.459 --> 21:34.628
he's often liked to use--
that, "It's a crutch."

21:34.661 --> 21:36.730
- Lidar ends up being, like,
somewhat of a crutch.

21:36.763 --> 21:40.467
- He starts to say,
very early on, internally,

21:40.501 --> 21:42.436
and then
pretty soon externally,

21:42.469 --> 21:45.138
that Tesla can build
a self-driving car

21:45.172 --> 21:46.540
just with cameras.

21:46.573 --> 21:49.510
- You can absolutely be
superhuman with just cameras.

21:49.543 --> 21:51.211
- As human beings,
we have two eyes,

21:51.245 --> 21:52.746
and we manage not to
run into each other,

21:52.779 --> 21:54.715
for the most part, when we're
walking down the street.

21:54.748 --> 21:57.551
So the idea was, if you put
eight cameras around a car,

21:57.584 --> 22:00.487
and essentially gave
that camera eight eyes,

22:00.521 --> 22:02.256
you could keep it very safe

22:02.289 --> 22:04.057
from the other vehicles
that are around it.

22:05.559 --> 22:08.729
- There was nothing
theoretically preventing that

22:08.762 --> 22:09.730
from happening.

22:09.763 --> 22:11.498
Like, you know, humans do it,

22:11.532 --> 22:13.200
and so there must be a way

22:13.233 --> 22:15.335
eventually for us
to do it with cameras.

22:15.369 --> 22:19.406
- There was no deep research
phase, where various vehicles

22:19.439 --> 22:22.676
were outfitted
with a range of sensors.

22:22.709 --> 22:25.012
Many team members
would have liked that.

22:25.045 --> 22:27.781
Instead, the conclusion
was made first,

22:27.814 --> 22:29.650
and then the tests
and development activities

22:29.683 --> 22:33.053
began to prove
that conclusion correct.

22:34.454 --> 22:38.058
- A big Silicon Valley company
plans a major announcement.

22:38.091 --> 22:39.793
- Last night at an event
in Southern California.

22:39.826 --> 22:41.061
- Holy shit!
- Whoa.

22:41.094 --> 22:43.697
- Oh, shit.
Oh, my God.

22:43.730 --> 22:45.499
- The first announcement
for Autopilot

22:45.532 --> 22:48.035
was in the fall of 2014.

22:48.068 --> 22:49.570
- Welcome, everyone.
[cheering]

22:49.603 --> 22:52.439
So, we've been able
to accelerate Autopilot.

22:52.472 --> 22:54.474
- At the time,
what they're building

22:54.508 --> 22:57.778
is really
a driver-assisted system.

22:57.811 --> 23:01.615
The human must stay diligent,

23:01.648 --> 23:02.749
must keep their eyes
on the road,

23:02.783 --> 23:03.750
ready to take over at any time.

23:03.784 --> 23:06.386
That's very different
from a self-driving car.

23:06.420 --> 23:08.555
- It'll detect if there's a car
in your blind spot.

23:08.589 --> 23:12.292
- But Elon Musk,
and by extension Tesla,

23:12.326 --> 23:14.228
decided they were gonna
tell people

23:14.261 --> 23:17.364
that we're on the way
to a self-driving car.

23:17.397 --> 23:19.132
That's gonna be
a selling point.

23:19.166 --> 23:20.601
- We have the Autopilot
section here.

23:20.634 --> 23:22.002
And you can watch it.

23:22.035 --> 23:23.270
It'll read
the speed limit signs,

23:23.303 --> 23:25.105
so we
increase speed from 25 to 30.

23:25.138 --> 23:26.240
- It's following
the white lines.

23:26.406 --> 23:27.508
- It's following
the white lines.

23:28.242 --> 23:31.345
- The car can do
almost anything.

23:31.378 --> 23:33.780
- He was up there
in the lights,

23:33.814 --> 23:35.516
making all sorts of wild claims

23:35.549 --> 23:38.185
about the capabilities
of that particular system.

23:38.218 --> 23:41.388
- In fact, when you get home,
you'll actually be able to

23:41.421 --> 23:43.390
just step out of the car

23:43.423 --> 23:45.425
and have it park itself
in your garage.

23:45.459 --> 23:47.494
- At some point,
he cracked a joke about

23:47.528 --> 23:50.063
how he was gonna say something

23:50.097 --> 23:52.499
that his engineers would hear
for the first time.

23:52.533 --> 23:56.737
- And then something-something
I'd like to do--

23:56.770 --> 23:58.705
which I think many of our
engineers will be hearing this

23:58.739 --> 24:01.775
in real time--
[laughter]

24:01.808 --> 24:05.078
is have the charge connector
plug itself in.

24:05.112 --> 24:07.114
[laughter]

24:07.147 --> 24:09.783
Like an articulating--
like, sort of a snake.

24:09.816 --> 24:11.552
- And I thought to myself,
buddy,

24:11.585 --> 24:13.620
you already said a lot
that your engineers

24:13.654 --> 24:16.056
are hearing for the first time.

24:16.089 --> 24:19.626
- The other thing that is
really heightened inside Tesla

24:19.660 --> 24:21.495
is you've got Elon Musk

24:21.528 --> 24:25.165
really driving the aura
around these cars.

24:25.199 --> 24:28.769
- Autopilot was a very strong
focus of Elon.

24:28.802 --> 24:32.139
He sort of created
Tesla's brand around it.

24:32.172 --> 24:37.611
- You know, I'm confident that,
in less than a year,

24:37.644 --> 24:41.315
you'll be able to go from
highway onramp to highway exit

24:41.348 --> 24:43.250
without touching any controls.

24:43.283 --> 24:44.518
[applause]

24:44.551 --> 24:46.119
- So people start buying this.

24:46.153 --> 24:49.356
And even then--and this
is typical of Tesla,

24:49.389 --> 24:51.725
and Silicon Valley
in general--

24:51.758 --> 24:53.527
it wasn't ready.

24:53.560 --> 24:57.397
Then there's all this pressure
inside Tesla to get it done.

24:57.431 --> 25:00.534
- Elon sets crazy ambitious
goals for himself,

25:00.567 --> 25:02.736
and then that translates
to crazy ambitious goals

25:02.769 --> 25:04.204
for people around him.

25:04.238 --> 25:07.074
So, often we describe
to recruits,

25:07.107 --> 25:08.775
you are not joining
the regular army here.

25:08.809 --> 25:11.111
You're joining special forces.

25:11.144 --> 25:16.350
♪ ♪

25:16.383 --> 25:21.421
- I got to be an approved
Autopilot tester back in 2014.

25:21.455 --> 25:23.624
The first time
I drove the car,

25:23.657 --> 25:26.326
went across an intersection
in a neighborhood,

25:26.360 --> 25:30.330
and the car went full brake
for about half a second,

25:30.364 --> 25:32.733
and then immediately
full throttle.

25:34.501 --> 25:37.004
It was really
sort of a wakeup call.

25:37.037 --> 25:38.572
This is very experimental.

25:38.605 --> 25:41.141
- I'm testing the latest
version of Autopilot

25:41.175 --> 25:42.209
every week.

25:42.242 --> 25:45.779
We wanna make sure
that our testing is exhaustive

25:45.812 --> 25:49.116
before we release the software.

25:49.149 --> 25:50.717
♪ ♪

25:50.751 --> 25:52.553
- A lot of the
software updates were pushed

25:52.586 --> 25:54.488
to Elon Musk's own car.

25:54.521 --> 25:57.057
Certainly, his opinions
were the ones

25:57.090 --> 26:00.294
that were always keeping
the team on their toes.

26:00.327 --> 26:03.363
But what it also does
is it focuses the team

26:03.397 --> 26:07.167
on certain short-term
appeasement projects,

26:07.201 --> 26:09.670
as opposed to developing

26:09.703 --> 26:12.239
a more total,
complete solution.

26:14.241 --> 26:17.544
I was concerned about the fact
that the software

26:17.578 --> 26:23.217
simply wasn't validated across
a wide range of roadways.

26:23.250 --> 26:26.019
And if this is the first step,

26:26.053 --> 26:30.090
in terms of this technology's
relationship to the public,

26:30.123 --> 26:34.361
then, you know, it doesn't
paint a pretty picture.

26:34.394 --> 26:38.699
And so I started considering
other opportunities.

26:38.732 --> 26:41.268
- I mean, I almost--this may
sound a little complacent,

26:41.301 --> 26:43.170
but I almost view it as,
like, a solved problem.

26:43.203 --> 26:45.105
Like, we know exactly
what to do,

26:45.138 --> 26:47.508
and we'll be there
in a few years.

26:52.546 --> 26:54.047
- Are self-driving cars

26:54.081 --> 26:55.449
closer than we think?

26:55.482 --> 26:58.318
Well, a few days ago,
Tesla CEO Elon Musk tweeted,

26:58.352 --> 27:00.554
"Autopilot goes to wide
release on Thursday."

27:00.587 --> 27:02.422
- Unveiled
an Autopilot system,

27:02.456 --> 27:06.326
which allows cars to change
lanes by themselves.

27:06.360 --> 27:09.429
- It takes a lot of the tedious
aspects of driving

27:09.463 --> 27:11.565
and alleviates
it from your concern

27:11.598 --> 27:15.402
as you're driving
on a long stretch of a highway.

27:15.435 --> 27:17.471
- We were really excited
to not only show

27:17.504 --> 27:19.006
the technology to the world,

27:19.039 --> 27:21.441
but also show the potential
of the technology.

27:21.475 --> 27:22.576
- You know, in fact,
comfortably

27:22.609 --> 27:26.313
within three years, the car
will be able to take you

27:26.346 --> 27:27.748
from point to point--
like, basically

27:27.781 --> 27:30.117
from your driveway to work--

27:30.150 --> 27:31.552
without you touching anything.

27:31.585 --> 27:34.254
And you could be asleep
the whole time.

27:34.288 --> 27:37.524
- Tesla, in putting out
material blog posts,

27:37.558 --> 27:40.360
made it clear self-driving cars
are not here,

27:40.394 --> 27:41.995
they are a long way away.

27:48.602 --> 27:51.705
- When it comes to Tesla
and Elon Musk,

27:51.738 --> 27:56.210
the message is constantly
going up and down

27:56.243 --> 27:57.477
and up and down, right?

27:57.511 --> 28:00.147
And Elon can change his mind
at any moment.

28:00.180 --> 28:02.049
He can say one thing
at one moment,

28:02.082 --> 28:04.151
and then he'll say something
completely different.

28:12.226 --> 28:14.461
- The car can
do almost anything.

28:14.494 --> 28:19.099
The expectation is that someone
is paying attention to the road

28:19.132 --> 28:21.602
and is ready to take over
if there is an issue.

28:26.673 --> 28:30.577
- What people need to realize
is that it's very easy

28:30.611 --> 28:32.079
to say these things.

28:32.112 --> 28:33.680
And there's no check on him.

28:33.714 --> 28:35.649
- They advise you to keep your
hands on the steering wheel

28:35.682 --> 28:37.317
when using the auto-steer,

28:37.351 --> 28:40.654
but as we're in testing,
you really don't need to.

28:40.687 --> 28:43.023
- I think, for a lot
of the Tesla fans,

28:43.056 --> 28:48.161
they focus in on the things
that Elon Musk says

28:48.195 --> 28:49.730
that they want to hear.

28:51.331 --> 28:55.636
So when he says self-driving
is a solved problem,

28:55.669 --> 28:57.070
that's what they hear,

28:57.104 --> 28:59.339
and that's what
they pay attention to.

28:59.373 --> 29:00.741
- I had an investor say to me,

29:00.774 --> 29:04.011
"You guys have embarked
on a really virtuous path,

29:04.044 --> 29:05.546
but it's gonna be
a difficult path."

29:05.579 --> 29:08.649
And I said, "Why?" He said,
"Well, we're also, you know,

29:08.682 --> 29:11.018
investors in the largest pharma
companies in the world,"

29:11.051 --> 29:14.688
and it's expected that people
will die in a drug trial."

29:14.721 --> 29:18.325
And it happens largely outside
of the spotlight of the media."

29:18.358 --> 29:20.794
- A number of videos hit
the internet showing drivers

29:20.827 --> 29:22.462
going hands-free,

29:22.496 --> 29:26.266
playing games, even sleeping
while the car's in motion.

29:26.300 --> 29:28.502
- He pointed that
"your challenge is gonna be

29:28.535 --> 29:31.138
quite different with Autopilot,"

29:31.171 --> 29:35.709
because people don't expect to
tolerate deaths on a highway,"

29:35.742 --> 29:37.544
and it's going to be
in the spotlight."

29:38.145 --> 29:41.515
- Somebody is gonna get
in an accident.

29:41.548 --> 29:43.250
Will Tesla be liable for that?

29:43.283 --> 29:44.718
- If there's unfortunately
an accident,

29:44.751 --> 29:47.654
the driver is in control
of the car.

29:49.823 --> 29:51.658
- I remember Josh
talking to me

29:51.692 --> 29:53.760
about the Autopilot system.

29:53.794 --> 29:56.797
I wasn't there yet,
in terms of the technology.

29:56.830 --> 29:58.198
You know, he was all-in.

29:58.232 --> 30:01.368
- All right, so this is
the new 7.0 firmware

30:01.401 --> 30:03.370
for the Tesla Model S.

30:03.403 --> 30:06.106
- I believe that he felt,
you know, very qualified

30:06.139 --> 30:09.443
as to how those features,
you know, worked.

30:09.476 --> 30:11.411
He would create these videos.

30:11.445 --> 30:14.114
- This is gonna be a busy
intersection,

30:14.147 --> 30:17.351
just so you can see
how it reacts with the traffic.

30:17.384 --> 30:19.186
- He was studying it
with an eye toward,

30:19.219 --> 30:21.321
"How can I help other people

30:21.355 --> 30:23.524
get the best
out of their Tesla, too?"

30:23.557 --> 30:26.026
- Here's a turn
that the auto-steer

30:26.059 --> 30:27.728
is probably going to do
very, very poorly,

30:27.761 --> 30:31.365
'cause it's in a turn
that's very sharp.

30:31.398 --> 30:33.200
And yep, it said take control,

30:33.233 --> 30:35.035
and he immediately
took control.

30:35.068 --> 30:37.104
♪ ♪

30:37.137 --> 30:40.641
- I remember something about
how Josh had said

30:40.674 --> 30:42.676
the car had helped
possibly save his life,

30:42.709 --> 30:45.078
because of something
that occurred on the road.

30:46.313 --> 30:48.615
[horn blaring]

30:53.687 --> 30:59.159
- Josh told me that Elon
retweeted the video.

30:59.193 --> 31:01.495
And he was so happy about it.

31:01.528 --> 31:04.064
Sort of in the midst
of this--you know,

31:04.097 --> 31:06.700
this great wave of technology
and what's happening.

31:06.733 --> 31:09.736
And yeah, it was just
a great moment for him.

31:14.374 --> 31:15.676
[phone dialing]

31:15.709 --> 31:17.744
[line ringing]

31:17.778 --> 31:20.781
- Levy 911, what is the
address of your emergency?

31:20.814 --> 31:22.449
- There was just a wreck.

31:22.482 --> 31:23.684
A head-on collision
right here--

31:23.717 --> 31:25.552
Oh, my God Almighty.

31:25.586 --> 31:30.791
♪ ♪

31:30.824 --> 31:36.430
- I was here at work,
and probably heard about

31:36.463 --> 31:40.067
the accident an hour
after it happened.

31:42.336 --> 31:44.171
- Ken called me.

31:44.204 --> 31:48.509
Told me that Josh had been
killed in a car accident.

31:50.744 --> 31:53.247
- Josh and his family
had just been on a vacation

31:53.280 --> 31:56.183
to Disney World, in Orlando,

31:56.216 --> 31:59.686
and that he had said
goodbye to everybody,

31:59.720 --> 32:01.722
jumped in his car.

32:01.755 --> 32:04.558
- I, Corporal Daphne Yunker,
of the Florida Highway Patrol,

32:04.591 --> 32:06.493
am conducting
a criminal investigation.

32:06.527 --> 32:10.230
- I noticed the car come over
the upper grade

32:10.264 --> 32:11.732
and start coming down,

32:11.765 --> 32:16.003
and the semi turned left,
started crossing the highway.

32:16.036 --> 32:20.107
I thought the car
was gonna stop, and it didn't.

32:20.140 --> 32:23.677
It was like a white explosion,
a cloud.

32:23.710 --> 32:28.015
- Only thing I could think
of was how could this happen?

32:28.048 --> 32:33.053
And my heart was broken
for his family.

32:38.692 --> 32:43.030
- I was--I was incredulous,
and it was a real blow.

32:43.063 --> 32:46.533
Of all people. Of all people.

32:46.567 --> 32:49.203
- It did not seem to speed up
or slow down.

32:49.236 --> 32:52.072
Drove right through
a little grove of trees

32:52.105 --> 32:54.308
at the--at someone's
property line.

32:54.341 --> 32:56.276
- The first question I think
that went through my mind

32:56.310 --> 32:59.346
after the accident--
was he in self-drive?

32:59.379 --> 33:01.748
It was devastating, obviously,
to lose a friend,

33:01.782 --> 33:03.517
but it was--
what was frustrating,

33:03.550 --> 33:07.221
I think, to me,
was knowing that,

33:07.254 --> 33:10.691
you know, that maybe he was on
that front edge of technology,

33:10.724 --> 33:14.061
maybe a little bit further
than we would have all liked.

33:15.629 --> 33:17.798
- How do you think that
that particular crash

33:17.831 --> 33:20.033
that day
could have been prevented?

33:20.067 --> 33:24.671
♪ ♪

33:24.705 --> 33:26.607
- I don't know,
because I didn't see anything

33:26.640 --> 33:29.409
that was--you know,
I don't know.

33:31.478 --> 33:33.180
- When I heard
about Josh's accident,

33:33.213 --> 33:36.149
it was personal, in that sense,

33:36.183 --> 33:38.785
that it felt like we'd lost
a member of a family.

33:38.819 --> 33:42.789
♪ ♪

33:42.823 --> 33:45.025
- Elon had
an all-hands meeting

33:45.058 --> 33:46.326
for the Autopilot team.

33:48.295 --> 33:50.063
It was just that, you know,
this had happened,

33:50.097 --> 33:54.434
and we're doing all we could
to figure it out,

33:54.468 --> 34:00.140
and, you know, we do want
to try to make Autopilot safe.

34:02.042 --> 34:03.443
- At the time of that crash,
I was aware

34:03.477 --> 34:06.580
that people were trusting
the system to do things

34:06.613 --> 34:10.083
that it was not designed
or capable of doing.

34:10.117 --> 34:12.719
The fact that that
sort of accident happened

34:12.753 --> 34:15.455
was obviously tragic,
but it wasn't really--

34:15.489 --> 34:17.357
wasn't something that--

34:17.391 --> 34:18.659
it was going to happen.

34:20.494 --> 34:22.296
It was going to happen.

34:26.834 --> 34:29.770
[light music]

34:29.803 --> 34:36.076
♪ ♪

34:37.444 --> 34:39.313
- It was the middle of June.

34:39.346 --> 34:42.482
I got an email
from our investigatory team

34:42.516 --> 34:45.085
that there had been
a Tesla fatality.

34:45.118 --> 34:49.523
♪ ♪

34:49.556 --> 34:51.758
The National Highway
Traffic Safety Administration,

34:51.792 --> 34:55.729
or NHTSA, has the authority
to regulate unreasonable risk

34:55.762 --> 34:57.164
to safety on the roads.

34:59.433 --> 35:03.370
Evening of June 29th, we had
scheduled a call with Tesla.

35:03.403 --> 35:05.472
Our general counsel
let them know

35:05.506 --> 35:07.674
we'd be opening
this investigation

35:07.708 --> 35:10.177
and that it would be made
public the following day.

35:11.712 --> 35:14.181
At that point,
Elon Musk came on

35:14.214 --> 35:17.317
and just sort of
started shouting.

35:17.351 --> 35:18.685
He was really, really upset

35:18.719 --> 35:20.754
that we'd be opening
a public investigation,

35:20.787 --> 35:25.259
accusing us
of singling Tesla out.

35:25.292 --> 35:27.227
Made the point several times
that, you know,

35:27.261 --> 35:31.031
this was one fatality
out of more than 35,000 a year,

35:31.064 --> 35:33.700
so why were we
picking on Tesla

35:33.734 --> 35:35.469
and suggesting
that he would sue us

35:35.502 --> 35:37.137
for opening this investigation.

35:39.039 --> 35:41.608
I was surprised to hear Elon
on the call.

35:41.642 --> 35:44.211
I was surprised to hear
how angry he was.

35:46.180 --> 35:48.048
But ultimately,
none of that mattered.

35:48.081 --> 35:51.018
Our job was only to worry
about the safety,

35:51.051 --> 35:53.220
and this was
a clear issue of safety

35:53.253 --> 35:55.422
that needed to be investigated.

35:57.324 --> 36:00.460
- The driver of the semi
reported that the Navy vet

36:00.494 --> 36:04.131
was watching a movie
while driving.

36:04.164 --> 36:06.533
- Not very long
after the accident,

36:06.567 --> 36:08.202
there were all these people

36:08.235 --> 36:11.205
saying
really just crass things,

36:11.238 --> 36:16.376
claiming, you know, that Josh
was watching a program.

36:18.345 --> 36:20.347
That's not Josh.

36:20.380 --> 36:21.782
Guarantee you that's not Josh.

36:21.815 --> 36:23.383
- What investigators
are looking for

36:23.417 --> 36:26.987
is the data leading up
to the accident.

36:28.455 --> 36:32.492
- One of the huge challenges
of the system at the time

36:32.526 --> 36:37.331
was trying to differentiate
between a truck

36:37.364 --> 36:40.200
and a bridge--
and a overhead bridge.

36:40.234 --> 36:42.336
You know, when a truck
is parked perpendicular

36:42.369 --> 36:44.204
to the road
and blocking the way,

36:44.238 --> 36:46.340
the system might think of it
as a overhead bridge,

36:46.373 --> 36:49.676
and so it was safe to kind of
continue driving through it.

36:49.710 --> 36:51.512
- Tesla posted to their blog,

36:51.545 --> 36:53.714
calling this incident
a tragic loss.

36:53.747 --> 36:56.283
- Tesla said the car ran into
a tractor-trailer

36:56.316 --> 36:57.718
because the software
didn't notice

36:57.751 --> 37:03.624
the white side of the truck
in the brightly lit sky.

37:03.657 --> 37:05.125
- After the crash,

37:05.158 --> 37:09.029
I think Tesla and Musk
were pretty defensive.

37:09.062 --> 37:10.631
- If, in writing some article
that's negative,

37:10.664 --> 37:12.266
you effectively
dissuade people

37:12.299 --> 37:13.534
from using autonomous vehicle,

37:13.567 --> 37:14.701
you're killing people.

37:14.735 --> 37:17.104
- In the statement that Tesla
put out,

37:17.137 --> 37:19.573
they more or less said
it was driver error.

37:20.807 --> 37:24.144
They reminded people you have
to keep your eyes on the road.

37:24.178 --> 37:25.579
They didn't say Joshua Brown

37:25.612 --> 37:27.181
didn't keep his eyes
on the road,

37:27.214 --> 37:29.049
but that's what
they were implying.

37:29.082 --> 37:30.517
- Tesla says you should keep
your hands

37:30.551 --> 37:33.153
on the steering wheel
during the Autopilot.

37:33.187 --> 37:35.455
The question then is...
-both: What is the point?

37:35.489 --> 37:36.456
- We both said it.
- If I have to hold on

37:36.490 --> 37:38.158
to the wheel?

37:38.192 --> 37:40.527
- Elon had already talked
a pretty big game

37:40.561 --> 37:42.729
about what this technology
was going to do.

37:43.730 --> 37:45.365
It's kinda hard
to reel it back

37:45.399 --> 37:47.634
if you've already raised
people's expectations

37:47.668 --> 37:48.902
and excitement.

37:48.936 --> 37:51.738
- Do you have any regrets about
how Tesla rolled out Autopilot

37:51.772 --> 37:53.507
in the cars?

37:53.540 --> 37:55.709
- No, I think--I think we did
the right thing.

37:55.742 --> 37:58.412
You know, it's basically
advanced driver's assistance,

37:58.445 --> 38:00.113
at this point.

38:00.147 --> 38:02.082
Every single step we took,
at least from our standpoint,

38:02.115 --> 38:05.219
was to reduce complacency
in the use of Autopilot

38:05.252 --> 38:06.720
and to improve safety.

38:06.753 --> 38:10.791
♪ ♪

38:10.824 --> 38:13.260
- This is new technology
that's on the roads.

38:13.293 --> 38:15.062
People have
a lot of questions.

38:15.095 --> 38:17.598
This one crash was
an opportunity to sort of say,

38:17.631 --> 38:19.399
is there a technological
problem here

38:19.433 --> 38:22.102
with this--you know,
with this Autopilot suite?

38:24.371 --> 38:26.673
The first thing we did
was go to Tesla and say,

38:26.707 --> 38:29.610
"Hey, give us all the data
you have on crashes

38:29.643 --> 38:30.744
on where Autopilot is in use."

38:33.313 --> 38:34.781
What we knew is that
there were a lot of crashes.

38:34.815 --> 38:36.717
And this is not surprising
and necessarily

38:36.750 --> 38:38.318
a cause for concern.

38:38.352 --> 38:42.623
There are a lot of crashes
on the roadways in the U. S.

38:42.656 --> 38:44.791
So yeah, there's
38 separate crashes

38:44.825 --> 38:47.027
that we're looking at here.

38:47.060 --> 38:49.596
- The world doesn't know
about these other crashes,

38:49.630 --> 38:52.065
because Tesla
hasn't made it public.

38:52.099 --> 38:55.269
Tesla's saying
Autopilot is safer,

38:55.302 --> 38:57.237
but what we're seeing
with these crashes

38:57.271 --> 38:59.139
are these gray areas.

38:59.173 --> 39:01.508
- In the Tesla case,
what we were looking at was:

39:01.542 --> 39:02.776
was there a pattern showing

39:02.809 --> 39:04.745
that there is
a technological defect,

39:04.778 --> 39:06.580
or that people
were using Autopilot

39:06.613 --> 39:09.383
beyond the way that
it was designed to be used?

39:09.416 --> 39:11.218
- The internal pressure was,

39:11.251 --> 39:13.120
"We gotta get this problem
solved, pronto."

39:15.189 --> 39:16.557
- When Autopilot
first came out,

39:16.590 --> 39:19.026
the main way of making sure
the driver

39:19.059 --> 39:20.761
was paying attention--
it could detect

39:20.794 --> 39:23.430
whether your hand
was on the steering wheel.

39:23.463 --> 39:25.732
It would let you keep your hand
off the steering wheel

39:25.766 --> 39:28.502
for minutes at a time--three,
four, five minutes.

39:29.469 --> 39:32.339
- It was just too long
between those warnings.

39:32.372 --> 39:34.308
What we had to do was struggle
with how to do that

39:34.341 --> 39:37.411
in an elegant way that would
keep consumers engaged

39:37.444 --> 39:41.215
and not--and not cause them to
ignore or be frustrated by it.

39:41.248 --> 39:43.250
- After weeks of controversy
and questions

39:43.283 --> 39:44.418
about the safety
of it's Autopilot drivers.

39:44.451 --> 39:46.086
-What it calls
major improvements

39:46.119 --> 39:47.454
to its Autopilot software.

39:48.455 --> 39:50.657
- They announced there would be
this press conference,

39:50.691 --> 39:51.992
and Elon would talk about it.

39:52.593 --> 39:54.528
- Something quite
significant is,

39:54.561 --> 39:57.130
if the user ignores
repeated warnings,

39:57.164 --> 39:59.032
more than three times
in an hour,

39:59.066 --> 40:02.503
then the driver will have to
park the car and restart it.

40:02.536 --> 40:06.173
- There would be more frequent
warnings, shorter intervals,

40:06.206 --> 40:08.141
up to three minutes.

40:08.175 --> 40:10.210
You would get a chime
to remind you

40:10.244 --> 40:13.480
to put your hands back on.

40:13.514 --> 40:16.650
But that's still a system
that has a lot of gaps.

40:16.683 --> 40:19.186
In terms of taking your eyes
off the road,

40:19.219 --> 40:22.089
30 seconds is an eternity.

40:22.122 --> 40:24.191
- I really feel like
we've struck a great balance

40:24.224 --> 40:29.229
between improving the safety
and improved the usefulness.

40:29.263 --> 40:33.233
- I remember Elon talked about
how it was gonna be the radar

40:33.267 --> 40:38.438
that was sort of
first-rank or priority one.

40:38.472 --> 40:42.276
- We're making much
more effective use of radar.

40:42.309 --> 40:47.047
- I just thought radar
has been around for 75 years.

40:47.080 --> 40:51.051
If they could do this now,
why didn't they do it before?

40:51.084 --> 40:52.686
I think the timing
was significant.

40:52.719 --> 40:57.457
I mean, it was right
after this tragic accident.

40:57.491 --> 41:00.527
And they were trying
to make it sound like,

41:00.561 --> 41:02.529
"We got this under control."

41:02.563 --> 41:04.464
- Obvious question
I have to ask:

41:04.498 --> 41:07.301
would the improvements
have mitigated

41:07.334 --> 41:10.237
or saved, say,
Josh Brown's life?

41:10.270 --> 41:12.739
♪ ♪

41:12.773 --> 41:15.342
- We believe it would have.

41:15.375 --> 41:18.745
- And so, the truck would have
been seen by the radar only,

41:18.779 --> 41:20.747
and braking would
have been engaged.

41:24.051 --> 41:26.553
- These things cannot be said
with absolute certainty,

41:26.587 --> 41:28.755
but we believe
it is very likely that,

41:28.789 --> 41:31.158
yes, it would have.

41:37.097 --> 41:38.398
- Yeah, I mean, there have been
so many announcements of,

41:38.432 --> 41:39.499
like, autonomous EV startups.

41:39.533 --> 41:40.767
I'm waiting for my mom
to announce one.

41:40.801 --> 41:42.069
- Okay.
[laughter]

41:42.102 --> 41:44.705
- It's like, "Mom, you too?"
[laughter]

41:44.738 --> 41:46.673
- Speaking of that, when you're
talking about the sales,

41:46.707 --> 41:50.010
you have booked
how many orders for--

41:50.043 --> 41:51.778
- It's on the order of 400,000.
- 400,000.

41:51.812 --> 41:53.580
- It's quite surprising,
actually.

41:53.614 --> 41:56.083
I mean, the--

41:56.116 --> 41:58.318
'cause we didn't do
any advertising.

41:58.352 --> 42:00.320
- Elon had, I think,
in some ways,

42:00.354 --> 42:01.722
a personal point of pride

42:01.755 --> 42:05.058
to be able to move faster
than the competition.

42:05.092 --> 42:08.729
[cheers and applause]

42:08.762 --> 42:11.164
The company was betting
its survival

42:11.198 --> 42:13.367
on the success of the Model 3.

42:13.400 --> 42:15.469
And the fact that Autopilot
was gonna be on it,

42:15.502 --> 42:17.337
I think
was a huge selling point.

42:17.371 --> 42:20.007
- If you think about fully
autonomous vehicles,

42:20.040 --> 42:22.709
how far do you think we are
from that becoming a reality?

42:22.743 --> 42:25.179
- I think we're basically

42:25.212 --> 42:28.315
less than two years
away from complete autonomy.

42:28.348 --> 42:31.084
- Wow.
- Complete. Safer than a human.

42:31.118 --> 42:33.153
- As with a lot of what
happens with Elon,

42:33.187 --> 42:35.689
he doubles down on it
over and over and over again.

42:35.722 --> 42:37.457
And he continues
with his message, right,

42:37.491 --> 42:39.193
that, you know,
this is gonna be

42:39.226 --> 42:41.061
a safe thing for the world.

42:41.094 --> 42:42.596
You know,
the Joshua Brown crash

42:42.629 --> 42:45.032
was in the spring of 2016.

42:45.065 --> 42:48.202
By the fall of 2016,
the entire Autopilot team

42:48.235 --> 42:51.205
essentially quit
what they were doing,

42:51.238 --> 42:54.608
and they all chipped in
on this video

42:54.641 --> 42:58.345
to show just how autonomous,

42:58.378 --> 43:00.280
so to speak,
their car could be.

43:00.314 --> 43:03.283
[rock music]

43:03.317 --> 43:10.157
♪ ♪

43:16.730 --> 43:19.066
- Do you remember this video?

43:19.099 --> 43:20.734
- Yeah.

43:20.767 --> 43:23.370
- Changed lanes,
and stopped just in--

43:23.403 --> 43:24.705
just short of a crosswalk.

43:24.738 --> 43:27.274
We're turning right onto--
yeah, kind of

43:27.307 --> 43:28.675
in front of traffic, but--

43:28.709 --> 43:32.646
- It's very slick, but
the video does not give you

43:32.679 --> 43:36.517
a full impression
of what is actually happening.

43:36.550 --> 43:38.252
- The people that were
putting it together

43:38.285 --> 43:41.188
were sitting right behind me.

43:41.221 --> 43:44.558
And the Autopilot group was
running lap after lap that day,

43:44.591 --> 43:46.426
to try to get a clean lap.

43:46.460 --> 43:51.098
- At one point, the car,
while in Autopilot mode,

43:51.131 --> 43:53.100
hit a fence.

43:53.133 --> 43:55.736
They patched the car up,
and they did another run.

43:55.769 --> 43:57.337
- And so, at the very end
of the day,

43:57.371 --> 43:59.473
apparently
the clean lap came in.

43:59.506 --> 44:01.375
They started editing it
all together.

44:01.408 --> 44:03.410
♪ ♪

44:03.443 --> 44:05.345
- This was meant to be
a demo video

44:05.379 --> 44:07.214
of what the team was
working on and developing,

44:07.247 --> 44:10.551
and what its capability
could deliver in the future.

44:10.584 --> 44:12.419
- I think my biggest problem
with the video

44:12.452 --> 44:15.489
was the first line
that says it's the driver

44:15.522 --> 44:17.391
was only there
for legal reason.

44:17.424 --> 44:19.393
♪ ♪

44:19.426 --> 44:21.128
I think
it's definitely language

44:21.161 --> 44:22.796
that's designed for marketing.

44:22.829 --> 44:25.098
We are trying to imply
that the thing

44:25.132 --> 44:26.567
is fully capable
of self-driving,

44:26.600 --> 44:30.404
and only the evil regulators
are holding us back.

44:30.437 --> 44:31.505
- They sort of portrayed it
as something

44:31.538 --> 44:32.706
as all their cars can do,

44:32.739 --> 44:35.776
and that, I don't think,
was really fair.

44:35.809 --> 44:38.712
[cheering]

44:38.745 --> 44:40.347
- Not too long after that,

44:40.380 --> 44:43.150
Tesla started offering
an official service called

44:43.183 --> 44:49.189
Full Self-Driving, capital FSD,
for as much as $10,000.

44:49.223 --> 44:50.691
Now, in the short-term,

44:50.724 --> 44:53.360
what they and everybody else
was really buying

44:53.393 --> 44:56.463
was the promise
that this is gonna happen.

44:56.496 --> 44:58.765
- The idea was we were putting
the hardware on every car

44:58.799 --> 45:01.134
in advance
of having the software.

45:01.168 --> 45:04.104
It was a gutsy move
because then the software

45:04.137 --> 45:08.208
had to be developed
to deliver the capability.

45:08.242 --> 45:09.776
- We're still on track
for being able

45:09.810 --> 45:13.080
to go cross-country,
from L. A. to New York

45:13.113 --> 45:15.382
by the end of the year,
fully autonomous.

45:15.415 --> 45:17.784
- There was a sincere belief
inside of Tesla, and Elon

45:17.818 --> 45:19.219
had the sincere belief that

45:19.253 --> 45:21.388
hey, we're just
around the corner.

45:21.421 --> 45:23.090
- A lot of people at the time
believed

45:23.123 --> 45:25.092
that Tesla had an advantage

45:25.125 --> 45:27.561
in getting self-driving
to the market first,

45:27.594 --> 45:30.364
because it already had
all the cars on the road

45:30.397 --> 45:32.499
that could be collecting data
all the time,

45:32.533 --> 45:36.703
and that data would help train
the computer to be better.

45:36.737 --> 45:38.438
- So, you've already got
a fleet of Teslas

45:38.472 --> 45:40.641
driving all these roads.
- Yeah.

45:40.674 --> 45:42.543
- You're accumulating
a huge amount of data.

45:42.576 --> 45:44.144
- Yes.

45:44.178 --> 45:47.548
- I expected to see
sophisticated infrastructure

45:47.581 --> 45:51.485
to collect that data,
to process that data.

45:51.518 --> 45:54.321
The reality was a lot
of the types of data

45:54.354 --> 45:56.657
that you would want to collect
from the car,

45:56.690 --> 46:00.394
like video data,
high-quality images,

46:00.427 --> 46:04.231
there was neither the hardware
nor the backend infrastructure

46:04.264 --> 46:08.101
to allow that volume of data
to reach Tesla.

46:08.135 --> 46:11.572
And so that rate
of learning wasn't great.

46:13.407 --> 46:16.143
- Elon, he put eight cameras
on the car.

46:16.176 --> 46:17.578
I don't think that was enough,

46:17.611 --> 46:20.180
because they were
not redundant,

46:20.214 --> 46:22.182
other than the front cameras.

46:22.216 --> 46:24.751
You really need redundancy, so
if one of these sensors fails,

46:24.785 --> 46:28.121
the car can either stop itself
in a safe manner

46:28.155 --> 46:30.057
or it can continue driving.

46:30.090 --> 46:32.526
- There was a small space
right in front of the car

46:32.559 --> 46:37.297
that was completely out of the
view for any of the cameras.

46:37.331 --> 46:39.132
And so, you know, a small dog

46:39.166 --> 46:42.102
or a baby could crawl
in front of the car,

46:42.135 --> 46:44.271
and a car wouldn't be able
to know

46:44.304 --> 46:48.442
whether it's safe to move
forward or start to drive.

46:53.347 --> 46:55.415
It was hard for me
to personally believe

46:55.449 --> 46:58.051
that promise was gonna be
lived up to,

46:58.085 --> 46:59.386
that we could be confident

46:59.419 --> 47:01.722
that this was gonna enable
full self-driving.

47:01.755 --> 47:04.491
♪ ♪

47:04.525 --> 47:07.127
- Sometime after
the Joshua Brown crash,

47:07.160 --> 47:10.230
the head of Autopilot
left Tesla.

47:10.264 --> 47:11.498
You know,
it just gave the image

47:11.532 --> 47:13.534
of some sort
of instability there.

47:13.567 --> 47:16.136
- There was a sense that
when Elon felt that things

47:16.170 --> 47:17.271
were not going well,

47:17.304 --> 47:20.174
there was efforts
to shake things up.

47:20.207 --> 47:23.410
There were members of the team
that I learned were fired.

47:23.443 --> 47:27.014
I never knew why.
They just stopped showing up.

47:27.047 --> 47:30.017
[tense music]

47:30.050 --> 47:31.451
♪ ♪

47:31.485 --> 47:35.589
Theranos was happening
during that same time period.

47:35.622 --> 47:38.158
And a lot of the stories
were kind of, like,

47:38.192 --> 47:39.526
at the back of my mind,

47:39.560 --> 47:43.397
and it just definitely
made me question a lot more

47:43.430 --> 47:49.002
about what's behind
some of this public optimism.

47:49.036 --> 47:53.774
♪ ♪

47:53.807 --> 47:55.375
After I left Tesla,

47:55.409 --> 47:58.745
I felt like I had
to do a bit of soul searching,

47:58.779 --> 48:03.517
just because I feel like
sometimes it seems like

48:03.550 --> 48:06.153
people and companies

48:06.186 --> 48:09.356
were being rewarded
not for telling the truth

48:09.389 --> 48:13.026
but in fact for doing
maybe a bit of the opposite.

48:13.060 --> 48:17.364
♪ ♪

48:17.397 --> 48:19.466
- It was my last day
on the job at NHTSA

48:19.499 --> 48:23.203
when we were ready
to release that report.

48:23.237 --> 48:25.239
It was the end
of the Obama Administration,

48:25.272 --> 48:27.641
and so we made sort of
an internal commitment

48:27.674 --> 48:31.278
to say we're not gonna
leave this to the next guys.

48:31.311 --> 48:34.214
- A months-long investigation
into Tesla's Autopilot system

48:34.248 --> 48:36.083
has wrapped up.
- There was no defect,

48:36.116 --> 48:37.651
and therefore there
will be no recall

48:37.684 --> 48:39.353
related to Tesla's Autopilot.

48:39.386 --> 48:42.656
- Essentially
clearing the company.

48:42.689 --> 48:45.425
- I was a little bit
dumbfounded.

48:45.459 --> 48:50.130
The system couldn't see
a tractor-trailer,

48:50.163 --> 48:52.165
and that's not a defect?

48:52.199 --> 48:55.536
♪ ♪

48:55.569 --> 48:57.337
- So, this is--you know,
it's a little complicated,

48:57.371 --> 48:59.706
and almost counterintuitive,
right?

48:59.740 --> 49:03.177
Autopilot didn't even engage
to try to stop that crash.

49:03.210 --> 49:05.145
But the fact of the matter
is Autopilot

49:05.179 --> 49:09.516
wasn't designed to stop
every crash in every instance.

49:09.550 --> 49:12.085
It was a driver-assistance
system.

49:12.119 --> 49:14.588
It wasn't a full
self-driving system.

49:14.621 --> 49:17.124
- Tesla issued a statement
saying it appreciated

49:17.157 --> 49:19.359
the thoroughness
of the investigation.

49:19.393 --> 49:22.396
- My personal point of view
was it's clear this technology

49:22.429 --> 49:24.231
is being misused right now.

49:24.264 --> 49:27.100
We saw people were pushing
the limits on the system,

49:27.134 --> 49:28.435
but--and this was early on

49:28.468 --> 49:30.571
in the deployment
of the technology,

49:30.604 --> 49:34.341
and at the time, there wasn't
enough data to show

49:34.374 --> 49:36.510
that there was
a technological defect here.

49:37.544 --> 49:41.782
- I remember the day the news
came out that crashes dropped

49:41.815 --> 49:46.587
40% after the Autopilot
component was added.

49:46.620 --> 49:48.555
A lot of news articles
repeated it

49:48.589 --> 49:50.324
because NHTSA had said it,

49:50.357 --> 49:52.759
and that gave it
some legitimacy.

49:52.793 --> 49:55.562
You know, I mean, if the
regulators are saying it,

49:55.596 --> 49:58.232
it must be true.

49:58.265 --> 50:00.100
- You know, I think that's
an unfortunate statistic

50:00.133 --> 50:02.469
that didn't probably belong
in the report.

50:02.503 --> 50:04.505
It was based on data
provided by the company

50:04.538 --> 50:06.173
that hadn't been sort of

50:06.206 --> 50:09.409
independently verified
or vetted.

50:09.443 --> 50:12.145
- Eventually,
some independent researchers

50:12.179 --> 50:13.747
started looking
at the crash data

50:13.780 --> 50:17.050
and didn't believe
it was valid.

50:17.084 --> 50:20.254
- But Tesla was very eager
to pick up on that statistic

50:20.287 --> 50:23.690
and use it to sort of say
"not only is Autopilot good,

50:23.724 --> 50:25.392
it's better than human drivers."

50:25.425 --> 50:28.762
- NHTSA did a study on
Tesla's Autopilot version 1,

50:28.795 --> 50:30.697
which was relatively primitive,

50:30.731 --> 50:35.002
and found that it was a 45%
reduction in highway accidents.

50:35.035 --> 50:37.638
- You know, I think that was
a successful PR move

50:37.671 --> 50:39.339
on their part.

50:39.373 --> 50:42.442
Musk and Tesla,
they're master marketers.

50:47.114 --> 50:50.083
[light music]

50:50.117 --> 50:51.718
♪ ♪

50:51.752 --> 50:54.621
- What scares you the most
about autonomous cars?

50:54.655 --> 50:58.592
- I think people are wildly
underestimating the complexity

50:58.625 --> 51:00.661
of bringing automation
into this system.

51:03.730 --> 51:06.099
My name is Christopher Hart.
I am the former Chairman

51:06.133 --> 51:09.169
of the National Transportation
Safety Board.

51:09.203 --> 51:11.104
The NTSB is the federal agency

51:11.138 --> 51:12.639
that was created
to investigate

51:12.673 --> 51:14.708
transportation accidents
and make recommendations

51:14.741 --> 51:16.109
to try to prevent
the accidents

51:16.143 --> 51:18.679
from happening again.

51:18.712 --> 51:21.315
When I first heard
about that Tesla crash,

51:21.348 --> 51:24.318
I knew enough about automation
from my own aviation experience

51:24.351 --> 51:26.587
that I knew it was not gonna be
as simple as people thought.

51:27.588 --> 51:31.258
It took a year-plus
to investigate.

51:31.291 --> 51:34.461
Then, September 2017,
there was a public hearing.

51:34.494 --> 51:35.696
- Welcome to the boardroom

51:35.729 --> 51:37.731
of the National Transportation
Safety Board.

51:37.764 --> 51:40.434
We were very curious
about this particular crash.

51:40.467 --> 51:44.671
And the further we got into it,
the more we started realizing

51:44.705 --> 51:46.540
that, wow,
there are a lot of issues here

51:46.573 --> 51:48.275
that really need
to be looked at.

51:48.308 --> 51:49.610
It is our sincere hope

51:49.643 --> 51:52.613
that the lessons learned
from this tragedy

51:52.646 --> 51:56.016
can help prevent
future tragedies.

51:56.049 --> 52:00.654
An accident is rarely
the result of just one factor.

52:00.687 --> 52:04.191
In this crash, one would be,
of course, the truck driver

52:04.224 --> 52:08.061
pulling across the lane,
when he shouldn't have.

52:08.095 --> 52:11.231
But I would say that there was
also the automation complacency

52:11.265 --> 52:14.434
associated with the design
of the Tesla vehicle.

52:16.203 --> 52:17.437
For up to ten seconds,

52:17.471 --> 52:19.339
that there would have been
a line of sight

52:19.373 --> 52:21.708
between this Tesla
and the vehicle

52:21.742 --> 52:23.377
that was crossing
in front of him,

52:23.410 --> 52:27.548
there was the opportunity
to avoid this crash.

52:27.581 --> 52:30.517
We could not determine
exactly what he was doing

52:30.551 --> 52:33.654
in this crash.

52:33.687 --> 52:35.289
We certainly heard
those rumors

52:35.322 --> 52:38.058
about the driver
watching videos.

52:38.091 --> 52:40.794
But we had no evidence
of that at all.

52:40.827 --> 52:43.397
Did you find any evidence
at all

52:43.430 --> 52:45.065
that the driver of the Tesla

52:45.098 --> 52:48.202
may have been watching a movie
while driving this car?

52:48.235 --> 52:50.103
- We looked through his laptop,

52:50.137 --> 52:53.273
and there was no movies
on that laptop.

52:53.307 --> 52:57.177
- We, at the NTSB, really feel
like the drivers

52:57.211 --> 53:01.682
have the tendency to disengage
when the Autopilot

53:01.715 --> 53:04.751
is engaged
with the Tesla vehicle.

53:04.785 --> 53:06.620
Complacency creeps
in over time,

53:06.653 --> 53:09.156
and you develop overconfidence
with the system.

53:09.189 --> 53:12.192
- I was concerned about the use
of the term "Autopilot,"

53:12.226 --> 53:13.527
because there are
too many people

53:13.560 --> 53:15.028
who construe
the term "Autopilot"

53:15.062 --> 53:18.332
to mean human-engagement
no longer necessary.

53:18.365 --> 53:20.300
- They advise you to keep your
hands on the steering wheel

53:20.334 --> 53:21.702
when using the auto-steer,

53:21.735 --> 53:25.305
but as we're in testing,
you really don't need to.

53:25.339 --> 53:27.374
[beeping]
- The Autopilot

53:27.407 --> 53:28.775
is supposed to have a system

53:28.809 --> 53:32.379
where it can detect
driver engagement.

53:32.412 --> 53:33.780
There were periods
of time--

53:33.814 --> 53:36.283
almost of six minutes--
where his hands

53:36.316 --> 53:38.685
were not even detected
to be on the steering wheel.

53:38.719 --> 53:41.588
We felt that the system
of determining

53:41.622 --> 53:46.193
driver engagement was poor.

53:46.226 --> 53:48.095
- Another issue is
at that time,

53:48.128 --> 53:49.763
no manufacturer had a system

53:49.796 --> 53:52.366
to reliably sense
crossing traffic.

53:52.399 --> 53:54.334
That's why these systems
are supposed to be used

53:54.368 --> 53:57.604
only on roads that
don't have crossing traffic.

53:57.638 --> 54:00.641
- This road, Highway 27A,
in Florida,

54:00.674 --> 54:04.244
was not a limited access road.
But the question is,

54:04.278 --> 54:07.047
if the system is not supposed
to be operated

54:07.080 --> 54:10.083
on anything
other than a highway,

54:10.117 --> 54:13.587
why does the system allow it
to be operated

54:13.620 --> 54:16.356
in other types of roadways?

54:16.390 --> 54:19.560
It's like having a swimming
pool without a fence around it.

54:19.593 --> 54:22.229
It's a--it's an attractive
nuisance.

54:22.262 --> 54:25.265
Tesla allowed the driver
to use the system

54:25.299 --> 54:28.268
outside of the environment
for which it was designed.

54:28.302 --> 54:32.105
The result was a collision
that, frankly,

54:32.139 --> 54:33.307
should have never happened.

54:35.375 --> 54:38.045
- The ultimate paradox is that
the better the automation gets

54:38.078 --> 54:40.547
after removing the human,
the more challenging

54:40.581 --> 54:44.718
the human-automation
interface issues become.

54:44.751 --> 54:46.220
While the human is the most

54:46.253 --> 54:47.588
unpredictable
and variable part

54:47.621 --> 54:50.090
of the whole system,
it is also, at the same time,

54:50.123 --> 54:51.758
the most adaptable part
of the system

54:51.792 --> 54:54.728
when you need adaptation.

54:54.761 --> 54:56.496
I think Elon is an IT wizard,

54:56.530 --> 54:59.199
and I think that IT wizardry
is going to help us

54:59.233 --> 55:01.702
get where we want to go,
but we need to do it in a way

55:01.735 --> 55:04.438
that encompasses
the human element as well.

55:04.471 --> 55:06.373
- I think that
the manufacturers

55:06.406 --> 55:12.312
have a role in preventing
this automation complacency.

55:12.346 --> 55:15.749
You can't buy a production
model self-driving car

55:15.782 --> 55:19.052
from any automobile
maker today.

55:19.086 --> 55:21.788
Anyone who says that you can
is misleading you,

55:21.822 --> 55:24.591
and anyone who leaves
that impression

55:24.625 --> 55:26.727
is leaving
the wrong impression.

55:29.563 --> 55:32.733
To Tesla, we issued several
recommendations--

55:32.766 --> 55:36.370
basically,
do not allow the system

55:36.403 --> 55:38.071
to be operated on roadways

55:38.105 --> 55:41.141
where it's not designed
to be operated.

55:41.175 --> 55:44.211
And another recommendation
was you need a better way

55:44.244 --> 55:46.413
of determining
driver engagement.

55:46.446 --> 55:50.684
I do feel that if those recs
are accomplished,

55:50.717 --> 55:52.152
safety will be improved.

55:53.353 --> 55:54.521
- Tesla releasing a statement

55:54.555 --> 55:57.724
saying customer safety
comes first.

55:57.758 --> 56:00.594
- Boulder Crest is a nonprofit
that takes care

56:00.627 --> 56:03.096
of men and women
who are suffering with PTSD.

56:05.365 --> 56:07.134
The building
we're standing in today

56:07.167 --> 56:09.603
is the Josh Brown Center
for Innovation.

56:09.636 --> 56:11.638
We had this great
dedication ceremony

56:11.672 --> 56:13.307
the day we opened this.

56:13.340 --> 56:14.675
The family came back to us

56:14.708 --> 56:17.077
with this amazing paragraph
that they wanted

56:17.110 --> 56:20.747
the Director of the Boulder
Crest Institute to read.

56:20.781 --> 56:24.585
- Joshua believed, and our
family continues to believe,

56:24.618 --> 56:26.787
that the new technology
going into cars

56:26.820 --> 56:28.522
and the move
to autonomous driving

56:28.555 --> 56:30.591
has already saved many lives.

56:30.624 --> 56:32.759
Change always comes
with risks,

56:32.793 --> 56:34.494
and zero tolerance for deaths

56:34.528 --> 56:38.232
would totally stop innovations
and improvements.

56:38.265 --> 56:41.301
Nobody wants tragedy
to touch their family.

56:41.335 --> 56:43.704
But expecting to identify
all limitations

56:43.737 --> 56:45.506
of an emerging technology,

56:45.539 --> 56:49.209
and expecting perfection
is not feasible either.

56:49.243 --> 56:51.278
- And that, to me, just--
I mean, it--

56:51.311 --> 56:53.347
I think it brought tears
to everybody in that audience

56:53.380 --> 56:55.182
that knew Josh Brown.

56:55.215 --> 56:58.018
- Part of Joshua's legacy
is that the accident

56:58.051 --> 56:59.286
drove additional improvements,

56:59.319 --> 57:02.055
making the new technology
even safer.

57:02.089 --> 57:05.058
Our family takes solace
and pride in the fact

57:05.092 --> 57:08.061
that our son is making
such a positive impact

57:08.095 --> 57:10.564
on future highway safety.

57:10.597 --> 57:12.099
- We all sat there and thought,

57:12.132 --> 57:15.769
we have to learn a lesson
from what happened.

57:15.802 --> 57:17.504
When you think of somebody
like Josh,

57:17.538 --> 57:19.306
who was on that leading edge,

57:19.339 --> 57:22.042
he was gonna test that car.

57:22.075 --> 57:23.677
I think there's
a false sense of security

57:23.710 --> 57:26.580
when you put these options
in front of people.

57:35.471 --> 57:36.605
- Wouldn't hurt to have
more love in the world.

57:36.639 --> 57:37.907
- How you gonna fix that?

57:37.940 --> 57:39.341
You have a love machine
you're working on?

57:39.375 --> 57:40.476
[laughter]

57:40.509 --> 57:44.046
- No, but probably spend
more time with your friends

57:44.079 --> 57:46.882
and less time on social media.

57:49.018 --> 57:51.520
I mean, the only thing
I've kept is Twitter,

57:51.554 --> 57:53.255
because I kinda, like,
need some means

57:53.289 --> 57:55.524
of getting a message out,
you know?

57:56.826 --> 57:59.762
- I think Elon Musk
definitely understands

57:59.795 --> 58:01.030
the power of his celebrity.

58:01.063 --> 58:04.633
- Elon, what do you think about
dogecoin going crazy right now?

58:04.667 --> 58:06.936
[people shouting]

58:06.969 --> 58:09.839
- I think that's part of
how he operates.

58:09.872 --> 58:11.907
That's why he's on Twitter
all the time.

58:11.941 --> 58:15.911
- You use your tweeting to
kind of get back at critics.

58:15.945 --> 58:18.314
- Rarely.
- You kinda have little wars

58:18.347 --> 58:19.381
with the press.

58:19.415 --> 58:20.749
- Twitter is a war zone.

58:20.783 --> 58:22.852
- He sort of
doesn't have a filter.

58:22.885 --> 58:24.754
- Elon Musk
was on Twitter today

58:24.787 --> 58:25.955
calling one of the divers

58:25.988 --> 58:28.491
in that cave rescue
a pedophile.

58:28.524 --> 58:30.693
- Elon Musk shook up
the stock market

58:30.726 --> 58:32.294
this afternoon with
a tweet that read,

58:32.328 --> 58:34.997
"I'm considering
taking Tesla private."

58:35.030 --> 58:37.366
- I think it kinda
goes both ways.

58:37.399 --> 58:40.536
He can say things, and he can
get people believing them.

58:43.339 --> 58:45.608
- New tonight at 5:00,
Tesla has published

58:45.641 --> 58:48.043
its first quarterly
safety report.

58:48.077 --> 58:50.913
- In 2018,
Tesla started releasing

58:50.946 --> 58:53.916
these Autopilot
safety statistics,

58:53.949 --> 58:56.552
and have continued
to release data.

58:56.585 --> 58:58.554
On the surface,
they looked like

58:58.587 --> 59:00.022
they presented a good picture.

59:00.055 --> 59:01.924
- We publish the safety stats,
like, basically,

59:01.957 --> 59:06.262
miles driven on Autopilot
and miles driven manually.

59:06.295 --> 59:07.797
It was a factor
of ten difference.

59:07.830 --> 59:09.298
This is not subtle.

59:09.331 --> 59:12.735
- But it was just
broad numbers.

59:12.768 --> 59:15.671
It's not really a fair
comparison to say Teslas

59:15.704 --> 59:18.541
are dramatically safer than
all other cars on the road,

59:18.574 --> 59:20.509
because all other cars
on the road

59:20.543 --> 59:22.511
can include
20-year-old vehicles

59:22.545 --> 59:24.647
that are not in good repair.

59:24.680 --> 59:27.750
- If you think about the miles
that Tesla drives on Autopilot,

59:27.783 --> 59:29.885
almost all those are gonna be
freeway cruising miles.

59:29.919 --> 59:31.887
Those miles
are incredibly safe.

59:31.921 --> 59:34.390
City streets, parking lots,
things like that,

59:34.423 --> 59:36.292
those are much more likely
to have incidents.

59:38.294 --> 59:39.795
I believe that
they're presenting data

59:39.829 --> 59:41.397
that makes them look the best,

59:41.430 --> 59:43.899
that is still
technically accurate.

59:46.335 --> 59:49.505
- It's Tesla and Elon Musk
providing data

59:49.538 --> 59:51.874
to support
their point of view,

59:51.907 --> 59:53.776
but that's not a full picture.

59:53.809 --> 59:55.811
I don't think that
gives you enough data

59:55.845 --> 59:57.279
to really make a judgment.

59:57.313 --> 59:59.381
- People can say, "Oh, well,
you're playing

59:59.415 --> 1:00:00.850
with the statistics."

1:00:00.883 --> 1:00:02.485
I'm like, we're not fiddling
with the statistics.

1:00:02.518 --> 1:00:05.020
The truth is that people
are actually not great

1:00:05.054 --> 1:00:08.524
at driving
these two-ton death machines.

1:00:08.557 --> 1:00:10.926
- Then, March of 2018--

1:00:10.960 --> 1:00:12.428
- Fatal crash and fire

1:00:12.461 --> 1:00:14.663
involving a Tesla
in Mountain View.

1:00:14.697 --> 1:00:19.969
- That's when the Walter Huang
crash happens in California.

1:00:20.002 --> 1:00:22.805
It was at a point
where the freeway splits,

1:00:22.838 --> 1:00:25.374
and the Autopilot
became confused,

1:00:25.407 --> 1:00:27.910
and he ran straight into
a concrete barrier.

1:00:27.943 --> 1:00:30.946
- 38-year-old Walter Huang
had a wife and two kids.

1:00:30.980 --> 1:00:35.050
- The NTSB is investigating
that fatal crash and fire.

1:00:35.084 --> 1:00:38.788
- Tesla was a party
to our investigation.

1:00:38.821 --> 1:00:41.590
But one of the rules
of being a party

1:00:41.624 --> 1:00:44.593
is that the parties
can't release information

1:00:44.627 --> 1:00:47.563
about the active investigation.

1:00:47.596 --> 1:00:50.699
- Tesla released data saying
Walter Huang had his hands

1:00:50.733 --> 1:00:53.369
off the wheel for six seconds
before the crash.

1:00:54.537 --> 1:00:57.506
- I called Elon Musk and said
they would have to abide

1:00:57.540 --> 1:00:59.275
by our party agreement.

1:00:59.308 --> 1:01:00.843
And then a few days later,

1:01:00.876 --> 1:01:04.947
Tesla was releasing information
about the crash.

1:01:04.980 --> 1:01:06.882
- Tesla released another
statement that read,

1:01:06.916 --> 1:01:08.818
"The only way for this
accident to have occurred

1:01:08.851 --> 1:01:11.854
is if Mr. Huang was not
paying attention to the road."

1:01:11.887 --> 1:01:16.425
- Tesla needed to be removed
from that investigation.

1:01:16.459 --> 1:01:20.029
And so I called. Elon was,
I would say, argumentative.

1:01:20.062 --> 1:01:24.834
He indicated that
he was going to sue the NTSB.

1:01:24.867 --> 1:01:27.403
There was an attempt
to bully us into submission.

1:01:27.436 --> 1:01:29.772
But we didn't back down,
and he hung up on us.

1:01:31.707 --> 1:01:34.410
That night,
Tesla put out a press release

1:01:34.443 --> 1:01:38.380
saying that
they were resigning.

1:01:38.414 --> 1:01:40.850
- Tesla announced it's leaving
the investigation

1:01:40.883 --> 1:01:42.551
into the deadly crash,

1:01:42.585 --> 1:01:43.486
but the NTSB says

1:01:43.519 --> 1:01:46.756
it kicked the electric car
maker out first.

1:01:46.789 --> 1:01:50.259
- It was sort of like,
"You can't fire me, we quit"

1:01:50.292 --> 1:01:51.627
sort of a thing.

1:01:51.660 --> 1:01:53.896
- The system worked
as described,

1:01:53.929 --> 1:01:55.965
which is that
it's a hands-on system.

1:01:55.998 --> 1:01:58.701
It is not
a self-driving system.

1:02:00.836 --> 1:02:04.874
♪ ♪

1:02:04.907 --> 1:02:06.976
- Today, we meet to consider
a collision

1:02:07.009 --> 1:02:10.279
involving a Tesla Model X SUV.

1:02:10.312 --> 1:02:12.815
♪ ♪

1:02:12.848 --> 1:02:15.751
We do know that
in the Mountain View crash,

1:02:15.785 --> 1:02:18.687
the driver was
engaged continuously

1:02:18.721 --> 1:02:20.823
with playing a video game.

1:02:20.856 --> 1:02:22.691
It would be easy to say
the driver

1:02:22.725 --> 1:02:24.326
was not acting responsibly.

1:02:24.360 --> 1:02:28.464
However, it also shows
that there's great potential

1:02:28.497 --> 1:02:32.635
for there to be this automation
complacency to creep in.

1:02:32.668 --> 1:02:36.038
In 2017, we issued
two recommendations

1:02:36.071 --> 1:02:39.442
to six automobile
manufacturers.

1:02:39.475 --> 1:02:44.747
And of the six, one
manufacturer has ignored us,

1:02:44.780 --> 1:02:48.584
and that manufacturer
is Tesla.

1:02:48.617 --> 1:02:51.887
All of our recommendations
are based on tragic events.

1:02:51.921 --> 1:02:55.291
And when someone doesn't
respond or doesn't act,

1:02:55.324 --> 1:02:56.459
that's heartbreaking,

1:02:56.492 --> 1:02:58.894
especially when you see
another accident

1:02:58.928 --> 1:03:00.763
that could have been prevented

1:03:00.796 --> 1:03:04.733
had those recommendations
been implemented.

1:03:04.767 --> 1:03:06.836
- What started as an ordinary
drive to work

1:03:06.869 --> 1:03:09.038
ended in tragedy
for a father and husband

1:03:09.071 --> 1:03:11.941
from suburban Lake Worth Beach
driving a Tesla.

1:03:11.974 --> 1:03:14.777
- In March of 2019,
the next fatality

1:03:14.810 --> 1:03:19.482
that we became aware of
was Jeremy Banner.

1:03:19.515 --> 1:03:23.486
- We saw the almost
identical crash

1:03:23.519 --> 1:03:25.521
that we saw
in the Joshua Brown case.

1:03:27.656 --> 1:03:30.693
You've got a Tesla
being operated on Autopilot.

1:03:30.726 --> 1:03:32.461
We've got a tractor-trailer

1:03:32.495 --> 1:03:36.031
that is pulling
across the road.

1:03:36.065 --> 1:03:39.902
We've got a driver does not
attempt any evasive steering.

1:03:39.935 --> 1:03:42.471
Does not attempt
any breaking action.

1:03:44.940 --> 1:03:47.743
And goes right under
the tractor-trailer,

1:03:50.312 --> 1:03:52.314
sheering the roof
off of the car,

1:03:54.416 --> 1:03:56.419
and killing the driver.

1:04:00.856 --> 1:04:02.458
- Where is the super
duper radar

1:04:02.491 --> 1:04:05.661
that Elon was talking
about in September 2016?

1:04:05.694 --> 1:04:09.765
♪ ♪

1:04:09.799 --> 1:04:12.668
Well, whatever they did
wasn't sufficient

1:04:12.701 --> 1:04:14.703
to ensure
it didn't happen again,

1:04:14.737 --> 1:04:17.306
'cause the exact
same crash happened.

1:04:21.377 --> 1:04:24.647
- Stationary objects are this
vexing problem in autonomy.

1:04:24.680 --> 1:04:27.383
And everybody that's developing
autonomous software

1:04:27.416 --> 1:04:28.851
has this problem.

1:04:28.884 --> 1:04:32.655
This is the one Achilles heel
that you continue to see.

1:04:32.688 --> 1:04:34.523
- I thought the self-driving
problem would be hard,

1:04:34.557 --> 1:04:36.659
but it's--it was harder
than I thought.

1:04:39.795 --> 1:04:44.467
- It may be that Autopilot
vehicles have fewer crashes.

1:04:44.500 --> 1:04:48.604
But we've continued to see
other crashes that happen

1:04:48.637 --> 1:04:51.874
because the system can't see
something in the road.

1:04:51.907 --> 1:04:54.577
- Nearly a dozen accidents
where a Tesla slammed

1:04:54.610 --> 1:04:56.479
into a parked
emergency vehicle.

1:04:56.512 --> 1:05:00.049
- If your company is supposed
to be putting safety first,

1:05:00.082 --> 1:05:03.385
and this well-respected
safety agency says,

1:05:03.419 --> 1:05:05.721
you know, there are these two
deficiencies in your system,

1:05:05.755 --> 1:05:07.590
you should address them,

1:05:07.623 --> 1:05:10.359
why wouldn't you address them?
Why wouldn't you fix them?

1:05:10.392 --> 1:05:12.361
- One of the biggest mistakes
people generally make--

1:05:12.394 --> 1:05:14.864
and I'm guilty of it, too--
is wishful thinking.

1:05:14.897 --> 1:05:17.500
You know, like,
you want something to be true

1:05:17.533 --> 1:05:18.701
even if it isn't true.

1:05:18.734 --> 1:05:20.503
And so you ignore
the real truth

1:05:20.536 --> 1:05:23.973
because of what
you want to be true.

1:05:24.006 --> 1:05:26.642
This is a very difficult
trap to avoid.

1:05:26.675 --> 1:05:30.579
♪ ♪

1:05:30.613 --> 1:05:32.748
- I think, for those of us
in the safety business,

1:05:32.782 --> 1:05:35.484
we would have liked to have
seen more regulations

1:05:35.518 --> 1:05:38.287
implemented to improve safety.

1:05:38.320 --> 1:05:40.423
I mean, it's horribly
frustrating.

1:05:40.456 --> 1:05:41.857
- The truth is companies
have always had

1:05:41.891 --> 1:05:44.760
an enormous amount of power,
in terms of the technology

1:05:44.794 --> 1:05:47.530
in the vehicles
that they put on the road.

1:05:47.563 --> 1:05:49.298
- Honestly, I worry
that the government

1:05:49.331 --> 1:05:51.934
cannot keep up
with the technology.

1:05:51.967 --> 1:05:53.502
I don't think
in a situation like this

1:05:53.536 --> 1:05:57.039
we want to necessarily
inhibit innovation.

1:05:57.072 --> 1:05:59.442
But when innovation
is implemented,

1:05:59.475 --> 1:06:02.344
we have to make sure
that it's done safely.

1:06:02.378 --> 1:06:05.481
Or it's going to be
the Wild West out there.

1:06:10.753 --> 1:06:13.722
[light music]

1:06:13.756 --> 1:06:15.891
♪ ♪

1:06:17.466 --> 1:06:18.867
- When you think full
self-driving,

1:06:18.900 --> 1:06:20.369
you think hands off the wheel.

1:06:20.402 --> 1:06:21.970
You don't have to worry
about anything.

1:06:22.004 --> 1:06:25.507
You can listen to music
and read a book, whatever.

1:06:25.540 --> 1:06:29.378
I believe the first full video
we saw was, like, in 2016.

1:06:29.411 --> 1:06:31.279
I thought we're already here.

1:06:31.313 --> 1:06:35.183
So, yeah, it was very,
very exciting at the time.

1:06:35.217 --> 1:06:36.418
A couple years later,

1:06:36.451 --> 1:06:39.121
I purchased
the full self-driving.

1:06:39.154 --> 1:06:41.390
I now kind of make
a distinction.

1:06:41.423 --> 1:06:44.326
I think Tesla makes
great electric vehicles.

1:06:44.359 --> 1:06:47.963
But I think their advertising
of certain Autopilot features

1:06:47.996 --> 1:06:50.232
have been--overpromising

1:06:50.265 --> 1:06:52.100
is probably the nicest way
to say it.

1:06:52.134 --> 1:06:54.002
- I almost view it as, like,
a solved problem.

1:06:54.036 --> 1:06:55.971
Like, we know exactly
what to do,

1:06:56.004 --> 1:06:57.372
and we'll be there
in a few years.

1:06:57.406 --> 1:07:00.042
- As far back as 2015,
Elon Musk was saying

1:07:00.075 --> 1:07:01.576
self-driving cars
were two years away.

1:07:01.610 --> 1:07:08.016
- I think we're basically
less than two years away

1:07:08.050 --> 1:07:09.318
from complete autonomy.

1:07:09.351 --> 1:07:11.286
- The time when someone
will be able

1:07:11.320 --> 1:07:13.855
to take their hands
off the wheel and go to sleep,

1:07:13.889 --> 1:07:15.457
how far away is that?
To do that safely?

1:07:15.490 --> 1:07:17.826
- I think that's about--
that's about two years.

1:07:17.859 --> 1:07:19.561
- The promise was
very aspirational,

1:07:19.594 --> 1:07:21.263
and probably not gonna happen.

1:07:21.296 --> 1:07:24.967
But Tesla and Elon made people
think it was gonna happen.

1:07:25.000 --> 1:07:29.137
- By end of next year,
self-driving will be

1:07:29.171 --> 1:07:33.976
at least 100%
to 200% safer than a person.

1:07:34.009 --> 1:07:36.845
If you buy a car that does not
have the hardware necessary

1:07:36.878 --> 1:07:39.147
for full self-driving,
it is like buying a horse.

1:07:39.181 --> 1:07:43.118
I'm extremely confident
of achieving full autonomy

1:07:43.151 --> 1:07:47.389
and releasing it to the
Tesla customer base next year.

1:07:47.422 --> 1:07:49.524
- Some people say,
what does it matter?

1:07:49.558 --> 1:07:52.260
Well, I think it matters a lot.

1:07:52.294 --> 1:07:54.830
Do you want other
people on the roads

1:07:54.863 --> 1:07:56.832
buying this technology
and thinking

1:07:56.865 --> 1:07:59.901
that it's more powerful
than it really is?

1:07:59.935 --> 1:08:01.536
- I felt that
what I was being told

1:08:01.570 --> 1:08:03.372
that we were gonna do
didn't match

1:08:03.405 --> 1:08:05.874
what we actually did

1:08:05.907 --> 1:08:09.011
because Tesla has changed
the hardware on the car.

1:08:09.044 --> 1:08:11.380
They changed the computer.

1:08:11.413 --> 1:08:13.448
And now they're changing
the cameras.

1:08:13.482 --> 1:08:17.586
I think that that should
give someone pause

1:08:17.619 --> 1:08:19.287
when Tesla says they're
gonna do something else.

1:08:21.089 --> 1:08:24.526
- Elon Musk has officially
blown my mind yet again.

1:08:24.559 --> 1:08:27.863
In a recent tweet,
he talked about vision

1:08:27.896 --> 1:08:29.965
and using only vision
and no radar.

1:08:29.998 --> 1:08:32.134
- Taking the radar out
is literally

1:08:32.167 --> 1:08:35.137
going to make
the system better.

1:08:35.170 --> 1:08:37.272
- When I heard they were gonna
do cameras alone

1:08:37.306 --> 1:08:39.408
and get rid of radar,

1:08:39.441 --> 1:08:41.910
I was really taken aback.

1:08:41.943 --> 1:08:45.247
The whole rest of the industry
believes that you need cameras,

1:08:45.280 --> 1:08:48.283
radar, and lidar.

1:08:48.317 --> 1:08:50.986
Tesla's really
the only automaker

1:08:51.019 --> 1:08:53.922
who thinks that cameras alone
is a good idea.

1:08:53.955 --> 1:08:57.426
- You can absolutely be
superhuman with just cameras.

1:08:57.459 --> 1:09:01.229
- What Elon Musk is leaving
out of his analogy--

1:09:01.263 --> 1:09:03.365
comparing cameras
to eyes--

1:09:03.398 --> 1:09:08.036
is the fact that there is not
a brain behind those cameras.

1:09:08.070 --> 1:09:09.504
[beeping]

1:09:09.538 --> 1:09:12.007
We don't know
how to build a system

1:09:12.040 --> 1:09:13.542
that can behave
like the human brain.

1:09:13.575 --> 1:09:19.314
And what that means is full
autonomy may be decades away.

1:09:19.348 --> 1:09:22.351
[cheers and applause]

1:09:24.219 --> 1:09:26.855
- Anyone here use the full
self-driving beta?

1:09:26.888 --> 1:09:30.125
[cheering]
Great.

1:09:30.158 --> 1:09:31.193
The car will be able
to take you

1:09:31.226 --> 1:09:34.162
anywhere you want
with ultimately ten times safer

1:09:34.196 --> 1:09:36.231
than if you were
driving it yourself.

1:09:36.264 --> 1:09:39.401
It's gonna just completely
revolutionize the world.

1:09:39.434 --> 1:09:43.105
♪ ♪

1:09:43.138 --> 1:09:45.974
- There's a question around
whether Elon

1:09:46.008 --> 1:09:47.843
is acting cynically, right?

1:09:47.876 --> 1:09:49.911
Like, does he believe
in what he says?

1:09:49.945 --> 1:09:54.182
And is it okay as long as he
does believe in what he says?

1:09:54.216 --> 1:09:57.419
Some of it feels
intentional to me.

1:09:57.452 --> 1:10:00.155
There's, like, financing needs
that he needs to make.

1:10:00.188 --> 1:10:03.392
There are milestones
that Elon needs to hit,

1:10:03.425 --> 1:10:06.361
from an investor's perspective.

1:10:06.395 --> 1:10:09.965
- At times,
people misinterpret Elon.

1:10:09.998 --> 1:10:12.367
Oftentimes, there's--
when the goal is set,

1:10:12.401 --> 1:10:15.103
there's no capability
to deliver against that goal.

1:10:15.137 --> 1:10:17.306
You kind of need to believe
that, as a team,

1:10:17.339 --> 1:10:19.107
you're gonna
achieve the impossible.

1:10:19.141 --> 1:10:21.510
- I've had many conversations
with the Tesla Autopilot team.

1:10:21.543 --> 1:10:23.111
The reality of doing
the right thing matters

1:10:23.145 --> 1:10:24.980
more than the perception
of doing the right thing.

1:10:25.013 --> 1:10:28.417
- He's convinced that the
technology will be delivered.

1:10:28.450 --> 1:10:30.552
And I wouldn't necessarily bet
against him,

1:10:30.585 --> 1:10:32.421
because eventually
he does deliver.

1:10:33.622 --> 1:10:36.525
- Tesla says it's launching
its highly anticipated

1:10:36.558 --> 1:10:39.428
full self-driving software
later this week.

1:10:39.461 --> 1:10:41.229
- They're gonna open up
self-driving

1:10:41.263 --> 1:10:43.165
in America's cities.

1:10:43.198 --> 1:10:47.235
That would seem to be quite
a difficult thing to pull off.

1:10:47.269 --> 1:10:49.104
In a city?

1:10:51.540 --> 1:10:55.377
- So, this is a tricky thing
for beta.

1:10:55.410 --> 1:10:58.013
We are--this is a blind left.
There's a fence here.

1:10:58.046 --> 1:11:02.584
It can't see around.
So my car is inching forward.

1:11:02.617 --> 1:11:05.320
I feel honored
that I get to do this,

1:11:05.354 --> 1:11:09.324
and be, like, a little part
of this, you know, history.

1:11:09.358 --> 1:11:14.963
I stopped it because
it was inching out too far.

1:11:14.997 --> 1:11:17.165
There are definitely people
that do not agree

1:11:17.199 --> 1:11:20.402
with Tesla's approach.

1:11:20.435 --> 1:11:22.904
I don't feel that it's risky.

1:11:22.938 --> 1:11:28.377
I have never felt endangered,
okay?

1:11:28.410 --> 1:11:31.913
See, it's gonna miss this.
Can't do it.

1:11:31.947 --> 1:11:35.183
I can say that people
who buy a Tesla understand

1:11:35.217 --> 1:11:37.252
that it's not full
self-driving yet.

1:11:37.285 --> 1:11:42.024
And nobody is forcing anybody
to buy full self-driving.

1:11:42.057 --> 1:11:42.958
It's an option.

1:11:45.060 --> 1:11:47.229
- Full self-driving,
that's what I paid for,

1:11:47.262 --> 1:11:48.830
and I don't have it.

1:11:48.864 --> 1:11:51.500
I mean, it's right there
in the name of it, right?

1:11:51.533 --> 1:11:53.902
And I don't think
that's fair to say.

1:11:53.935 --> 1:11:56.505
Especially right now.

1:11:56.538 --> 1:11:59.508
Musk, I think he has
a huge responsibility.

1:11:59.541 --> 1:12:01.576
You know, I think he needs to
be a little bit more cautious

1:12:01.610 --> 1:12:04.179
about what he tells
his followers.

1:12:04.212 --> 1:12:08.116
- Wow. Oh, my God! Okay!

1:12:08.150 --> 1:12:11.386
- A lot of the work
in the tech industry proceeds

1:12:11.420 --> 1:12:14.856
with the central claim
of improving human lives

1:12:14.890 --> 1:12:17.960
through the methodical use
of our technologies.

1:12:17.993 --> 1:12:22.497
- Okay, did--
oh, God! Fuck! Jesus!

1:12:22.531 --> 1:12:26.234
That was one of the closest
calls we've ever had.

1:12:26.268 --> 1:12:30.839
- With the ongoing full
self-driving beta releases,

1:12:30.872 --> 1:12:31.840
there's quite a spectacle.

1:12:32.407 --> 1:12:33.976
- Is it just gonna run
this light?

1:12:34.009 --> 1:12:36.311
Holy shit,
it just ran that red light.

1:12:36.345 --> 1:12:38.914
- Here, we have a lot
of customers

1:12:38.947 --> 1:12:43.251
who are essentially standing in
for professional test drivers.

1:12:43.452 --> 1:12:46.054
- Ooh! Ooh!
- Oh, fuck! Oh shit!

1:12:46.088 --> 1:12:47.255
- Shit! We--

1:12:47.289 --> 1:12:48.857
- We hit that.
- We actually hit it.

1:12:48.890 --> 1:12:50.125
- We hit it.

1:12:50.158 --> 1:12:54.496
- With Tesla, an example
of scientific integrity,

1:12:54.529 --> 1:12:56.365
public responsibility,

1:12:56.398 --> 1:13:00.369
and reasoned and methodical
engineering development

1:13:00.402 --> 1:13:01.503
it is not.

1:13:01.536 --> 1:13:03.372
- With a software update,
you can actually

1:13:03.405 --> 1:13:06.375
make thousands
of people drive safer.

1:13:06.408 --> 1:13:07.976
Just with a software
update overnight.

1:13:08.010 --> 1:13:10.112
- Wow. That's actually--
- Yeah.

1:13:10.145 --> 1:13:11.913
- That's actually--
[beeping]

1:13:11.947 --> 1:13:15.450
- Fuck.
- [laughs]

1:13:15.484 --> 1:13:16.451
Fuck.

1:13:16.485 --> 1:13:19.054
- Are we gonna have to
cut that?

1:13:19.087 --> 1:13:26.061
♪ ♪
