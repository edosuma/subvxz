WEBVTT

00:19.300 --> 00:22.195
- TikTok has very
much become a way

00:22.220 --> 00:23.660
for the young generation

00:23.700 --> 00:25.600
to express ourselves
in every way.

00:27.113 --> 00:29.676
You can be yourself, you're
at home, you're filming,

00:29.700 --> 00:31.586
and there's always
gonna be like millions

00:31.610 --> 00:33.036
of people watching you.

00:33.540 --> 00:35.202
I like this one. Look and see.

00:35.382 --> 00:37.254
You never know when
you could blow up.

00:41.450 --> 00:43.036
- I think every
young kid's dream

00:43.060 --> 00:45.047
is to be successful online.

00:45.530 --> 00:47.326
The Chinese
social media platform,

00:47.350 --> 00:49.963
TikTok, has
changed the internet.

00:51.070 --> 00:54.346
It's become the most
popular app in the world.

00:54.370 --> 00:56.166
- It's fishing
videos, it's cooking.

00:56.190 --> 00:58.056
You can make skits,
singing, dancing.

00:58.080 --> 01:00.827
Literally everything you
can think of, TikTok have.

01:05.540 --> 01:07.306
- It's not an app on
their phone anymore.

01:07.330 --> 01:08.356
It's their livelihood.

01:08.380 --> 01:10.166
It's how they communicate
with their friends.

01:10.190 --> 01:11.636
It's how they see their world.

01:11.660 --> 01:13.976
That's a part that I
don't think everybody

01:14.000 --> 01:15.273
has adjusted to yet.

01:17.060 --> 01:20.546
- We're really at risk of having
generations of young people

01:20.570 --> 01:23.506
that performed identities
in response to something

01:23.530 --> 01:27.683
that a technology platform
prescribes to be the new normal.

01:29.250 --> 01:31.106
Behind the shiny dance videos,

01:31.130 --> 01:34.673
the platform is leading
people down dangerous paths.

01:36.130 --> 01:37.916
- I'd like to think that I
wouldn't have struggled

01:37.940 --> 01:40.349
with an eating disorder if I
hadn't downloaded TikTok.

01:41.840 --> 01:43.106
- My claim with TikTok

01:43.130 --> 01:47.146
is that they are harvesting
huge amounts of data illegally

01:47.170 --> 01:49.552
without the consent of
children or their parents.

01:50.990 --> 01:52.746
- If you just look at
TikTok in isolation,

01:52.770 --> 01:54.006
it seems innocuous.

01:54.030 --> 01:56.876
But it's really takes place
in this much larger context

01:56.900 --> 01:59.656
of data collection,
artificial intelligence,

01:59.680 --> 02:00.966
and a real effort by the Chinese

02:00.990 --> 02:04.483
to consolidate influence in
the region and across the globe.

02:06.150 --> 02:08.556
- Tonight on four
corners, TikTok.

02:08.580 --> 02:11.256
In a joint investigation
with Hack on Triple J,

02:11.280 --> 02:13.056
we're going down the rabbit hole

02:13.080 --> 02:15.176
to reveal the dark side of app.

02:15.200 --> 02:17.686
How the platform
censors political content

02:17.710 --> 02:20.046
and harvests children's data.

02:20.070 --> 02:23.886
And how the app's powerful
algorithm exposes people

02:23.910 --> 02:26.773
to misinformation and
dangerous content.

02:35.660 --> 02:37.456
- Hi, my name is Rory Eliza.

02:37.480 --> 02:38.925
And, then what?

02:40.416 --> 02:42.076
And what do you do?

02:42.100 --> 02:43.848
- I am a full-time TikToker.

02:53.250 --> 02:54.626
So in the morning I'll wake up,

02:54.650 --> 02:55.946
maybe eight
o'clock, nine o'clock.

02:55.970 --> 02:57.226
I'll check my phone,

02:57.250 --> 02:59.176
check if my videos
have done well,

02:59.200 --> 03:01.646
or how my followers are reacting

03:01.670 --> 03:03.723
to the content that
I've just posted.

03:07.060 --> 03:09.740
TikTok honestly, I get
so much love on there.

03:09.770 --> 03:12.136
It's so weird because
that's my biggest platform,

03:12.160 --> 03:13.736
is TikTok with 5
million followers.

03:13.760 --> 03:16.326
It's crazy to think
that 5 million people,

03:16.350 --> 03:18.376
that's people, it's
not just the number.

03:18.400 --> 03:20.216
And if you really think
about it's 5 million people

03:20.240 --> 03:21.640
that have tapped
that follow button.

03:23.230 --> 03:24.492
They're all just so friendly and

03:24.516 --> 03:25.656
they're kind of
like your family.

03:25.680 --> 03:27.483
It's just weird, like you
don't know these people,

03:27.507 --> 03:29.216
but they know so much about you

03:29.240 --> 03:31.481
that they treat you
like a family member.

03:43.750 --> 03:46.763
And on that note, welcome
to the new Rory Eliza.

03:47.900 --> 03:49.796
Rory Eliza is one of millions

03:49.820 --> 03:53.026
of young Australians
recording virtually every moment

03:53.050 --> 03:55.666
of their lives to get
famous on TikTok.

03:55.690 --> 03:57.466
- Get ready with me for a date.

03:57.490 --> 03:58.916
Yo, I chose an outfit, let's go.

03:58.940 --> 04:00.686
Transition, yeah.

04:00.710 --> 04:02.486
So I think every
young kid's dream

04:02.510 --> 04:04.776
is to, you know, be
successful online.

04:04.800 --> 04:08.116
So, I think there's
definitely a group

04:08.140 --> 04:10.276
where they all
wanna be influencers

04:10.300 --> 04:11.726
'cause it's kind of
like the in thing now.

04:11.750 --> 04:13.456
And I think that's
because of TikTok.

04:14.340 --> 04:15.700
TikTok has been downloaded

04:15.710 --> 04:18.663
more than 3 billion
times around the world.

04:21.710 --> 04:23.717
It's become a
cultural phenomenon.

04:23.742 --> 04:24.773
I'm 21 and just

04:24.798 --> 04:26.123
learned how to
do my own laundry.

04:26.210 --> 04:28.536
Some tomatoes and some cheese.

04:28.560 --> 04:31.320
Dude, no you're
gotta go late like, hey.

04:32.380 --> 04:33.553
Oh, okay, okay. Okay.

04:38.470 --> 04:40.570
Everything is about going viral.

04:41.850 --> 04:43.406
The dance, started by someone

04:43.430 --> 04:46.138
in their living room
and uploaded to TikTok,

04:47.720 --> 04:49.876
can turn into a
stadium full of people,

04:49.900 --> 04:51.586
performing it in unison.

04:58.165 --> 05:00.096
- I like how creative
you can be on it.

05:00.120 --> 05:02.293
Like it's just so fun
to go on that app

05:02.317 --> 05:04.138
and just express your real self.

05:13.970 --> 05:16.626
Rory started posting
comedic skits on TikTok

05:16.650 --> 05:18.153
and her following snowballed.

05:19.090 --> 05:21.827
- No worries. I'll scan that one
right through for you right now.

05:22.700 --> 05:24.436
This was her first viral video.

05:24.460 --> 05:26.746
It got nearly 14 million views.

05:31.050 --> 05:33.637
- How about some Peking duck?

05:33.870 --> 05:36.816
Oh yeah, but we actually
don't have the Peking duck.

05:36.840 --> 05:38.586
But we've got this
sneaking goose.

05:38.610 --> 05:40.102
What an odd name.

05:40.126 --> 05:42.756
It is pretty normal for a book.

05:42.780 --> 05:46.016
In 2019, Rory
decided to leave school

05:46.040 --> 05:48.166
to become a full time TikToker.

05:48.590 --> 05:50.623
- Wait, wait, is this a library?

05:51.510 --> 05:53.870
School was just one of those
things. I just was not good at.

05:54.320 --> 05:57.156
I decided to leave school
when I was in year 11

05:57.180 --> 05:58.536
and I was never there, you know.

05:58.560 --> 06:00.336
I was always in
Sydney doing meetings

06:00.360 --> 06:02.526
or presentations
for TikTok ends.

06:02.550 --> 06:04.576
I just wasn't there. And
when I would come to school,

06:04.600 --> 06:06.476
I would have no
idea what we're doing.

06:06.500 --> 06:09.093
'Cause you know, I've
been away for heaps of days.

06:10.440 --> 06:13.076
No worries at all. Thanks
for coming to our library.

06:13.100 --> 06:15.051
School, you can
go back and do it at TAFE.

06:15.075 --> 06:17.026
You can go back any
time and do it if you need it.

06:17.050 --> 06:19.106
But you may never get
this opportunity again.

06:19.130 --> 06:21.256
So, we just thought it
was worth leaving school

06:21.280 --> 06:22.796
and pursuing all the
business opportunities

06:22.820 --> 06:23.846
while they were there for her.

06:23.870 --> 06:26.416
- No worries at all. Thanks
for coming to our library.

06:26.680 --> 06:28.648
- How do you feel about the
fact that 5 million people are

06:28.672 --> 06:30.446
watching her content?

06:30.470 --> 06:31.927
- It's incredible.
It's even, when she

06:31.951 --> 06:33.606
goes live, there was
a time she went live

06:33.630 --> 06:36.226
and she had 22,000 people
watching her in her room.

06:36.250 --> 06:38.226
And I just sort of, in
my mind, goes back

06:38.250 --> 06:39.263
to Elton John concert here.

06:39.287 --> 06:40.756
And she had more
people watching her.

06:40.780 --> 06:42.436
Than we had at that
Elton John concert.

06:42.460 --> 06:44.226
And it kind of way
out that's happening

06:44.250 --> 06:46.336
in my daughter's
bedroom at the moment.

06:46.360 --> 06:49.849
It was a bit yeah, different.

06:54.130 --> 06:56.266
- Big fashion and
cosmetic brands

06:56.290 --> 06:59.126
started noticing Rory
success on TikTok

06:59.150 --> 07:01.553
and wanted to tap into
a growing audience.

07:07.149 --> 07:09.306
Companies sponsor
influences like Rory.

07:09.330 --> 07:13.083
And businesses pay TikTok
to advertise on the platform.

07:14.680 --> 07:17.553
This is central to the app's
lucrative business model.

07:19.110 --> 07:21.226
- In this work industry
being an influencer,

07:21.250 --> 07:23.436
you have to present
yourself as a brand, you know.

07:23.460 --> 07:25.566
We aren't really people
anymore, we're brands.

07:25.590 --> 07:26.926
We're selling
products for brands.

07:26.950 --> 07:28.750
So, you kind of
gotta look the part.

07:32.070 --> 07:34.494
The money involved
it's enough to live off.

07:34.518 --> 07:36.835
So, it's a pretty fair amount.

07:36.860 --> 07:38.416
I'm about in the
medium to high range

07:38.440 --> 07:39.926
of incomes in Australia.

07:39.950 --> 07:41.549
So yeah. Very, very
descent.

07:42.600 --> 07:44.246
- Well, it's hard not to
even be jealous sometimes

07:44.270 --> 07:46.016
'cause you look at
our life and you know,

07:46.040 --> 07:48.590
we get up and we go to
work and we come home.

07:49.905 --> 07:51.245
And she can earn money

07:51.270 --> 07:53.696
that can take us days
to earn in minutes.

07:53.720 --> 07:56.526
- I found myself
driving and just crying,

07:56.550 --> 07:58.666
having like a total breakdown.

07:58.690 --> 07:59.856
And I found myself having

07:59.880 --> 08:02.206
some really quite
nasty thoughts and-

08:02.230 --> 08:05.566
- Rory shares her
life with 5 million people.

08:05.590 --> 08:07.438
Even her lowest moments.

08:07.462 --> 08:08.994
- Why am I meant
to be on this earth.

08:09.018 --> 08:11.626
Like, why does no one like me?

08:11.650 --> 08:13.263
Why do I have no friends?

08:14.630 --> 08:17.459
But most days
she feels very alone.

08:17.483 --> 08:19.286
- Okay. That's
an old name for,

08:19.310 --> 08:22.176
Being away from people, it's
definitely lonely, you know.

08:22.200 --> 08:24.136
I film, oh, four videos a day.

08:24.160 --> 08:25.778
That's a good three
hours outta my day.

08:25.820 --> 08:27.100
And then I've got
another eight hours

08:27.111 --> 08:28.476
and I'm like, what the
heck am I gonna do

08:28.500 --> 08:30.412
for the rest of the day? Like
I can't ring out my friends.

08:30.436 --> 08:32.226
Like, y'all, want to hang
out? 'Cause they're at work.

08:32.250 --> 08:34.201
So it definitely
gets lonely at times.

08:34.230 --> 08:35.726
And you know,
sometimes if you're reading

08:35.750 --> 08:38.006
the hate comments
and the stress load,

08:38.030 --> 08:39.386
it can be so much for your body

08:39.410 --> 08:41.856
and you're just overwhelmed
and you're lonely.

08:41.880 --> 08:43.984
So that can also
creep into depression.

08:44.008 --> 08:45.294
- Catherine hasn't
had a question.

08:45.318 --> 08:47.953
I'm happy to return to you
but let's just keep it civil.

08:47.977 --> 08:48.977
Andrew?

08:50.860 --> 08:51.860
Catherine.

08:55.860 --> 08:58.106
With people stuck
at home during lockdown,

08:58.130 --> 08:59.896
desperate for entertainment.

08:59.920 --> 09:03.660
TikTok became the world's
most downloaded app in 2020.

09:07.010 --> 09:09.779
And it's continued to
hold that title this year.

09:13.172 --> 09:17.416
- TikTok in Australia has
seen the same kind of bump

09:17.440 --> 09:19.663
in 2020 as elsewhere
in the world.

09:23.280 --> 09:24.306
In October of 2020, there were

09:24.330 --> 09:26.406
an estimated 2.5
million users on TikTok.

09:26.430 --> 09:29.230
Which was about a 50% growth
from earlier on in the year.

09:41.863 --> 09:43.522
Of the popular
social media apps,

09:43.547 --> 09:45.545
TikTok is the most addictive.

09:46.030 --> 09:48.966
Late TikTok advertising
data shows users spend

09:48.990 --> 09:52.213
an average of an hour and
a half on the app each day.

09:54.270 --> 09:56.688
- You know it's like 8:00 PM
and I'm watching and watching

09:56.712 --> 09:59.216
and then I look up at
my clock and it's 2:00 AM.

09:59.434 --> 10:01.394
And I'm like, where the
heck did those hours go?

10:01.420 --> 10:03.380
It's cause this, um, "For
You" page is so addictive.

10:03.390 --> 10:05.174
It's just so spot on.

10:09.290 --> 10:12.090
TikTok's algorithm
is its most valuable asset.

10:14.610 --> 10:17.296
It's designed to
determine your interests

10:17.320 --> 10:19.406
and send you
personalized content

10:19.430 --> 10:22.086
to keep you on the app
for as long as possible.

10:22.110 --> 10:23.186
- I went and saw my mama.

10:23.210 --> 10:25.226
And I went and got my
hair done, as well just to-

10:25.250 --> 10:28.656
- TikTok works by
recommending content to you

10:28.680 --> 10:30.976
through your
activity on the app.

10:31.000 --> 10:33.506
So the more that you
scroll through the app,

10:33.530 --> 10:35.176
the better the
recommendations are tailored

10:35.200 --> 10:36.783
to your specific interests.

10:37.850 --> 10:40.806
Rather than selecting
content that you want to watch

10:40.830 --> 10:43.231
like you would on
YouTube or on Netflix.

10:43.600 --> 10:47.216
You primarily access
content through one main feed,

10:47.240 --> 10:49.185
which is called the For
You page on TikTok.

10:49.450 --> 10:51.936
Which is essentially just
an endlessly scrolling,

10:51.960 --> 10:55.266
algorithmically
curated feed of videos

10:55.290 --> 10:57.543
that refreshes each
time you open the app.

10:58.947 --> 11:00.696
As soon as
you sign up to TikTok,

11:00.720 --> 11:02.476
the app starts collecting data

11:02.500 --> 11:05.676
about you, your
location, gender, and age,

11:05.700 --> 11:08.726
and also your facial data
to figure out who you are

11:08.750 --> 11:10.863
and what kind of
videos you want to see.

11:11.730 --> 11:15.703
- Your face is a form
of biometric information.

11:15.727 --> 11:19.475
And your face can be
analyzed to distinguish a range

11:19.500 --> 11:21.860
of personality and
demographic traits.

11:24.590 --> 11:26.336
TikTok collects your facial data

11:26.360 --> 11:29.746
every time you make a video
or use a filter on the app.

11:29.770 --> 11:33.816
And can even access photos
and videos saved on your phone

11:33.840 --> 11:35.930
that aren't being
used on the platform.

11:36.680 --> 11:40.686
To understand how an app
like TikTok interprets that data

11:40.710 --> 11:42.656
scientists in Melbourne
have developed

11:42.680 --> 11:44.706
what's called a
biometric mirror.

11:45.160 --> 11:46.866
- So biometric
mirror for instance,

11:46.890 --> 11:49.486
is trained by way of
artificial intelligence

11:49.510 --> 11:51.466
to distinguish how
intelligent you are,

11:51.490 --> 11:54.596
how attractive, how
weird, how responsible

11:54.620 --> 11:57.723
and how emotionally
unstable you are.

11:58.900 --> 12:00.366
The interesting thing
there is of course,

12:00.390 --> 12:02.756
is that biometric mirror
bases it's assumptions

12:02.788 --> 12:05.115
on a single
snapshot of your face.

12:05.140 --> 12:07.936
So all of these assumptions
are generated based

12:07.960 --> 12:10.606
on the exact
appearance of your face

12:10.630 --> 12:13.653
at that exact microsecond
that the photo has been taken.

12:14.834 --> 12:17.356
The TikTok algorithm
might read your face

12:17.380 --> 12:19.906
and think that you are dealing

12:19.930 --> 12:22.456
with a significant
mental health challenge.

12:22.480 --> 12:25.346
You might be
presented with videos

12:25.370 --> 12:27.726
that are created by
users with-going through

12:27.750 --> 12:29.946
a similar challenge
at that time.

12:29.970 --> 12:34.076
And it might really create a
very colored worldview for you

12:34.100 --> 12:35.516
where it's really hard to deal

12:35.540 --> 12:37.716
with your mental health
challenge at that time.

12:44.980 --> 12:47.636
Lauren Hemings
is studying to be a midwife.

12:47.660 --> 12:49.544
She used to spend
her uni breaks,

12:49.568 --> 12:51.265
scrolling through TikTok.

12:51.880 --> 12:53.896
- I think it was
quarantine boredom

12:53.920 --> 12:56.863
that kind of motivated
me to download it.

12:57.950 --> 12:59.276
It was quite an innocent hope

12:59.300 --> 13:01.376
of just getting a
good laugh, really.

13:01.400 --> 13:03.426
You know, like
getting funny videos

13:03.450 --> 13:05.633
and seeing what was on it.

13:06.870 --> 13:08.136
I never had the intention

13:08.160 --> 13:09.716
of making TikToks
or sharing them.

13:09.740 --> 13:13.045
It was more just kind of from
the viewpoint of a viewer.

13:13.820 --> 13:15.046
Lauren started following

13:15.070 --> 13:17.679
a popular fitness
influencer on the app.

13:20.100 --> 13:24.436
- There's one woman who had
like quite a similar body type

13:24.460 --> 13:28.486
to me and she'd expressed
that she was unhappy

13:28.510 --> 13:29.593
with that body type.

13:30.770 --> 13:33.136
And she had started tracking
calories over quarantine.

13:33.160 --> 13:36.003
She had lost a really, really
significant amount of weight.

13:39.260 --> 13:41.306
The algorithm
then flooded her feed

13:41.330 --> 13:44.283
with content promoting
unhealthy weight loss.

13:46.330 --> 13:48.516
- I was no longer saying
funny dance videos or anything.

13:48.540 --> 13:50.736
It was just like
this complete focus

13:50.760 --> 13:54.863
on that like fitness and
healthy lifestyle goal.

13:58.763 --> 14:01.366
- TikTok pushed Lauren
toward the popular trend

14:01.390 --> 14:05.303
of meticulously tracking how
many calories you eat in a day.

14:06.290 --> 14:09.453
Something researches, warn,
promotes disordered eating.

14:10.850 --> 14:12.746
The hashtag,
What I eat in a day,

14:12.770 --> 14:15.665
has more than 7
billion views on TikTok.

14:18.480 --> 14:20.056
- It turned into
like this obsession

14:20.080 --> 14:23.496
and I felt that I
could not eat anything

14:23.520 --> 14:26.526
without knowing how
many calories it contained

14:26.550 --> 14:28.796
and without meeting, you
know, my target number

14:28.820 --> 14:30.336
of calories throughout the day.

14:30.360 --> 14:32.516
There was a few months
where I didn't put anything

14:32.540 --> 14:34.673
into my mouth that
I had not weighed.

14:36.150 --> 14:38.356
Four months
after downloading TikTok,

14:38.380 --> 14:40.636
Lauren admitted to
her friends and family

14:40.660 --> 14:42.337
she had an eating disorder.

14:43.000 --> 14:44.806
- I'd like to think that I
wouldn't have struggled

14:44.830 --> 14:47.156
with an eating disorder if I
hadn't downloaded TikTok.

14:47.180 --> 14:48.236
I think, you know, TikTok

14:48.260 --> 14:51.783
was the main contributor
to the development of that.

14:53.470 --> 14:56.156
Young users are
increasingly turning to TikTok

14:56.180 --> 15:00.086
to find and spread information
on how to restrict food

15:00.110 --> 15:02.893
and hide their disordered,
eating from their families.

15:04.250 --> 15:06.916
- What they do is they
actually share content

15:06.940 --> 15:10.176
of what they go through and
what they have done for the day

15:10.200 --> 15:11.913
in the fascination
to become thin.

15:12.800 --> 15:14.286
So they would share recipes.

15:14.310 --> 15:16.526
They would share diet plans.

15:16.550 --> 15:19.549
They would share how
you need to be disciplined.

15:19.980 --> 15:23.620
For someone who's
vulnerable and desperate,

15:23.650 --> 15:26.286
they would follow
anyone's advice.

15:26.310 --> 15:28.306
None of this advice
is actually good

15:28.330 --> 15:31.396
because some of these
advice is, oh lick a pumpkin

15:31.420 --> 15:33.811
for your lunch, but don't eat.

15:34.600 --> 15:36.973
Drink a liter of water
and you should be fine.

15:37.900 --> 15:40.046
- I was super hesitant
to get on TikTok

15:40.070 --> 15:41.806
because I'd heard that
it was a really bad space

15:41.830 --> 15:42.956
for people with
eating disorders.

15:42.980 --> 15:45.006
Because the algorithm
knows everything

15:45.030 --> 15:46.916
and then it would
curate your feed

15:46.940 --> 15:48.485
to be interested
in that kind of stuff.

15:49.440 --> 15:51.906
Claire Benstead
has been in and out of hospital

15:51.930 --> 15:54.504
for anorexia for
more than five years.

15:54.590 --> 15:56.346
She decided to download TikTok

15:56.370 --> 15:59.613
to find support and to
promote her earrings business.

16:00.090 --> 16:01.736
- You want that support

16:01.760 --> 16:03.326
because it's such
an isolating illness.

16:03.350 --> 16:04.766
And there's so many
people in my life

16:04.790 --> 16:06.926
that don't get it and
don't understand it.

16:06.950 --> 16:09.286
Claire says the
TikTok algorithm identified

16:09.310 --> 16:11.556
she had an eating
disorder and she noticed

16:11.580 --> 16:15.436
an immediate change to the
types of videos on her feed.

16:15.460 --> 16:16.686
- So it went from
being, you know,

16:16.710 --> 16:18.726
my algorithm was, you
know, Australian humor

16:18.750 --> 16:21.536
and musical theater humor,
and all of that kind of stuff

16:21.560 --> 16:25.346
to just being eating
disorder content all the time.

16:25.370 --> 16:28.330
And as I got sicker and
I got more obsessive,

16:28.840 --> 16:30.746
all I could do was just
flick through my phone,

16:30.770 --> 16:33.692
and look at this footage.

16:34.220 --> 16:37.076
I spent hours on it
and just fixated on it.

16:37.100 --> 16:38.106
I wasn't recovering it all.

16:38.130 --> 16:39.723
I was actively relapsing.

16:40.520 --> 16:42.256
Claire was admitted to hospital.

16:42.280 --> 16:45.566
As part of her treatment, her
psychologists worked with her

16:45.590 --> 16:48.976
to remove the toxic
content from her TikTok feed

16:49.000 --> 16:52.326
by unfollowing accounts
and reporting videos.

16:52.350 --> 16:54.436
How long did it actually
take you to get rid

16:54.460 --> 16:56.875
of that eating disorder
content from your algorithm.

16:57.850 --> 16:58.858
Ages.

16:58.882 --> 17:01.126
Pretty much being in hospital,
so probably two months,

17:01.150 --> 17:02.510
it took me to
change the algorithm.

17:03.200 --> 17:04.796
When you're kind of
scrolling through like this-

17:04.820 --> 17:06.768
- Even while Claire was
showing me her

17:06.792 --> 17:08.436
cleaned up TikTok feed,

17:08.460 --> 17:11.659
videos about eating
disorders began reappearing.

17:12.020 --> 17:14.021
Hey, there we go.
Here's one right now.

17:14.540 --> 17:17.246
Just every five or six videos.

17:17.270 --> 17:21.246
And so, I'm in a good spot
that this doesn't trigger me.

17:21.270 --> 17:22.856
- So even though you're
saying not interested,

17:22.880 --> 17:24.586
it's still coming up?
- It's still coming up.

17:24.610 --> 17:27.086
If you report TikTok
videos, the company says

17:27.110 --> 17:30.046
its moderators then
decide whether to ban them.

17:30.070 --> 17:31.486
Which in turn is supposed

17:31.510 --> 17:34.076
to teach the algorithm
to stop featuring them.

17:34.100 --> 17:35.736
- I just say that
I'm not interested in that-

17:35.760 --> 17:38.676
- TikToks policies,
say the app bans content

17:38.700 --> 17:41.963
promoting, normalizing or
glorifying eating disorders.

17:41.980 --> 17:43.580
And you can
say that it's offensive,

17:43.588 --> 17:44.966
But when users like Claire,

17:44.990 --> 17:47.676
have reported those
videos, they were told

17:47.700 --> 17:50.026
they don't breach
any guidelines.

17:50.050 --> 17:51.946
- You would think that, you
know, something this serious

17:51.970 --> 17:53.476
and it's got the
highest mortality rate

17:53.500 --> 17:55.456
of any mental illness,
you would think that,

17:55.480 --> 17:57.056
that would be something
that you could report.

17:57.080 --> 17:58.556
Because it is promoting
those behaviors

17:58.580 --> 18:00.375
and it's making it worse.

18:05.940 --> 18:07.158
TikTok also says it

18:07.180 --> 18:09.295
bans pro eating
disorder hashtags

18:09.320 --> 18:11.776
so users can search
for those videos.

18:11.800 --> 18:13.496
And if they try to, a number

18:13.520 --> 18:15.356
for eating disorder
support service,

18:15.380 --> 18:18.756
the Butterfly Foundation
automatically pops up.

18:18.780 --> 18:20.823
But users find ways around it.

18:21.790 --> 18:25.486
- But the issue is now
that it's ever evolving.

18:25.510 --> 18:27.836
Like there's a hashtag
now that people

18:27.860 --> 18:29.356
with eating disorders use.

18:29.380 --> 18:31.106
And you would never guess that

18:31.130 --> 18:33.096
it was an eating
disorder hashtag.

18:33.120 --> 18:34.720
Like it's after a famous singer.

18:36.700 --> 18:40.046
So just changing them
to be completely irrelevant

18:40.070 --> 18:42.328
from what an eating disorder is.

18:42.670 --> 18:44.386
And so it's so hard
to escape now.

18:44.410 --> 18:46.496
And I think it's
really hard for TikTok

18:46.520 --> 18:47.818
to keep up with that all.

18:48.360 --> 18:51.066
- There are mechanisms in place

18:51.090 --> 18:52.446
to screen some of that content.

18:52.470 --> 18:55.646
But a lot of it is also reliant
on human moderation.

18:55.670 --> 18:58.026
And when you consider
the amount of videos

18:58.050 --> 19:00.039
and the volume that is
being uploaded to TikTok,

19:00.063 --> 19:02.176
it's a very difficult
task to imagine

19:02.200 --> 19:04.100
human moderators
can catch everything.

19:09.526 --> 19:12.286
Last year,
TikTok established a council

19:12.310 --> 19:14.366
of outside experts to advise

19:14.390 --> 19:16.773
the company about
content moderation.

19:17.730 --> 19:19.553
David Polgar is one of them.

19:20.940 --> 19:23.226
- As we know with great power
comes great responsibility.

19:23.250 --> 19:25.566
There's a lot of power
in TikToks algorithm.

19:25.590 --> 19:28.196
Therefore you have
to constantly be aware

19:28.220 --> 19:31.836
of how it's impacting
other individuals

19:31.860 --> 19:33.261
and other communities.

19:33.980 --> 19:37.060
I think comparatively
speaking TikTok

19:37.082 --> 19:39.886
has done a pretty decent job

19:39.910 --> 19:44.016
with being more
reflective on rabbit holes

19:44.040 --> 19:47.986
and how that can
affect individuals.

19:48.010 --> 19:53.010
But at the same time, you're
dealing with human behaviour.

19:53.180 --> 19:55.656
You're dealing with bad actors.

19:55.680 --> 19:58.106
You're dealing with
major differences

19:58.130 --> 20:02.653
of how people define appropriate
versus inappropriate.

20:02.790 --> 20:04.106
And we have this tricky kind

20:04.130 --> 20:07.013
of balancing act that's
constantly happening.

20:09.700 --> 20:13.380
- TikTok's business model
is built on creating a fun,

20:13.410 --> 20:16.356
glossy and glamorous
version of the world.

20:16.380 --> 20:19.526
And the company has been found
to strictly control content

20:19.550 --> 20:21.446
that doesn't fit
with that image.

20:21.470 --> 20:24.936
In March last year, TikTok
policy documents were leaked.

20:24.960 --> 20:27.456
Showing content
moderators were instructed

20:27.480 --> 20:29.796
to suppress posts by creators

20:29.820 --> 20:32.663
considered ugly,
poor or disabled.

20:36.460 --> 20:38.288
The documents said,
"Videos, including

20:38.312 --> 20:40.786
people who had chubby or obese

20:40.810 --> 20:42.096
with ugly facial looks,

20:42.120 --> 20:44.946
like too many wrinkles
or facial deformities

20:44.970 --> 20:47.806
and other disabilities
should be excluded."

20:47.830 --> 20:51.403
TikTok has said it no longer
engages in these practices.

20:55.899 --> 20:57.206
- I don't want to
admit it, but looks

20:57.230 --> 20:58.326
have a lot to do with it.

20:58.350 --> 21:00.706
And you know, we're
all secretly a bit vain.

21:00.730 --> 21:02.396
As much you don't
wanna admit it,

21:02.420 --> 21:04.806
you go for looks over
non-looks, you know.

21:04.830 --> 21:06.596
So I think looks definitely
have a lot to do with it.

21:06.620 --> 21:09.426
And if you look at all the
really big time influencers,

21:09.450 --> 21:10.546
they're all beautiful.

21:10.570 --> 21:12.259
Like, if you look at
all these influencers,

21:12.283 --> 21:14.376
they're all stunning, like
nothing wrong with them.

21:14.400 --> 21:16.865
So I think looks definitely
have a lot to do with it.

21:30.347 --> 21:31.968
Much of TikTok's popularity

21:31.992 --> 21:33.584
is driven by dance trends,

21:33.620 --> 21:35.826
choreographed by black creators

21:35.850 --> 21:38.302
and then copied
by white influencers.

21:40.290 --> 21:42.026
But black content makers say

21:42.050 --> 21:45.343
that the platform actively
discriminates against them.

21:47.220 --> 21:49.746
Think it's high
time we let black women

21:49.770 --> 21:52.126
on this app also be famous
for doing the bare minimum.

21:52.150 --> 21:54.836
Like I should be able
to just sit here in silence,

21:54.860 --> 21:56.006
and let y'all look at me

21:56.030 --> 21:58.830
and the next thing you know,
I have a million followers.

22:00.180 --> 22:01.540
- Petition for black
people for the rest

22:01.560 --> 22:03.206
of April to stop talking.

22:03.230 --> 22:04.856
- There have been instances

22:04.880 --> 22:08.116
of black creator
led mass walk offs

22:08.140 --> 22:09.756
from the platform
called Blackouts.

22:09.780 --> 22:11.166
Where on a certain day,

22:11.190 --> 22:12.726
black creators will
stop using the platform

22:12.750 --> 22:15.896
or urge other creators
to leave the platform

22:15.920 --> 22:19.466
because of TikToks inaction
and failure to respond to

22:19.490 --> 22:21.696
or engage with
some of the criticisms

22:21.720 --> 22:25.224
and the discourse that
black creators have raised.

22:25.294 --> 22:30.869
So if the company continues
to be reactive and responsive,

22:30.980 --> 22:33.826
rather than proactive and
really meaningfully engage,

22:33.850 --> 22:36.125
then these issues are
gonna continue to occur.

22:39.260 --> 22:41.356
- Often, it makes me
quite furious, I guess,

22:41.380 --> 22:42.886
'cause it's like
these black creators,

22:42.910 --> 22:45.526
they got talent, they're
out here dancing

22:45.550 --> 22:47.566
and showing what
they're capable of.

22:47.880 --> 22:50.246
So it's kind of very
much disappointing

22:50.270 --> 22:53.516
and hard on us when
we're out here expected

22:53.540 --> 22:55.976
to have all of these in
order to get the views

22:56.000 --> 22:57.956
in order to get the
likes and shares.

22:57.980 --> 23:00.066
But no matter how much we try,

23:00.090 --> 23:02.022
we're just not gonna get that.

23:08.620 --> 23:12.896
- Unice Wani is an 18 year
old TikTok creator from Perth.

23:13.010 --> 23:14.800
- I like this one.
Look and see.

23:15.120 --> 23:16.456
I feel like the more I go viral,

23:16.480 --> 23:20.496
the more I can basically
show the younger generation

23:20.520 --> 23:23.216
and show more
colored girls, I guess,

23:23.240 --> 23:27.016
or people out there like
I'm okay in my own skin

23:27.040 --> 23:28.726
and I love myself the way I am.

23:28.750 --> 23:31.236
I don't care what social
media says about me.

23:31.260 --> 23:34.146
What people on the other side
of the screen says about me.

23:34.170 --> 23:36.163
You can be yourself
at the end of the day.

23:36.668 --> 23:38.136
Let me quickly address this-

23:38.160 --> 23:39.326
- As her following grew,

23:39.350 --> 23:41.816
so did the hateful comments.

23:41.840 --> 23:44.816
And she decided to
confront the issue on the app.

23:44.840 --> 23:46.636
- So a majority of you
guys still feel the need

23:46.660 --> 23:49.226
to comment about my skin
color and about how dark I am

23:49.250 --> 23:51.616
and about how black, black,
black, black, black I am.

23:51.620 --> 23:52.654
Well, guess what?

23:52.679 --> 23:54.523
I'm black and I'm so proud.

23:57.891 --> 24:00.516
- Unice says often
her videos are hidden

24:00.540 --> 24:02.356
or muted from the TikTok feed.

24:02.380 --> 24:03.946
Meaning few people see them.

24:03.970 --> 24:05.917
A practice known
as Shadow Banning.

24:05.941 --> 24:07.617
- Are you pressed?

24:07.641 --> 24:09.147
Are you mad?

24:09.171 --> 24:10.598
Are you upset?

24:10.622 --> 24:11.622
Are you sad?

24:12.920 --> 24:14.076
Sorry, what?

24:14.100 --> 24:17.236
I guess you tend to
get a lot of shadow bans

24:17.260 --> 24:20.556
for speaking up about
stuff such as racism.

24:20.580 --> 24:21.866
Stuff you couldn't mention.

24:21.890 --> 24:24.476
One word, black,
could say all of this

24:24.500 --> 24:26.876
and your video could
get shadow banned.

24:26.900 --> 24:32.300
When you post a video,
the video, just it's on the app.

24:32.330 --> 24:34.536
It's just, you're not
gonna get any views for it.

24:34.560 --> 24:36.916
So you can see it. It's just
other people can't see it

24:36.940 --> 24:39.286
when they go onto
your account as well.

24:39.310 --> 24:42.509
So it's up there. It's just,
it's not going to get any views.

24:47.270 --> 24:49.506
Last year
TikTok creators noticed

24:49.530 --> 24:51.776
the algorithm was
suppressing posts

24:51.800 --> 24:55.113
with the hashtag Black
Lives Matter or George Floyd.

24:59.620 --> 25:04.316
- So word on the street
is that TikTok has banned

25:04.410 --> 25:06.169
the Black Lives Matter hashtag.

25:12.060 --> 25:14.332
One of those
creators was Sydney man,

25:14.357 --> 25:16.512
Paniora Nukunuku,
who had created

25:16.540 --> 25:18.900
a video using a pool table

25:18.930 --> 25:22.296
to explain the Black Lives
Matter issue to Australians.

25:22.320 --> 25:23.886
- This is a white
Australia table.

25:23.910 --> 25:25.796
And they pretty much
had 200 years head-start

25:25.820 --> 25:27.517
and they had established
everything in the country.

25:27.541 --> 25:29.476
So their break looks like this.

25:29.500 --> 25:32.455
Bro, can you get home
ownership in business?

25:32.500 --> 25:33.540
Beautiful.

25:33.552 --> 25:35.056
That was spicy.

25:35.080 --> 25:37.161
That blew up bigger
than I thought it would.

25:37.278 --> 25:38.635
I just need to put this here.

25:38.660 --> 25:39.806
Boy, what the,

25:39.830 --> 25:42.586
- Don't worry. It's trauma,
injustice and discrimination.

25:42.610 --> 25:44.056
But I said, sorry,
so it should be fine.

25:44.080 --> 25:45.230
So just go for it, bro.

25:46.520 --> 25:48.526
It was the biggest video
at the time that I've done.

25:48.540 --> 25:50.060
I think you're just
being lazy, hey.

25:50.085 --> 25:51.596
I don't know why.

25:51.620 --> 25:53.962
Oh, I do know why,
because it was good.

25:53.980 --> 25:55.361
I shouldn't look at
the camera, but I'm

25:55.385 --> 25:56.981
just really proud right now.

25:57.220 --> 25:58.396
Using these two cue balls,

25:58.420 --> 25:59.616
I'll explain to
you, that resulted

25:59.640 --> 26:01.136
in my account getting banned

26:01.160 --> 26:02.776
for like seven days.

26:02.800 --> 26:03.856
I don't know why.

26:03.880 --> 26:07.786
They claimed that my video
breached community guidelines,

26:07.810 --> 26:10.926
which is extremely vague
because there is no swearing,

26:10.950 --> 26:13.079
there is no explicit language.

26:13.103 --> 26:17.536
There's no nudity or
explicit like sexual stuff.

26:17.560 --> 26:20.139
None of that.
And my account got banned.

26:20.900 --> 26:22.566
- The Black Lives Matter
is trending on TikTok,

26:22.590 --> 26:24.976
which is ironic considering
how much time TikTok spends

26:25.000 --> 26:26.696
silencing the voices
of black creators.

26:26.720 --> 26:28.966
TikTok apologized
for suppressing hashtags,

26:28.990 --> 26:30.786
referring to Black Lives Matter,

26:30.849 --> 26:32.815
blaming a glitch
in the algorithm.

26:33.003 --> 26:34.803
- Let's take a moment
of silence for this man.

26:34.939 --> 26:37.019
- The company responded
with a new initiative

26:37.050 --> 26:40.056
for black creators called the
TikTok Black Creator Programme.

26:40.080 --> 26:42.926
I've spoken to creators
who had been approached

26:42.950 --> 26:46.566
for that programme, who
felt that it was lip service.

26:46.590 --> 26:49.836
It wasn't really a
well-meaning effort

26:49.860 --> 26:52.826
to engage with black voices
and engage with discourse

26:52.850 --> 26:54.800
that is important to
black communities.

26:56.840 --> 27:00.835
Paniora, has more than
180,000 followers on TikTok.

27:01.500 --> 27:03.996
He often posts about
living with a disability.

27:04.020 --> 27:05.326
- So growing up
with the fake leg,

27:05.350 --> 27:06.876
I always got in trouble
every time I park

27:06.900 --> 27:08.216
in my disabled spot.

27:08.240 --> 27:10.396
The first video I
did, was me going up

27:10.420 --> 27:13.516
to a pool and telling
my friends to record me,

27:13.540 --> 27:16.476
dip my fake leg in the
water to test the water out.

27:16.500 --> 27:18.236
It was a really dumb idea.

27:18.260 --> 27:19.816
But for some reason,
people loved it.

27:19.840 --> 27:21.606
And in this space
of eight hours,

27:21.630 --> 27:24.353
it hit about 780,000 views.

27:25.190 --> 27:29.486
If you have this many
followers and that many likes,

27:29.510 --> 27:30.916
it's 'cause you're pretty.

27:30.940 --> 27:32.986
If you have this many followers

27:33.010 --> 27:34.783
and the same amount of likes,

27:38.410 --> 27:39.410
you're just funny.

27:41.280 --> 27:44.106
Paniora ran into trouble
with the TikTok censors

27:44.130 --> 27:46.766
when he posted a
video of a confrontation

27:46.790 --> 27:48.296
with someone
who was telling him,

27:48.320 --> 27:50.896
he shouldn't have
a disability permit

27:50.920 --> 27:54.326
- So this old lady had
the nerve to ask me

27:54.350 --> 27:57.063
if this is my disability card.

27:58.900 --> 28:00.186
This,

28:00.210 --> 28:02.816
I wonder if this is enough.

28:02.840 --> 28:04.696
The video was taken down.

28:04.720 --> 28:07.906
TikTok said it breached the
app's community guidelines.

28:07.930 --> 28:10.606
Paniora appealed
and it was put back up.

28:10.630 --> 28:11.886
But he's had other videos

28:11.910 --> 28:14.456
about his disability
removed as well.

28:14.480 --> 28:15.796
- You don't need
to worry about it.

28:15.820 --> 28:18.020
The video got taken down
and I didn't even know it

28:18.030 --> 28:20.056
until I looked back
at the hashtags

28:20.080 --> 28:22.386
and decided to see which
videos that I've done

28:22.410 --> 28:24.808
have like made it to the
top and that wasn't there.

28:25.260 --> 28:28.386
I appealed it and I don't
know why that was taken down.

28:28.420 --> 28:29.656
Don't ever do that again.

28:29.820 --> 28:31.906
Do I feel like TikTok
is being racist?

28:31.930 --> 28:32.930
I don't know.

28:34.190 --> 28:36.602
Has TikTok been
hit up in the past,

28:36.660 --> 28:39.086
around the moderators being told

28:39.100 --> 28:44.580
to limit the exposure of
disabled people and ugly people?

28:44.590 --> 28:46.216
Yes. They've been
called out on that.

28:46.240 --> 28:47.426
Is this happening again?

28:47.450 --> 28:51.016
I hope not, but it
definitely feels like it has.

28:51.040 --> 28:54.186
We know
that to decolonize Palestine

28:54.210 --> 28:56.516
means also to decolonize-

28:56.540 --> 28:58.986
- I'll probably keep
moving, get some shots.

28:59.010 --> 29:00.016
In may of this year,

29:00.040 --> 29:03.406
Paniora posted a video
from a pro-Palestine rally.

29:03.430 --> 29:05.636
But TikTok's
algorithm flagged it.

29:05.660 --> 29:07.439
And it was instantly taken down.

29:09.950 --> 29:13.086
Other creators posting
TikToks about Palestine

29:13.110 --> 29:15.855
have said they've
experienced the same thing.

29:18.198 --> 29:20.856
- When TikTok started
removing my videos

29:20.880 --> 29:22.566
about the protests in regards

29:22.590 --> 29:25.506
to the Palestinian
situation, I was furious.

29:25.530 --> 29:29.216
I was like, why? There
is nothing in these videos

29:29.240 --> 29:33.066
that would justify,
like a removal.

29:33.090 --> 29:34.333
There really isn't.

29:34.710 --> 29:37.326
- One of the big
problems with TikTok

29:37.350 --> 29:42.046
and the unique nature
of its opaque algorithm,

29:42.070 --> 29:45.736
is that it's very
difficult to understand

29:45.760 --> 29:49.534
or to recognise when
censorship is taking place.

29:49.540 --> 29:51.140
People came together to try to-

29:51.167 --> 29:54.796
- So it is possible
for content on the app

29:54.820 --> 29:58.676
to be promoted or demoted
without anyone knowing.

29:58.700 --> 30:01.566
- I'm so sick and tired of
every social media platform

30:01.590 --> 30:03.366
silencing Palestinian voices.

30:03.390 --> 30:08.066
- But we also see evidence
of how content moderation

30:08.090 --> 30:09.616
that takes place in China.

30:09.640 --> 30:13.806
How that type of
thinking is still applied

30:13.830 --> 30:15.843
to TikTok outside of China.

30:18.591 --> 30:21.445
TikTok is owned by
Chinese start-up, ByteDance,

30:21.470 --> 30:25.098
which is believed to be
worth more than $250 billion.

30:25.490 --> 30:28.166
It's heavily regulated by
the Chinese government.

30:28.190 --> 30:30.847
And there's a Communist
Party Internal Committee

30:30.872 --> 30:34.696
in ByteDance, which ensures
the parties political goals

30:34.720 --> 30:37.009
are pursued alongside
the company's.

30:38.880 --> 30:40.976
- We have to be extra concerned

30:41.000 --> 30:45.006
about how apps like
TikTok can be used

30:45.030 --> 30:47.883
as a vector for censorship
and surveillance.

30:49.990 --> 30:52.386
- The Australian
Strategic Policy Institute

30:52.410 --> 30:54.566
did the first
academic investigation

30:54.590 --> 30:56.346
into censorship on TikTok,

30:56.370 --> 30:59.376
concluding the company
actively uses the algorithm

30:59.400 --> 31:02.660
to hide political speech
it deems controversial.

31:03.020 --> 31:05.616
The research was funded
by the US State Department

31:05.640 --> 31:08.566
and found anti-Russian
government videos

31:08.580 --> 31:12.035
as well as hashtags
about LGBTQI issues

31:12.060 --> 31:13.820
and the mass
detention of Uyghurs

31:13.860 --> 31:15.833
were among those
being suppressed.

31:18.510 --> 31:22.636
- The company has cooperated
with public security bureaus

31:22.660 --> 31:26.076
all throughout China
and including in Xinjiang.

31:26.100 --> 31:30.306
And that means that they work,

31:30.330 --> 31:33.176
they coordinate with
government agencies

31:33.200 --> 31:36.676
to ensure that the
information space in China

31:36.700 --> 31:39.966
is pumped full of
this propaganda.

31:39.990 --> 31:42.596
That shows a very rosy picture

31:42.620 --> 31:44.484
of what's happening in Xinjiang.

31:48.640 --> 31:51.296
In 2018, then CEO of ByteDance

31:51.320 --> 31:53.366
was forced to
publicly apologise.

31:53.390 --> 31:55.496
Saying one of the
company's platforms

31:55.520 --> 31:59.396
had gone against China's
core socialist values.

31:59.420 --> 32:02.986
- We have a very
clear public statement

32:03.010 --> 32:04.766
from the founder of ByteDance,

32:04.790 --> 32:08.786
that this is something that
he's committed to doing

32:08.810 --> 32:11.426
and to ensuring that
the company continues

32:11.450 --> 32:15.316
to push this type of propaganda,
certainly inside of China.

32:15.340 --> 32:18.676
Whether that is then extended
out to the rest of the world

32:18.700 --> 32:22.916
via apps like TikTok,
is another question.

32:22.940 --> 32:25.183
And it's something
worth watching.

32:26.190 --> 32:27.626
In a statement TikTok said,

32:27.650 --> 32:30.216
it does not moderate
or remove content

32:30.240 --> 32:32.086
based on political
sensitivities.

32:32.110 --> 32:34.516
And has never
content at the request

32:34.540 --> 32:35.906
of the Chinese government.

32:35.930 --> 32:37.976
It also said it
embraces diversity

32:38.000 --> 32:41.006
and denied it discriminates
against any creator

32:41.030 --> 32:42.943
or community on our platform.

32:46.730 --> 32:49.186
- We've known for a
better part of a decade,

32:49.210 --> 32:51.146
both here in the
US and in Australia,

32:51.170 --> 32:53.706
about the concerns
raised by the prevalence

32:53.730 --> 32:55.306
of Chinese
telecommunications companies.

32:55.330 --> 32:56.726
And so then the next
question became,

32:56.750 --> 32:58.996
well, what about all
these apps that have,

32:59.020 --> 33:00.906
of companies that are
headquartered in China?

33:00.930 --> 33:03.072
They're collecting tremendous
amounts of user data.

33:03.280 --> 33:06.233
They have access to
the devices of individuals.

33:07.440 --> 33:08.846
Jamil Jaffer is Founder

33:08.870 --> 33:11.996
of the National Security
Institute in Washington.

33:12.020 --> 33:16.016
And has advised the us
government on cyber-security.

33:16.040 --> 33:18.476
- In China, it's all the
central government,

33:18.500 --> 33:19.506
the Communist Party.

33:19.530 --> 33:21.926
There's no separation
between the branches.

33:21.950 --> 33:24.426
And so, when these
apps have all that data,

33:24.450 --> 33:26.006
it's much easier for
the Chinese government

33:26.030 --> 33:28.436
to simply obtain
access to that data.

33:31.320 --> 33:32.326
- My understanding is that,

33:32.350 --> 33:34.916
about a quarter of
the world's population

33:34.940 --> 33:37.316
is a member of TikTok
if I'm not mistaken.

33:37.340 --> 33:39.596
So that's obviously an
enormous amount of data

33:39.620 --> 33:40.676
that's being generated.

33:40.700 --> 33:43.006
That's being
handed over for free

33:43.030 --> 33:45.016
to that single social network

33:45.040 --> 33:46.856
that has pretty
much full control

33:46.880 --> 33:48.876
over what it does to the data.

33:48.900 --> 33:52.875
It might analyze it to
generate personalized content

33:52.900 --> 33:55.180
for you, but it might
also use that data

33:55.190 --> 33:58.026
to offer technology
products and services

33:58.050 --> 34:01.056
to other companies
moving forward in the future.

34:23.830 --> 34:25.476
- Hello, it's Avani in Sydney.

34:25.500 --> 34:26.726
How's it going?

34:26.750 --> 34:28.246
- Hi.

34:28.270 --> 34:29.836
Anne Longfield is England's

34:29.860 --> 34:31.764
former children's commissioner.

34:31.780 --> 34:33.650
Anne's interview, take one.

34:33.660 --> 34:36.300
- She's representing
millions of kids on TikTok

34:36.340 --> 34:39.650
in the UK and Europe in a class
action against the company.

34:39.950 --> 34:43.036
- My claim with TikTok
at the moment is that,

34:43.060 --> 34:46.216
they are harvesting huge
amounts of data illegally

34:46.240 --> 34:48.856
without the consent of
children or their parents.

34:48.880 --> 34:52.056
And they aren't
giving the right level

34:52.080 --> 34:55.016
of transparency about
what happens to that data,

34:55.040 --> 34:57.993
or actually what
that data includes.

35:01.600 --> 35:06.086
Almost a third of TikTok's
Australian users are under 14.

35:06.110 --> 35:08.666
Lawyers say TikTok
takes personal information

35:08.690 --> 35:11.836
like phone numbers, videos,
locations, and facial data

35:11.860 --> 35:13.896
from kids without their consent.

35:13.920 --> 35:17.416
As well as the photos and
videos recorded using TikTok,

35:17.440 --> 35:20.033
but not uploaded or
saved to the platform.

35:21.180 --> 35:25.216
- Given the level of data
and the lack of transparency

35:25.240 --> 35:27.306
around there, it's
difficult to imagine

35:27.330 --> 35:28.536
that this isn't just a kind of

35:28.560 --> 35:30.386
information gathering service,

35:30.410 --> 35:34.966
which is thinly veiled as some
kind of enjoyable platform,

35:34.990 --> 35:38.006
which appeals to young children.

35:38.030 --> 35:41.516
So the real incentive here,

35:41.540 --> 35:43.813
when you look at it
in really cold terms,

35:43.837 --> 35:47.596
seems to be, to gather
as much data as possible

35:47.620 --> 35:50.460
to really be able
to monetize that.

35:53.180 --> 35:55.676
TikTok's already
been fined millions of dollars

35:55.700 --> 35:59.113
in the US and South Korea
for harvesting children's data.

36:01.290 --> 36:04.136
The company restricted
app access for children

36:04.160 --> 36:08.196
and has taken down millions
of under-age users' accounts.

36:08.220 --> 36:10.855
There's been no legal
action in Australia.

36:12.530 --> 36:15.156
- I think that governments
do have a responsibility

36:15.180 --> 36:18.066
to intervene to
ensure that children

36:18.090 --> 36:20.546
are protected in whatever
kind of environment they're in.

36:20.570 --> 36:23.106
And you see those
protections and measures

36:23.130 --> 36:25.356
in terms of the
physical environment,

36:25.380 --> 36:28.376
in terms of their
safety, you know,

36:28.400 --> 36:29.856
in the communities they live in,

36:29.880 --> 36:31.726
in the environments they are.

36:31.750 --> 36:34.387
But it hasn't always
been the case online.

36:34.420 --> 36:37.420
And some governments have

36:37.461 --> 36:39.529
struggled to see
what that means.

36:42.730 --> 36:44.254
If the case is successful,

36:44.278 --> 36:45.946
TikTok could have
to pay children

36:45.970 --> 36:49.166
from the UK and Europe,
billions in compensation.

36:49.360 --> 36:50.826
TikTok is fighting the case.

36:50.850 --> 36:52.453
In a statement,
the company said,

36:52.477 --> 36:55.696
"Privacy and safety are
top priorities for TikTok

36:55.720 --> 36:58.026
and we have robust
policies, processes,

36:58.050 --> 37:01.736
and technologies in place
to help protect all users

37:01.760 --> 37:04.056
and our teenage
users in particular.

37:04.080 --> 37:05.836
We believe the claims lack merit

37:05.860 --> 37:08.627
and intend to vigorously
defend the action."

37:11.630 --> 37:14.006
The US government
is reviewing TikTok

37:14.030 --> 37:15.928
and hasn't ruled out a ban.

37:16.340 --> 37:17.585
- The real question
you ask is, what

37:17.609 --> 37:19.106
about the national
security implications?

37:19.130 --> 37:21.426
So, okay. Yes, a lot of
people are using it, right.

37:21.450 --> 37:22.536
But why does that matter?

37:22.560 --> 37:24.986
And it matters, I think,
because of the access,

37:25.010 --> 37:27.110
it gives you to this
large amount of data.

37:28.290 --> 37:31.416
You never think about the
Chinese government in Beijing,

37:31.440 --> 37:34.136
having videos of
you in your home,

37:34.160 --> 37:36.936
outside your home, at
the park with your kids,

37:36.960 --> 37:38.333
knowing who your kids play with.

37:38.760 --> 37:40.666
I mean, that's
what they have now

37:40.690 --> 37:42.186
potentially with this data set.

37:42.210 --> 37:44.516
We've seen now two
consecutive presidents

37:44.540 --> 37:45.616
sign executive orders,

37:45.640 --> 37:47.976
making clear that they
are very concerned

37:48.000 --> 37:49.996
about the national
security implications

37:50.020 --> 37:51.954
of TikTok's data collection.

37:52.249 --> 37:54.025
As well as the impact it has

37:54.050 --> 37:56.250
on the privacy and civil
liberties of Americans.

38:01.550 --> 38:03.574
India has
announced a ban on TikTok.

38:04.050 --> 38:06.716
And in July last year, Prime
Minister Scott Morrison

38:06.740 --> 38:10.223
ordered a review by intelligence
agencies into the app.

38:12.750 --> 38:16.503
We are always
very mindful of those risks

38:16.527 --> 38:20.326
and we are always
monitoring them very closely.

38:20.350 --> 38:22.246
And if we've considered,
there is a need

38:22.270 --> 38:24.836
to take further action
than we are taking now,

38:24.860 --> 38:27.073
then I can tell you, we
won't be shy about it.

38:28.720 --> 38:31.016
- It's certainly a
security concern

38:31.040 --> 38:33.506
that the data of
Australian users

38:33.530 --> 38:36.726
is potentially going
back to Beijing.

38:37.260 --> 38:39.780
TikTok maintained
that this is not the case.

38:39.810 --> 38:44.486
And our analysis showed that

38:44.510 --> 38:46.546
there's certainly
not a fire hose

38:46.570 --> 38:50.016
of content that's being
sent back to Beijing.

38:50.040 --> 38:51.386
But that doesn't mean that,

38:51.410 --> 38:53.486
that content can't be accessed

38:53.510 --> 38:55.531
from Beijing, if
that's required.

38:55.820 --> 38:56.826
How are you going?

38:56.874 --> 38:58.406
- I'm good, thank
you. How are you?

38:58.431 --> 39:00.735
TikTok maintains
Australian users' data

39:00.760 --> 39:03.426
is held on servers in
the US and Singapore.

39:03.450 --> 39:05.456
And that it has
never provided data

39:05.480 --> 39:06.923
to the Chinese government.

39:08.480 --> 39:11.036
Staff in the Home Affairs
and Defense Departments

39:11.060 --> 39:14.016
have been told not to
have TikTok on their phones

39:14.040 --> 39:15.842
because of security risks.

39:16.470 --> 39:19.196
But Scott Morrison said
there wasn't enough evidence

39:19.220 --> 39:21.037
to ban TikTok in Australia.

39:21.780 --> 39:24.276
- The scope of the
investigation did seem

39:24.300 --> 39:25.996
to be quite limited.

39:26.020 --> 39:31.075
And that scope is not
really enough to be able

39:31.100 --> 39:34.110
to tell the rest of Australia

39:34.180 --> 39:36.196
and regular Australian citizens,

39:36.220 --> 39:39.786
whether it's a good idea
for them to be using the app.

39:41.150 --> 39:44.556
- There should definitely
be another more rigorous

39:44.580 --> 39:47.046
and lengthy review into TikTok

39:47.070 --> 39:51.478
to fully understand the
risks that TikTok presents.

39:52.300 --> 39:53.973
- And so if you just look
at TikTok in isolation,

39:53.997 --> 39:55.683
and say, well, it's
just this one app,

39:55.707 --> 39:57.516
and it's just kids
doing dancing videos.

39:57.540 --> 39:58.836
It seems innocuous.

39:58.860 --> 40:01.706
But it's really takes place
in this much larger context

40:01.730 --> 40:04.486
of data collection,
artificial intelligence,

40:04.510 --> 40:08.046
and a real effort by the
Chinese to consolidate influence

40:08.070 --> 40:09.602
in the region and
across the globe.

40:13.450 --> 40:14.942
In just two years,

40:14.980 --> 40:17.875
TikTok has cemented
itself as the app of choice

40:17.900 --> 40:20.016
for millions of Australians.

40:20.040 --> 40:22.916
- So you guys kept telling
me to go on the Voice 2021.

40:22.940 --> 40:25.446
So, I did.

40:25.470 --> 40:26.926
There are serious concerns

40:26.950 --> 40:30.406
that TikToks fun and
beautiful version of reality

40:30.430 --> 40:33.103
is distorting the way
we see the world.

40:34.680 --> 40:38.967
And questions about whether
its users understand the risks.

40:41.280 --> 40:44.136
- So we're really at risk
of having generations

40:44.160 --> 40:46.306
of young people
that haven't been able

40:46.330 --> 40:49.416
to form their own
identity in natural ways.

40:49.440 --> 40:51.396
And instead have
formed identities

40:51.420 --> 40:54.026
in response to something
that a technology

40:54.050 --> 40:56.456
or a technology
platform prescribes

40:56.480 --> 40:58.476
to be the normal
or the new normal.

40:58.500 --> 41:00.177
- Last time this lady
came up to me and go,

41:00.201 --> 41:01.673
you don't look disabled enough.

41:01.820 --> 41:02.980
I don't look disabled enough?

41:03.010 --> 41:05.296
- I understand that
TikTok is trying its very best

41:05.320 --> 41:07.706
to make the platform
palatable to everyone

41:07.730 --> 41:12.730
by just having fun dance
videos and lip sync videos.

41:16.290 --> 41:18.946
But I know that my
content gives value

41:18.970 --> 41:21.156
to so many people
who look like me.

41:21.180 --> 41:23.876
Who live the same life like me.

41:23.900 --> 41:25.595
Who are brown like me.

41:33.750 --> 41:37.976
- I ended up cutting off
TikTok like after a few months.

41:38.000 --> 41:40.186
But even with that,
like it still left me

41:40.210 --> 41:42.526
with the eating
disorder, you know.

41:42.550 --> 41:45.336
Like, TikTok kind of led to
the development and then

41:45.360 --> 41:48.923
it has taken a really,
really long time to fix that.

41:50.238 --> 41:52.275
TikTok isn't out
here to help people.

41:52.300 --> 41:53.716
I don't think it's
coming to the world

41:53.740 --> 41:55.396
with this intention
of helping people.

41:55.420 --> 41:57.226
If they're going to make
money off of something,

41:57.250 --> 41:59.646
then they will make
money off of something.

42:00.120 --> 42:02.246
I think they maybe
need to realise

42:02.270 --> 42:04.170
the impact that is
having on people.
