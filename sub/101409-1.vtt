WEBVTT

00:15.849 --> 00:17.934
[eerie instrumental music playing]

00:31.114 --> 00:34.659
[interviewer] Why don't you go ahead?
Sit down and see if you can get comfy.

00:37.579 --> 00:39.789
-You good? All right.
-Yeah. [exhales]

00:39.914 --> 00:42.125
-[interviewer] Um...
-[cell phone vibrates]

00:43.043 --> 00:44.794
[crew member] Take one, marker.

00:46.796 --> 00:48.798
[interviewer] Wanna start
by introducing yourself?

00:48.882 --> 00:49.799
[crew member coughs]

00:50.467 --> 00:53.344
Hello, world. Bailey. Take three.

00:53.970 --> 00:56.347
-[interviewer] You good?
-This is the worst part, man.

00:56.890 --> 00:59.517
[chuckling] I don't like this.

00:59.851 --> 01:02.228
I worked at Facebook in 2011 and 2012.

01:02.312 --> 01:05.190
I was one of the really early employees
at Instagram.

01:05.273 --> 01:08.693
[man 1] <i>I worked at, uh, Google,</i>
<i>uh, YouTube.</i>

01:08.777 --> 01:11.696
[woman] <i>Apple, Google, Twitter, Palm.</i>

01:12.739 --> 01:15.533
I helped start Mozilla Labs
and switched over to the Firefox side.

01:15.617 --> 01:18.119
-[interviewer] Are we rolling? Everybody?
-[crew members reply]

01:18.203 --> 01:19.162
[interviewer] Great.

01:21.206 --> 01:22.624
[man 2] I worked at Twitter.

01:23.041 --> 01:23.917
My last job there

01:24.000 --> 01:26.169
was the senior vice president
of engineering.

01:27.337 --> 01:29.255
-[man 3] I was the president of Pinterest.
-[sips]

01:29.339 --> 01:32.717
Before that, um,
I was the... the director of monetization

01:32.801 --> 01:34.260
at Facebook for five years.

01:34.344 --> 01:37.972
While at Twitter, I spent a number
of years running their developer platform,

01:38.056 --> 01:40.225
and then I became
head of consumer product.

01:40.308 --> 01:44.270
I was theÂ coinventor of Google Drive,
Gmail Chat,

01:44.354 --> 01:46.689
Facebook Pages,
and the Facebook like button.

01:47.440 --> 01:50.777
Yeah. This is... This is why I spent,
like, eight months

01:50.860 --> 01:52.779
talking back and forth with lawyers.

01:54.072 --> 01:55.406
This freaks me out.

01:58.409 --> 01:59.702
[man 2] When I was there,

01:59.786 --> 02:02.914
I always felt like,
fundamentally, it was a force for good.

02:03.414 --> 02:05.375
I don't know if I feel that way anymore.

02:05.458 --> 02:10.588
I left Google in June 2017, uh,
due to ethical concerns.

02:10.672 --> 02:14.134
And... And not just at Google
but within the industry at large.

02:14.217 --> 02:15.385
I'm very concerned.

02:16.636 --> 02:17.679
I'm very concerned.

02:19.097 --> 02:21.808
It's easy today to lose sight of the fact

02:21.891 --> 02:27.814
that these tools actually have created
some wonderful things in the world.

02:27.897 --> 02:31.943
They've reunited lost family members.
They've found organ donors.

02:32.026 --> 02:36.573
I mean, there were meaningful,
systemic changes happening

02:36.656 --> 02:39.159
around the world
because of these platforms

02:39.242 --> 02:40.285
that were positive!

02:40.827 --> 02:44.539
I think we were naive
about the flip side of that coin.

02:45.540 --> 02:48.585
Yeah, these things, you release them,
and they take on a life of their own.

02:48.668 --> 02:52.005
And how they're used is pretty different
than how you expected.

02:52.088 --> 02:56.509
Nobody, I deeply believe,
ever intended any of these consequences.

02:56.593 --> 02:59.554
There's no one bad guy.
No. Absolutely not.

03:01.598 --> 03:03.975
[interviewer] So, then,
what's the... what's the problem?

03:09.147 --> 03:11.482
[interviewer] Is there a problem,
and what is the problem?

03:12.108 --> 03:13.026
[swallows]

03:17.614 --> 03:19.991
[clicks tongue] Yeah, it is hard
to give a single, succinct...

03:20.074 --> 03:22.118
I'm trying to touch on
many different problems.

03:22.535 --> 03:23.953
[interviewer] What is the problem?

03:24.621 --> 03:25.914
[clicks tongue, chuckles]

03:27.916 --> 03:29.500
[birds singing]

03:31.169 --> 03:32.670
[dog barking in distance]

03:33.463 --> 03:35.340
[reporter 1]
<i>Despite facing mounting criticism,</i>

03:35.423 --> 03:37.675
<i>the so-called Big Tech names</i>
<i>are getting bigger.</i>

03:37.759 --> 03:40.929
The entire tech industry is
under a new level of scrutiny.

03:41.012 --> 03:43.806
And a new study sheds light on the link

03:43.890 --> 03:46.142
between mental health
and social media use.

03:46.226 --> 03:48.686
[on TV]
<i>Here to talk about the latest research...</i>

03:48.770 --> 03:51.397
[Tucker Carlson] <i>...is going on</i>
<i>that gets no coverage at all.</i>

03:51.481 --> 03:54.108
<i>Tens of millions of Americans</i>
<i>are hopelessly addicted</i>

03:54.192 --> 03:56.319
<i>to their electronic devices.</i>

03:56.402 --> 03:57.987
[reporter 2] <i>It's exacerbated by the fact</i>

03:58.071 --> 04:00.698
<i>that you can literally isolate yourself</i>
<i>now</i>

04:00.782 --> 04:02.742
in a bubble, thanks to our technology.

04:02.825 --> 04:04.577
Fake news is becoming more advanced

04:04.661 --> 04:06.788
and threatening societies
around the world.

04:06.871 --> 04:10.250
We weren't expecting any of this
when we created Twitter over 12 years ago.

04:10.333 --> 04:12.502
White House officials say
they have no reason to believe

04:12.585 --> 04:14.754
the Russian cyberattacks will stop.

04:14.837 --> 04:18.132
YouTube is being forced
to concentrate on cleansing the site.

04:18.216 --> 04:21.552
[reporter 3] <i>TikTok,</i>
<i>if you talk to any tween out there...</i>

04:21.636 --> 04:24.013
[on TV] <i>...there's no chance</i>
<i>they'll delete this thing...</i>

04:24.097 --> 04:26.224
Hey, Isla,
can you get the table ready, please?

04:26.307 --> 04:28.601
[reporter 4] <i>There's a question</i>
<i>about whether social media</i>

04:28.685 --> 04:29.978
<i>is making your child depressed.</i>

04:30.061 --> 04:32.105
[mom] Isla,
can you set the table, please?

04:32.188 --> 04:35.316
[reporter 5] <i>These cosmetic procedures</i>
<i>are becoming so popular with teens,</i>

04:35.400 --> 04:37.902
plastic surgeons have coined
a new syndrome for it,

04:37.986 --> 04:40.822
"Snapchat dysmorphia,"
with young patients wanting surgery

04:40.905 --> 04:43.741
so they can look more like they do
in filtered selfies.

04:43.825 --> 04:45.910
Still don't see why you let her have
that thing.

04:45.994 --> 04:47.412
What was I supposed to do?

04:47.495 --> 04:49.580
I mean, every other kid
in her class had one.

04:50.164 --> 04:51.165
She's only 11.

04:51.249 --> 04:52.959
Cass, no one's forcing you to get one.

04:53.042 --> 04:55.086
You can stay disconnected
as long as you want.

04:55.169 --> 04:59.340
Hey, I'm connected without a cell phone,
okay? I'm on the Internet right now.

04:59.424 --> 05:03.094
Also, that isn't even actual connection.
It's just a load of sh--

05:03.177 --> 05:05.013
Surveillance capitalism has come to shape

05:05.096 --> 05:07.765
our politics and culture
in ways many people don't perceive.

05:07.849 --> 05:10.101
[reporter 6]
<i>ISIS inspired followers online,</i>

05:10.184 --> 05:12.812
<i>and now white supremacists</i>
<i>are doing the same.</i>

05:12.895 --> 05:14.147
Recently in India,

05:14.230 --> 05:17.442
Internet lynch mobs have killed
a dozen people, including these five...

05:17.525 --> 05:20.361
[reporter 7] <i>It's not just fake news;</i>
<i>it's fake news with consequences.</i>

05:20.445 --> 05:24.073
[reporter 8] <i>How do you handle an epidemic</i>
<i>in the age of fake news?</i>

05:24.157 --> 05:26.993
Can you get the coronavirus
by eating Chinese food?

05:27.535 --> 05:32.540
We have gone from the information age
into the disinformation age.

05:32.623 --> 05:34.667
Our democracy is under assault.

05:34.751 --> 05:36.919
[man 4] What I said was,
"I think the tools

05:37.003 --> 05:39.005
that have been created today are starting

05:39.088 --> 05:41.799
to erode the social fabric
of how society works."

05:41.883 --> 05:44.427
[eerie instrumental music continues]

05:55.980 --> 05:58.483
-[music fades]
-[indistinct chatter]

05:58.566 --> 05:59.442
[crew member] Fine.

06:00.151 --> 06:03.446
[stage manager] Aza does
welcoming remarks. We play the video.

06:04.197 --> 06:07.325
And then, "Ladies and gentlemen,
Tristan Harris."

06:07.408 --> 06:08.868
-Right.
-[stage manager] Great.

06:08.951 --> 06:12.038
So, I come up, and...

06:13.831 --> 06:17.126
basically say, "Thank you all for coming."
Um...

06:17.919 --> 06:22.048
So, today, I wanna talk about a new agenda
for technology.

06:22.131 --> 06:25.468
And why we wanna do that
is because if you ask people,

06:25.551 --> 06:27.804
"What's wrong in the tech industry
right now?"

06:28.262 --> 06:31.641
there's a cacophony of grievances
and scandals,

06:31.724 --> 06:33.893
and "They stole our data."
And there's tech addiction.

06:33.976 --> 06:35.978
And there's fake news.
And there's polarization

06:36.062 --> 06:37.855
and some elections
that are getting hacked.

06:38.189 --> 06:41.609
But is there something
that is beneath all these problems

06:41.692 --> 06:44.612
that's causing all these things
to happen at once?

06:44.821 --> 06:46.364
[stage manager speaking indistinctly]

06:46.447 --> 06:48.408
-Does this feel good?
-Very good. Yeah.

06:49.033 --> 06:49.992
Um... [sighs]

06:50.743 --> 06:52.954
I'm just trying to...
Like, I want people to see...

06:53.037 --> 06:55.123
Like, there's a problem happening
in the tech industry,

06:55.206 --> 06:56.707
and it doesn't have a name,

06:56.791 --> 07:00.211
and it has to do with one source,
like, one...

07:00.795 --> 07:03.589
[eerie instrumental music playing]

07:05.091 --> 07:09.387
[Tristan] When you look around you,
it feels like the world is going crazy.

07:12.765 --> 07:15.309
You have to ask yourself, like,
"Is this normal?

07:16.102 --> 07:18.771
Or have we all fallen under some kind
of spell?"

07:27.989 --> 07:30.491
I wish more people could understand
how this works

07:30.575 --> 07:34.036
because it shouldn't be something
that only the tech industry knows.

07:34.120 --> 07:36.247
It should be something
that everybody knows.

07:36.330 --> 07:38.708
[backpack zips]

07:41.419 --> 07:42.378
[softly] Bye.

07:43.629 --> 07:44.881
[guard] Here you go, sir.

07:47.383 --> 07:48.676
-[employee] Hello!
-[Tristan] Hi.

07:48.759 --> 07:50.678
-Tristan. Nice to meet you.
<i>-</i>It's Tris-<i>tan, </i>right?

07:50.761 --> 07:51.721
-Yes.
-Awesome. Cool.

07:53.181 --> 07:55.933
[presenter] Tristan Harris
is a former design ethicist for Google

07:56.017 --> 07:59.395
and has been called the closest thing
Silicon Valley has to a conscience.

07:59.479 --> 08:00.730
[reporter] He's asking tech

08:00.813 --> 08:04.192
to bring what he calls "ethical design"
to its products.

08:04.275 --> 08:06.903
[Anderson Cooper] <i>It's rare</i>
<i>for a tech insider to be so blunt,</i>

08:06.986 --> 08:10.114
<i>but Tristan Harris believes</i>
<i>someone needs to be.</i>

08:11.324 --> 08:12.700
[Tristan] When I was at Google,

08:12.783 --> 08:16.037
I was on the Gmail team,
and I just started getting burnt out

08:16.120 --> 08:18.372
'cause we'd had
so many conversations about...

08:19.457 --> 08:23.169
you know, what the inbox should look like
and what color it should be, and...

08:23.252 --> 08:25.880
And I, you know, felt personally addicted
to e-mail,

08:26.297 --> 08:27.632
and I found it fascinating

08:27.715 --> 08:31.511
there was no one at Gmail working
on making it less addictive.

08:31.969 --> 08:34.514
And I was like,
"Is anybody else thinking about this?

08:34.597 --> 08:36.390
I haven't heard anybody talk about this."

08:36.849 --> 08:39.685
-And I was feeling this frustration...
-[sighs]

08:39.769 --> 08:41.229
...with the tech industry, overall,

08:41.312 --> 08:43.147
that we'd kind of, like, lost our way.

08:43.231 --> 08:46.442
-[ominous instrumental music playing]
-[message alerts chiming]

08:46.817 --> 08:49.820
[Tristan] You know, I really struggled
to try and figure out

08:49.904 --> 08:52.573
how, from the inside, we could change it.

08:52.907 --> 08:55.117
[energetic piano music playing]

08:55.201 --> 08:58.120
[Tristan] And that was when I decided
to make a presentation,

08:58.204 --> 08:59.497
kind of a call to arms.

09:00.998 --> 09:04.961
Every day, I went home and I worked on it
for a couple hours every single night.

09:05.044 --> 09:06.087
[typing]

09:06.170 --> 09:08.548
[Tristan] It basically just said,
you know,

09:08.631 --> 09:11.884
never before
in history have 50 designers--

09:12.426 --> 09:15.263
20- to 35-year-old white guys
in California--

09:15.888 --> 09:19.725
made decisions that would have an impact
on two billion people.

09:21.018 --> 09:24.438
Two billion people will have thoughts
that they didn't intend to have

09:24.522 --> 09:28.401
because a designer at Google said,
"This is how notifications work

09:28.484 --> 09:30.778
on that screen that you wake up to
in the morning."

09:31.195 --> 09:35.283
And we have a moral responsibility,
as Google, for solving this problem.

09:36.075 --> 09:37.743
And I sent this presentation

09:37.827 --> 09:41.789
to about 15, 20 of my closest colleagues
at Google,

09:41.872 --> 09:44.959
and I was very nervous about it.
I wasn't sure how it was gonna land.

09:46.460 --> 09:48.045
When I went to work the next day,

09:48.129 --> 09:50.464
most of the laptops
had the presentation open.

09:52.133 --> 09:54.552
Later that day, there was, like,
400 simultaneous viewers,

09:54.635 --> 09:56.053
so it just kept growing and growing.

09:56.137 --> 10:00.266
I got e-mails from all around the company.
I mean, people in every department saying,

10:00.349 --> 10:02.852
"I totally agree."
"I see this affecting my kids."

10:02.935 --> 10:04.979
"I see this affecting
the people around me."

10:05.062 --> 10:06.939
"We have to do something about this."

10:07.481 --> 10:10.818
It felt like I was sort of launching
a revolution or something like that.

10:11.861 --> 10:15.197
Later, I found out Larry Page
had been notified about this presentation

10:15.281 --> 10:17.908
-in three separate meetings that day.
-[indistinct chatter]

10:17.992 --> 10:20.286
[Tristan] And so, it created
this kind of cultural moment

10:20.870 --> 10:24.415
-that Google needed to take seriously.
-[whooshing]

10:26.000 --> 10:28.878
-[Tristan] And then... nothing.
-[whooshing fades]

10:32.673 --> 10:34.216
[message alerts chiming]

10:34.300 --> 10:36.135
[Tim] Everyone in 2006...

10:37.219 --> 10:39.221
including all of us at Facebook,

10:39.305 --> 10:43.392
just had total admiration for Google
and what Google had built,

10:43.476 --> 10:47.396
which was this incredibly useful service

10:47.480 --> 10:51.442
that did, far as we could tell,
lots of goodness for the world,

10:51.525 --> 10:54.695
and they built
this parallel money machine.

10:55.404 --> 11:00.034
We had such envy for that,
and it seemed so elegant to us...

11:00.826 --> 11:02.161
and so perfect.

11:02.953 --> 11:05.289
Facebook had been around
for about two years,

11:05.373 --> 11:08.376
um, and I was hired to come in
and figure out

11:08.459 --> 11:10.586
what the business model was gonna be
for the company.

11:10.670 --> 11:13.422
I was the director of monetization.
The point was, like,

11:13.506 --> 11:17.051
"You're the person who's gonna figure out
how this thing monetizes."

11:17.134 --> 11:19.804
And there were a lot of people
who did a lot of the work,

11:19.887 --> 11:25.476
but I was clearly one of the people
who was pointing towards...

11:26.769 --> 11:28.562
"Well, we have to make money, A...

11:29.313 --> 11:33.651
and I think this advertising model
is probably the most elegant way.

11:36.278 --> 11:38.280
[bright instrumental music playing]

11:42.243 --> 11:44.370
Uh-oh. What's this video Mom just sent us?

11:44.453 --> 11:46.747
Oh, that's from a talk show,
but that's pretty good.

11:46.831 --> 11:47.873
Guy's kind of a genius.

11:47.957 --> 11:50.584
He's talking all about deleting
social media, which you gotta do.

11:50.668 --> 11:52.878
I might have to start blocking
her e-mails.

11:52.962 --> 11:54.880
I don't even know
what she's talking about, man.

11:54.964 --> 11:56.090
She's worse than I am.

11:56.173 --> 11:58.509
-No, she only uses it for recipes.
-Right, and work.

11:58.592 --> 12:00.553
-And workout videos.
-[guy] And to check up on us.

12:00.636 --> 12:03.055
And everyone else she's ever met
in her entire life.

12:04.932 --> 12:07.893
<i>If you are scrolling through</i>
<i>your social media feed</i>

12:07.977 --> 12:11.731
<i>while you're watchin' us, you need to put</i>
<i>the damn phone down and listen up</i>

12:11.814 --> 12:14.817
'cause our next guest has written
an incredible book

12:14.900 --> 12:18.112
about how much it's wrecking our lives.

12:18.195 --> 12:19.447
Please welcome author

12:19.530 --> 12:23.951
of<i> Ten Arguments for Deleting</i>
<i>Your Social Media Accounts Right Now...</i>

12:24.034 --> 12:26.287
-[Sunny Hostin] Uh-huh.
-...Jaron Lanier.

12:26.370 --> 12:27.913
[cohosts speaking indistinctly]

12:27.997 --> 12:31.834
[Jaron] Companies like Google and Facebook
are some of the wealthiest

12:31.917 --> 12:33.544
and most successful of all time.

12:33.711 --> 12:36.839
Uh, they have relatively few employees.

12:36.922 --> 12:41.427
They just have this giant computer
that rakes in money, right? Uh...

12:41.510 --> 12:42.970
Now, what are they being paid for?

12:43.053 --> 12:45.222
[chuckles]
That's a really important question.

12:47.308 --> 12:50.311
[Roger] So, I've been an investor
in technology for 35 years.

12:51.020 --> 12:54.356
The first 50 years of Silicon Valley,
the industry made products--

12:54.440 --> 12:55.566
hardware, software--

12:55.649 --> 12:58.402
sold 'em to customers.
Nice, simple business.

12:58.486 --> 13:01.447
For the last ten years,
the biggest companies in Silicon Valley

13:01.530 --> 13:03.866
have been in the business
of selling their users.

13:03.949 --> 13:05.910
It's a little even trite to say now,

13:05.993 --> 13:09.205
but... because we don't pay
for the products that we use,

13:09.288 --> 13:12.166
advertisers pay
for the products that we use.

13:12.249 --> 13:14.210
Advertisers are the customers.

13:14.710 --> 13:16.086
We're the thing being sold.

13:16.170 --> 13:17.630
The classic saying is:

13:17.713 --> 13:21.592
"If you're not paying for the product,
then you <i>are </i>the product."

13:23.385 --> 13:27.223
A lot of people think, you know,
"Oh, well, Google's just a search box,

13:27.306 --> 13:29.850
and Facebook's just a place to see
what my friends are doing

13:29.934 --> 13:31.101
and see their photos."

13:31.185 --> 13:35.481
But what they don't realize
is they're competing for your attention.

13:36.524 --> 13:41.111
So, you know, Facebook, Snapchat,
Twitter, Instagram, YouTube,

13:41.195 --> 13:45.699
companies like this, their business model
is to keep people engaged on the screen.

13:46.283 --> 13:49.578
Let's figure out how to get
as much of this person's attention

13:49.662 --> 13:50.955
as we possibly can.

13:51.455 --> 13:53.374
How much time can we get you to spend?

13:53.874 --> 13:56.669
How much of your life can we get you
to give to us?

13:58.629 --> 14:01.090
[Justin] When you think about
how some of these companies work,

14:01.173 --> 14:02.424
it starts to make sense.

14:03.050 --> 14:06.095
There are all these services
on the Internet that we think of as free,

14:06.178 --> 14:09.473
but they're not free.
They're paid for by advertisers.

14:09.557 --> 14:11.559
Why do advertisers pay those companies?

14:11.642 --> 14:14.687
They pay in exchange for showing their ads
to us.

14:14.770 --> 14:18.357
We're the product. Our attention
is the product being sold to advertisers.

14:18.816 --> 14:20.442
That's a little too simplistic.

14:20.860 --> 14:23.654
It's the gradual, slight,
imperceptible change

14:23.737 --> 14:26.574
in your own behavior and perception
that is the product.

14:27.658 --> 14:30.244
And that <i>is </i>the product.
It's the only possible product.

14:30.327 --> 14:34.081
There's nothing else on the table
that could possibly be called the product.

14:34.164 --> 14:37.001
That's the only thing there is
for them to make money from.

14:37.668 --> 14:39.253
Changing what you do,

14:39.336 --> 14:41.714
how you think, who you are.

14:42.631 --> 14:45.301
It's a gradual change. It's slight.

14:45.384 --> 14:48.971
If you can go to somebody and you say,
"Give me $10 million,

14:49.054 --> 14:54.310
and I will change the world one percent
in the direction you want it to change..."

14:54.852 --> 14:58.188
It's the world! That can be incredible,
and that's worth a lot of money.

14:59.315 --> 15:00.149
Okay.

15:00.691 --> 15:04.570
[Shoshana] This is what every business
has alwaysÂ dreamt of:

15:04.653 --> 15:10.910
to have a guarantee that if it places
an ad, it will be successful.

15:11.327 --> 15:12.786
That's their business.

15:12.870 --> 15:14.413
They sell certainty.

15:14.997 --> 15:17.625
In order to be successful
in that business,

15:17.708 --> 15:19.793
you have to have great predictions.

15:20.085 --> 15:24.173
Great predictions begin
with one imperative:

15:25.215 --> 15:26.926
you need a lot of data.

15:29.136 --> 15:31.305
Many people call this
surveillance capitalism,

15:31.639 --> 15:34.350
capitalism profiting
off of the infinite tracking

15:34.433 --> 15:38.062
of everywhere everyone goes
by large technology companies

15:38.145 --> 15:40.356
whose business model is to make sure

15:40.439 --> 15:42.858
that advertisers are as successful
as possible.

15:42.942 --> 15:45.569
This is a new kind of marketplace now.

15:45.653 --> 15:48.072
It's a marketplace
that never existed before.

15:48.822 --> 15:55.371
And it's a marketplace
that trades exclusively in human futures.

15:56.080 --> 16:01.585
Just like there are markets that trade
in pork belly futures or oil futures.

16:02.127 --> 16:07.591
We now have markets
that trade in human futures at scale,

16:08.175 --> 16:13.472
and those markets have produced
the trillions of dollars

16:14.014 --> 16:19.269
that have made the Internet companies
the richest companies

16:19.353 --> 16:22.356
in the history of humanity.

16:23.357 --> 16:25.359
[indistinct chatter]

16:27.361 --> 16:30.990
[Jeff] What I want people to know
is that everything they're doing online

16:31.073 --> 16:34.326
<i>is </i>being watched, <i>is </i>being tracked,
<i>is </i>being measured.

16:35.035 --> 16:39.623
Every single action you take
is carefully monitored and recorded.

16:39.707 --> 16:43.836
Exactly what image you stop and look at,
for how long you look at it.

16:43.919 --> 16:45.796
Oh, yeah, seriously,
for how long you look at it.

16:45.879 --> 16:47.881
[monitors beeping]

16:50.509 --> 16:52.219
[Tristan] <i>They know</i>
<i>when people are lonely.</i>

16:52.302 --> 16:53.804
<i>They know when people are depressed.</i>

16:53.887 --> 16:57.099
<i>They know when people are looking</i>
<i>at photos of your ex-romantic partners.</i>

16:57.182 --> 17:00.853
<i>They know what you're doing late at night.</i>
<i>They know the entire thing.</i>

17:01.270 --> 17:03.230
<i>Whether you're an introvert</i>
<i>or an extrovert,</i>

17:03.313 --> 17:06.817
<i>or what kind of neuroses you have,</i>
<i>what your personality type is like.</i>

17:08.193 --> 17:11.613
[Shoshana] They have more information
about us

17:11.697 --> 17:14.324
than has ever been imagined
in human history.

17:14.950 --> 17:16.368
It is unprecedented.

17:18.579 --> 17:22.791
And so, all of this data that we're...
that we're just pouring out all the time

17:22.875 --> 17:26.754
is being fed into these systems
that have almost no human supervision

17:27.463 --> 17:30.883
and that are making better and better
and better and better predictions

17:30.966 --> 17:33.552
about what we're gonna do
and... and who we are.

17:33.635 --> 17:35.637
[indistinct chatter]

17:36.305 --> 17:39.349
[Aza] People have the misconception
it's our data being sold.

17:40.350 --> 17:43.187
It's not in Facebook's business interest
to give up the data.

17:45.522 --> 17:47.107
What do they do with that data?

17:49.401 --> 17:50.986
[console whirring]

17:51.070 --> 17:54.490
[Aza] They build models
that predict our actions,

17:54.573 --> 17:57.618
and whoever has the best model wins.

18:02.706 --> 18:04.041
His scrolling speed is slowing.

18:04.124 --> 18:06.085
Nearing the end
of his average session length.

18:06.168 --> 18:07.002
Decreasing ad load.

18:07.086 --> 18:08.337
Pull back on friends and family.

18:09.588 --> 18:11.340
[Tristan] On the other side of the screen,

18:11.423 --> 18:15.469
it's almost as if they had
this avatar voodoo doll-like model of us.

18:16.845 --> 18:18.180
All of the things we've ever done,

18:18.263 --> 18:19.473
all the clicks we've ever made,

18:19.556 --> 18:21.642
all the videos we've watched,
all the likes,

18:21.725 --> 18:25.354
that all gets brought back into building
a more and more accurate model.

18:25.896 --> 18:27.481
The model, once you have it,

18:27.564 --> 18:29.858
you can predict the kinds of things
that person does.

18:29.942 --> 18:31.777
Right, let me just test.

18:32.569 --> 18:34.988
[Tristan] Where you'll go.
I can predictÂ what kind of videos

18:35.072 --> 18:36.115
will keep you watching.

18:36.198 --> 18:39.159
I can predict what kinds of emotions tend
to trigger you.

18:39.243 --> 18:40.410
[blue AI] Yes, perfect.

18:41.578 --> 18:43.372
The most epic fails of the year.

18:46.125 --> 18:47.543
-[crowd groans on video]
-[whooshes]

18:48.627 --> 18:51.088
-Perfect. That worked.
-Following with another video.

18:51.171 --> 18:54.049
Beautiful. Let's squeeze in a sneaker ad
before it starts.

18:56.426 --> 18:58.178
[Tristan] At a lot
of technology companies,

18:58.262 --> 18:59.721
there's three main goals.

18:59.805 --> 19:01.348
There's the engagement goal:

19:01.431 --> 19:03.684
to drive up your usage,
to keep you scrolling.

19:04.601 --> 19:06.145
There's the growth goal:

19:06.228 --> 19:08.689
to keep you coming back
and inviting as many friends

19:08.772 --> 19:10.816
and getting them to invite more friends.

19:11.650 --> 19:13.152
And then there's the advertising goal:

19:13.235 --> 19:14.987
to make sure that,
as all that's happening,

19:15.070 --> 19:17.406
we're making as much money as possible
from advertising.

19:18.115 --> 19:19.158
[console beeps]

19:19.241 --> 19:21.994
Each of these goals are powered
by algorithms

19:22.077 --> 19:24.454
whose job is to figure out
what to show you

19:24.538 --> 19:26.165
to keep those numbers going up.

19:26.623 --> 19:29.918
We often talked about, at Facebook,
this idea

19:30.002 --> 19:34.006
of being able to just dial that as needed.

19:34.673 --> 19:38.594
And, you know, we talked
about having Mark have those dials.

19:41.305 --> 19:44.474
"Hey, I want more users in Korea today."

19:45.684 --> 19:46.602
"Turn the dial."

19:47.436 --> 19:49.188
"Let's dial up the ads a little bit."

19:49.980 --> 19:51.899
"Dial up monetization, just slightly."

19:52.858 --> 19:55.444
And so, that happ--

19:55.527 --> 19:59.239
I mean, at all of these companies,
there is that level of precision.

19:59.990 --> 20:02.409
-Dude, how--
-I don't know how I didn't get carded.

20:02.492 --> 20:05.704
-That ref just, like, sucked or something.
-You got literally all the way...

20:05.787 --> 20:07.956
-That's Rebecca. Go talk to her.
-I know who it is.

20:08.040 --> 20:10.834
-Dude, yo, go talk to her.
-[guy] I'm workin' on it.

20:10.918 --> 20:14.171
His calendar says he's on a break
right now. We should be live.

20:14.755 --> 20:16.465
[sighs] Want me to nudge him?

20:17.132 --> 20:18.050
Yeah, nudge away.

20:18.133 --> 20:19.092
[console beeps]

20:21.637 --> 20:24.181
"Your friend Tyler just joined.
Say hi with a wave."

20:26.016 --> 20:27.184
[Engagement AI] Come on, Ben.

20:27.267 --> 20:29.311
Send a wave. [sighs]

20:29.394 --> 20:32.606
-You're not... Go talk to her, dude.
-[phone vibrates, chimes]

20:33.857 --> 20:35.484
-[Ben sighs]
-[cell phone chimes]

20:36.902 --> 20:37.986
[console beeps]

20:38.070 --> 20:40.447
New link! All right, we're on. [exhales]

20:40.948 --> 20:46.078
Follow that up with a post
from User 079044238820, Rebecca.

20:46.161 --> 20:49.790
Good idea. GPS coordinates indicate
that they're in close proximity.

20:55.921 --> 20:57.172
He's primed for an ad.

20:57.631 --> 20:58.632
Auction time.

21:00.133 --> 21:02.803
Sold! To Deep Fade hair wax.

21:03.387 --> 21:07.933
We had 468 interested bidders. We sold Ben
at 3.262 cents for an impression.

21:08.850 --> 21:10.852
[melancholy piano music playing]

21:14.147 --> 21:15.065
[Ben sighs]

21:17.109 --> 21:18.735
[Jaron] We've created a world

21:18.819 --> 21:21.530
in which online connection
has become primary,

21:22.072 --> 21:23.907
especially for younger generations.

21:23.991 --> 21:28.328
And yet, in that world,
any time two people connect,

21:29.162 --> 21:33.250
the only way it's financed
is through a sneaky third person

21:33.333 --> 21:35.627
who's paying to manipulate
those two people.

21:36.128 --> 21:39.381
So, we've created
an entire global generation of people

21:39.464 --> 21:44.011
who are raised within a context
where the very meaning of communication,

21:44.094 --> 21:47.431
the very meaning of culture,
is manipulation.

21:47.514 --> 21:49.641
We've put deceit and sneakiness

21:49.725 --> 21:52.311
at the absolute center
of everything we do.

22:05.615 --> 22:07.242
-[interviewer] Grab the...
-[Tristan] Okay.

22:07.326 --> 22:09.286
-Where's it help to hold it?
-[interviewer] Great.

22:09.369 --> 22:10.787
-[Tristan] Here?
-[interviewer] Yeah.

22:10.871 --> 22:13.832
How does this come across on camera
if I were to do, like, this move--

22:13.915 --> 22:15.542
-[interviewer] We can--
-[blows] Like that?

22:15.625 --> 22:16.918
-[interviewer laughs] What?
-Yeah.

22:17.002 --> 22:19.004
-[interviewer] Do that again.
-Exactly. Yeah. [blows]

22:19.087 --> 22:20.589
Yeah. No, it's probably not...

22:20.672 --> 22:21.965
Like... yeah.

22:22.466 --> 22:23.884
I mean, this one is less...

22:29.681 --> 22:33.268
[interviewer laughs] Larissa's, like,
actually freaking out over here.

22:34.728 --> 22:35.562
Is that good?

22:35.645 --> 22:37.773
[instrumental music playing]

22:37.856 --> 22:41.068
[Tristan] I was, like, five years old
when I learned how to do magic.

22:41.151 --> 22:45.781
And I could fool adults,
fully-grown adults with, like,Â PhDs.

22:55.040 --> 22:57.709
Magicians were almost like
the first neuroscientists

22:57.793 --> 22:58.960
and psychologists.

22:59.044 --> 23:02.005
Like, they were the ones
who first understood

23:02.089 --> 23:03.382
how people's minds work.

23:04.216 --> 23:07.677
They just, in real time, are testing
lots and lots of stuff on people.

23:09.137 --> 23:11.139
A magician understands something,

23:11.223 --> 23:14.017
some part of your mind
that we're not aware of.

23:14.101 --> 23:15.936
That's what makes the illusion work.

23:16.019 --> 23:20.607
Doctors, lawyers, people who know
how to build 747s or nuclear missiles,

23:20.690 --> 23:24.361
they don't know more about
how their own mind is vulnerable.

23:24.444 --> 23:26.113
That's a separate discipline.

23:26.571 --> 23:28.990
And it's a discipline
that applies to all human beings.

23:30.909 --> 23:34.079
From that perspective, you can have
a very different understanding

23:34.162 --> 23:35.580
of what technology is doing.

23:36.873 --> 23:39.584
When I was
at the Stanford Persuasive Technology Lab,

23:39.668 --> 23:41.044
this is what we learned.

23:41.628 --> 23:43.463
How could you use everything we know

23:43.547 --> 23:45.882
about the psychology
of what persuades people

23:45.966 --> 23:48.385
and build that into technology?

23:48.468 --> 23:50.887
Now, many of you in the audience
are geniuses already.

23:50.971 --> 23:55.851
I think that's true, but my goal is
to turn you into a behavior-change genius.

23:56.852 --> 24:01.148
There are many prominent Silicon Valley
figures who went through that class--

24:01.231 --> 24:05.485
key growth figures at Facebook and Uber
and... and other companies--

24:05.569 --> 24:09.197
and learned how to make technology
more persuasive,

24:09.614 --> 24:10.782
Tristan being one.

24:12.284 --> 24:14.619
[Tristan] Persuasive technology
is just sort of design

24:14.703 --> 24:16.580
intentionally applied to the extreme,

24:16.663 --> 24:18.874
where we really want to modify
someone's behavior.

24:18.957 --> 24:20.542
We want them to take this action.

24:20.625 --> 24:23.336
We want them to keep doing this
with their finger.

24:23.420 --> 24:26.256
You pull down and you refresh,
it's gonna be a new thing at the top.

24:26.339 --> 24:28.508
Pull down and refresh again, it's new.
Every single time.

24:28.592 --> 24:33.722
Which, in psychology, we call
a positive intermittent reinforcement.

24:33.805 --> 24:37.142
You don't know when you're gonna get it
or if you're gonna get something,

24:37.225 --> 24:40.061
which operates just like the slot machines
in Vegas.

24:40.145 --> 24:42.230
It's not enough
that you use the product consciously,

24:42.314 --> 24:44.024
I wanna dig down deeper
into the brain stem

24:44.107 --> 24:45.817
and implant, inside of you,

24:45.901 --> 24:47.652
an unconscious habit

24:47.736 --> 24:50.864
so that you are being programmed
at a deeper level.

24:50.947 --> 24:52.115
You don't even realize it.

24:52.532 --> 24:54.034
[teacher] A man, James Marshall...

24:54.117 --> 24:56.286
[Tristan] Every time you see it there
on the counter,

24:56.369 --> 24:59.789
and you just look at it,
and you know if you reach over,

24:59.873 --> 25:01.333
it just might have something for you,

25:01.416 --> 25:03.877
so you play that slot machine
to see what you got, right?

25:03.960 --> 25:06.046
That's not by accident.
That's a design technique.

25:06.129 --> 25:08.632
[teacher] He brings a golden nugget
to an officer

25:09.841 --> 25:11.301
in the army in San Francisco.

25:12.219 --> 25:15.388
Mind you, the... the population
of San Francisco was only...

25:15.472 --> 25:17.432
[Jeff]
Another example is photo tagging.

25:17.516 --> 25:19.643
-[teacher] The secret didn't last.
-[phone vibrates]

25:19.726 --> 25:21.186
[Jeff] So, if you get an e-mail

25:21.269 --> 25:24.064
that says your friend just tagged you
in a photo,

25:24.147 --> 25:28.568
of course you're going to click
on that e-mail and look at the photo.

25:29.152 --> 25:31.821
It's not something
you can just decide to ignore.

25:32.364 --> 25:34.157
This is deep-seated, like,

25:34.241 --> 25:36.326
human personality
that they're tapping into.

25:36.409 --> 25:38.078
What you should be asking yourself is:

25:38.161 --> 25:40.288
"Why doesn't that e-mail contain
the photo in it?

25:40.372 --> 25:42.457
It would be a lot easier
to see the photo."

25:42.541 --> 25:45.919
When Facebook found that feature,
they just dialed the hell out of that

25:46.002 --> 25:48.505
because they said, "This is gonna be
a great way to grow activity.

25:48.588 --> 25:51.091
Let's just get people tagging each other
in photos all day long."

25:51.174 --> 25:53.176
[upbeat techno music playing]

25:57.889 --> 25:58.890
[cell phone chimes]

25:59.349 --> 26:00.475
He commented.

26:00.559 --> 26:01.434
[Growth AI] Nice.

26:01.935 --> 26:04.688
Okay, Rebecca received it,
and she is responding.

26:04.771 --> 26:07.566
All right, let Ben know that she's typing
so we don't lose him.

26:07.649 --> 26:08.733
Activating ellipsis.

26:09.776 --> 26:11.945
[teacher continues speaking indistinctly]

26:13.697 --> 26:15.865
[tense instrumental music playing]

26:19.953 --> 26:21.329
Great, she posted.

26:21.454 --> 26:24.249
He's commenting on her comment
about his comment on her post.

26:25.041 --> 26:26.418
Hold on, he stopped typing.

26:26.751 --> 26:27.752
Let's autofill.

26:28.420 --> 26:30.005
Emojis. He loves emojis.

26:33.842 --> 26:34.676
He went with fire.

26:34.759 --> 26:36.803
[clicks tongue, sighs]
I was rootin' for eggplant.

26:38.597 --> 26:42.726
[Tristan] There's an entire discipline
and field called "growth hacking."

26:42.809 --> 26:47.147
Teams of engineers
whose job is to hack people's psychology

26:47.230 --> 26:48.565
so they can get more growth.

26:48.648 --> 26:50.984
They can get more user sign-ups,
more engagement.

26:51.067 --> 26:52.861
They can get you to invite more people.

26:52.944 --> 26:55.989
After all the testing, all the iterating,
all of this stuff,

26:56.072 --> 26:57.907
you know the single biggest thing
we realized?

26:57.991 --> 27:00.702
Get any individual to seven friends
in ten days.

27:01.953 --> 27:02.787
That was it.

27:02.871 --> 27:05.498
Chamath was the head of growth at Facebook
early on,

27:05.582 --> 27:08.251
and he's very well known
in the tech industry

27:08.335 --> 27:11.004
for pioneering a lot of the growth tactics

27:11.087 --> 27:14.758
that were used to grow Facebook
at incredible speed.

27:14.841 --> 27:18.553
And those growth tactics have then become
the standard playbook for Silicon Valley.

27:18.637 --> 27:21.222
They were used at Uber
and at a bunch of other companies.

27:21.306 --> 27:27.062
One of the things that he pioneered
was the use of scientific A/B testing

27:27.145 --> 27:28.480
of small feature changes.

27:29.022 --> 27:30.940
Companies like Google and Facebook

27:31.024 --> 27:34.569
would roll out
lots of little, tiny experiments

27:34.653 --> 27:36.821
that they were constantly doing on users.

27:36.905 --> 27:39.866
And over time,
by running these constant experiments,

27:39.949 --> 27:43.036
you... you develop the most optimal way

27:43.119 --> 27:45.288
to get users to do
what you want them to do.

27:45.372 --> 27:46.790
It's... It's manipulation.

27:47.332 --> 27:49.459
[interviewer]
Uh, you're making me feel like a lab rat.

27:49.834 --> 27:51.920
You <i>are </i>a lab rat. We're all lab rats.

27:52.545 --> 27:55.548
And it's not like we're lab rats
for developing a cure for cancer.

27:55.632 --> 27:58.134
It's not like they're trying
to benefit <i>us.</i>

27:58.218 --> 28:01.680
Right? We're just zombies,
and they want us to look at more ads

28:01.763 --> 28:03.181
so they can make moreÂ money.

28:03.556 --> 28:05.266
[Shoshana] Facebook conducted

28:05.350 --> 28:08.228
what they called
"massive-scale contagion experiments."

28:08.311 --> 28:09.145
Okay.

28:09.229 --> 28:13.066
[Shoshana] How do we use subliminal cues
on the Facebook pages

28:13.400 --> 28:17.654
to get more people to go vote
in the midterm elections?

28:17.987 --> 28:20.824
And they discovered
that they were able to do that.

28:20.907 --> 28:24.160
One thing they concluded
is that we now know

28:24.744 --> 28:28.915
we can affect real-world behavior
and emotions

28:28.998 --> 28:32.877
without ever triggering
the user's awareness.

28:33.378 --> 28:37.382
They are completely clueless.

28:38.049 --> 28:41.970
We're pointing these engines of AI
back at ourselves

28:42.053 --> 28:46.224
to reverse-engineer what elicits responses
from us.

28:47.100 --> 28:49.561
Almost like you're stimulating nerve cells
on a spider

28:49.644 --> 28:51.479
to see what causes its legs to respond.

28:51.938 --> 28:53.940
So, it really is
this kind of prison experiment

28:54.023 --> 28:56.735
where we're just, you know,
roping people into the matrix,

28:56.818 --> 29:00.572
and we're just harvesting all this money
and... and data from all their activity

29:00.655 --> 29:01.489
to profit from.

29:01.573 --> 29:03.450
And we're not even aware
that it's happening.

29:04.117 --> 29:07.912
So, we want to psychologically figure out
how to manipulate you as fast as possible

29:07.996 --> 29:10.081
and then give you back that dopamine hit.

29:10.165 --> 29:12.375
We did that brilliantly at Facebook.

29:12.625 --> 29:14.919
Instagram has done it.
WhatsApp has done it.

29:15.003 --> 29:17.380
You know, Snapchat has done it.
Twitter has done it.

29:17.464 --> 29:19.424
I mean, it's exactly the kind of thing

29:19.507 --> 29:22.427
that a... that a hacker like myself
would come up with

29:22.510 --> 29:27.015
because you're exploiting a vulnerability
in... in human psychology.

29:27.807 --> 29:29.726
[chuckles] And I just...
I think that we...

29:29.809 --> 29:33.438
you know, the inventors, creators...

29:33.980 --> 29:37.317
uh, you know, and it's me, it's Mark,
it's the...

29:37.400 --> 29:40.403
you know, Kevin Systrom at Instagram...
It's all of these people...

29:40.487 --> 29:46.451
um, understood this consciously,
and we did it anyway.

29:50.580 --> 29:53.750
No one got upset when bicycles showed up.

29:55.043 --> 29:58.004
Right? Like, if everyone's starting
to go around on bicycles,

29:58.087 --> 30:00.924
no one said,
"Oh, my God, we've just ruined society.

30:01.007 --> 30:03.051
[chuckles]
Like, bicycles are affecting people.

30:03.134 --> 30:05.303
They're pulling people
away from their kids.

30:05.386 --> 30:08.723
They're ruining the fabric of democracy.
People can't tell what's true."

30:08.807 --> 30:11.476
Like, we never said any of that stuff
about a bicycle.

30:12.769 --> 30:16.147
If something is a tool,
it genuinely is just sitting there,

30:16.731 --> 30:18.733
waiting patiently.

30:19.317 --> 30:22.821
If something is not a tool,
it's demanding things from you.

30:22.904 --> 30:26.533
It's seducing you. It's manipulating you.
It wants things from you.

30:26.950 --> 30:30.495
And we've moved away from having
a tools-based technology environment

30:31.037 --> 30:34.499
to an addiction- and manipulation-based
technology environment.

30:34.582 --> 30:35.708
That's what's changed.

30:35.792 --> 30:39.420
Social media isn't a tool
that's just waiting to be used.

30:39.504 --> 30:43.466
It has its own goals,
and it has its own means of pursuing them

30:43.550 --> 30:45.677
by using your psychology against you.

30:45.760 --> 30:47.762
[ominous instrumental music playing]

30:57.564 --> 31:00.567
[Tim] Rewind a few years ago,
I was the...

31:00.650 --> 31:02.318
I was the president of Pinterest.

31:03.152 --> 31:05.113
I was coming home,

31:05.196 --> 31:08.366
and I couldn't get off my phone
once I got home,

31:08.449 --> 31:12.161
despite having two young kids
who needed my love and attention.

31:12.245 --> 31:15.748
I was in the pantry, you know,
typing away on an e-mail

31:15.832 --> 31:17.542
or sometimes looking at Pinterest.

31:18.001 --> 31:19.627
I thought, "God, this is classic irony.

31:19.711 --> 31:22.046
I am going to work during the day

31:22.130 --> 31:26.426
and building something
that then I am falling prey to."

31:26.509 --> 31:30.096
And I couldn't... I mean, some
of those moments, I couldn't help myself.

31:30.179 --> 31:31.848
-[notification chimes]
-[woman gasps]

31:32.307 --> 31:36.102
The one
that I'm... I'm most prone to is Twitter.

31:36.185 --> 31:38.021
Uh, used to be Reddit.

31:38.104 --> 31:42.859
I actually had to write myself software
to break my addiction to reading Reddit.

31:42.942 --> 31:44.903
-[notifications chime]
-[slot machines whir]

31:45.403 --> 31:47.780
I'm probably most addicted to my e-mail.

31:47.864 --> 31:49.866
I mean, really. I mean, I... I feel it.

31:49.949 --> 31:51.409
-[notifications chime]
-[woman gasps]

31:51.492 --> 31:52.493
[electricity crackles]

31:52.577 --> 31:54.954
Well, I mean, it's sort-- it's interesting

31:55.038 --> 31:58.166
that knowing what was going on
behind the curtain,

31:58.249 --> 32:01.628
I still wasn't able to control my usage.

32:01.711 --> 32:03.046
So, that's a little scary.

32:03.630 --> 32:07.050
Even knowing how these tricks work,
I'm still susceptible to them.

32:07.133 --> 32:09.886
I'll still pick up the phone,
and 20 minutes will disappear.

32:09.969 --> 32:11.387
[notifications chime]

32:11.471 --> 32:12.722
-[fluid rushes]
-[woman gasps]

32:12.805 --> 32:15.725
Do you check your smartphone
before you pee in the morning

32:15.808 --> 32:17.477
or while you're peeing in the morning?

32:17.560 --> 32:19.479
'Cause those are the only two choices.

32:19.562 --> 32:23.274
I tried through willpower,
just pure willpower...

32:23.358 --> 32:26.903
"I'll put down my phone, I'll leave
my phone in the car when I get home."

32:26.986 --> 32:30.573
I think I told myself a thousand times,
a thousand different days,

32:30.657 --> 32:32.617
"I am not gonna bring my phone
to the bedroom,"

32:32.700 --> 32:34.535
and then 9:00 p.m. rolls around.

32:34.619 --> 32:37.121
"Well, I wanna bring my phone
in the bedroom."

32:37.205 --> 32:39.290
[takes a deep breath]
And so, that was sort of...

32:39.374 --> 32:41.125
Willpower was kind of attempt one,

32:41.209 --> 32:44.295
and then attempt two was,
you know, brute force.

32:44.379 --> 32:48.091
[announcer] Introducing the Kitchen Safe.
The Kitchen Safe is a revolutionary,

32:48.174 --> 32:51.678
new, time-locking container
that helps you fight temptation.

32:51.761 --> 32:56.724
<i>All David has to do is place</i>
<i>those temptations in the Kitchen Safe.</i>

32:57.392 --> 33:00.395
<i>Next, he rotates the dial</i>
<i>to set the timer.</i>

33:01.479 --> 33:04.232
<i>And, finally, he presses the dial</i>
<i>to activate the lock.</i>

33:04.315 --> 33:05.525
<i>The Kitchen Safe is great...</i>

33:05.608 --> 33:06.776
We have that, don't we?

33:06.859 --> 33:08.653
<i>...video games, credit cards,</i>
<i>and cell phones.</i>

33:08.736 --> 33:09.654
Yeah, we do.

33:09.737 --> 33:12.407
[announcer] <i>Once the Kitchen Safe</i>
<i>is locked, it cannot be opened</i>

33:12.490 --> 33:13.866
<i>until the timer reaches zero.</i>

33:13.950 --> 33:15.618
[Anna] So, here's the thing.

33:15.702 --> 33:17.537
Social media is a drug.

33:17.620 --> 33:20.873
I mean,
we have a basic biological imperative

33:20.957 --> 33:23.084
to connect with other people.

33:23.167 --> 33:28.214
That directly affects the release
of dopamine in the reward pathway.

33:28.297 --> 33:32.552
Millions of years of evolution, um,
are behind that system

33:32.635 --> 33:35.596
to get us to come together
and live in communities,

33:35.680 --> 33:38.016
to find mates, to propagate our species.

33:38.099 --> 33:41.853
So, there's no doubt
that a vehicle like social media,

33:41.936 --> 33:45.690
which optimizes this connection
between people,

33:45.773 --> 33:48.568
is going to have the potential
for addiction.

33:52.071 --> 33:54.115
-Mmm! [laughs]
-Dad, stop!

33:55.450 --> 33:58.453
I have, like, 1,000 more snips
to send before dinner.

33:58.536 --> 34:00.788
-[dad] Snips?
-I don't know what a snip is.

34:00.872 --> 34:03.207
-Mm, that smells good, baby.
-All right. Thank you.

34:03.291 --> 34:05.877
I was, um, thinking we could use
all five senses

34:05.960 --> 34:07.712
to enjoy our dinner tonight.

34:07.795 --> 34:11.382
So, I decided that we're not gonna have
any cell phones at the table tonight.

34:11.466 --> 34:13.301
So, turn 'em in.

34:13.801 --> 34:14.802
-Really?
-[mom] Yep.

34:15.928 --> 34:18.056
-All right.
-Thank you. Ben?

34:18.139 --> 34:20.433
-Okay.
-Mom, the phone pirate. [scoffs]

34:21.100 --> 34:21.934
-Got it.
-Mom!

34:22.518 --> 34:26.147
So, they will be safe in here
until after dinner...

34:27.273 --> 34:30.651
-and everyone can just chill out.
-[safe whirs]

34:30.735 --> 34:31.569
Okay?

34:40.828 --> 34:41.704
[Cass sighs]

34:45.708 --> 34:47.043
[notification chimes]

34:47.418 --> 34:49.253
-Can I just see who it is?
-No.

34:54.759 --> 34:56.969
Just gonna go get another fork.

34:58.304 --> 34:59.263
Thank you.

35:04.727 --> 35:06.771
Honey, you can't open that.

35:06.854 --> 35:09.315
I locked it for an hour,
so just leave it alone.

35:11.192 --> 35:13.361
So, what should we talk about?

35:13.444 --> 35:14.695
Well, we could talk

35:14.779 --> 35:17.615
about the, uh, Extreme Center wackos
I drove by today.

35:17.698 --> 35:18.825
-[mom] Please, Frank.
-What?

35:18.908 --> 35:20.785
[mom] I don't wanna talk about politics.

35:20.868 --> 35:23.538
-What's wrong with the Extreme Center?
-See? He doesn't even get it.

35:23.621 --> 35:24.622
It depends on who you ask.

35:24.705 --> 35:26.624
It's like asking,
"What's wrong with propaganda?"

35:26.707 --> 35:28.376
-[safe smashes]
-[mom and Frank scream]

35:28.709 --> 35:29.710
[Frank] Isla!

35:32.797 --> 35:33.756
Oh, my God.

35:36.425 --> 35:38.553
-[sighs] Do you want me to...
-[mom] Yeah.

35:41.973 --> 35:43.933
[Anna] I... I'm worried about my kids.

35:44.016 --> 35:46.686
And if you have kids,
I'm worried about your kids.

35:46.769 --> 35:50.189
Armed with all the knowledge that I have
and all of the experience,

35:50.273 --> 35:52.108
I am fighting my kids about the time

35:52.191 --> 35:54.443
that they spend on phones
and on the computer.

35:54.527 --> 35:58.197
I will say to my son, "How many hours do
you think you're spending on your phone?"

35:58.281 --> 36:01.075
He'll be like, "It's, like, half an hour.
It's half an hour, tops."

36:01.159 --> 36:04.829
I'd say upwards hour, hour and a half.

36:04.912 --> 36:06.789
I looked at his screen report
a couple weeks ago.

36:06.873 --> 36:08.708
-Three hours and 45 minutes.
-[James] That...

36:11.377 --> 36:13.588
I don't think that's...
No. Per day, on average?

36:13.671 --> 36:15.506
-Yeah.
-Should I go get it right now?

36:15.590 --> 36:19.177
There's not a day that goes by
that I don't remind my kids

36:19.260 --> 36:21.762
about the pleasure-pain balance,

36:21.846 --> 36:24.390
about dopamine deficit states,

36:24.473 --> 36:26.267
about the risk of addiction.

36:26.350 --> 36:27.310
[Mary] Moment of truth.

36:27.935 --> 36:29.687
Two hours, 50 minutes per day.

36:29.770 --> 36:31.772
-Let's see.
-Actually, I've been using a lot today.

36:31.856 --> 36:33.357
-Last seven days.
-That's probably why.

36:33.441 --> 36:37.361
Instagram, six hours, 13 minutes.
Okay, so my Instagram's worse.

36:39.572 --> 36:41.991
My screen's completely shattered.

36:42.200 --> 36:43.201
Thanks, Cass.

36:44.410 --> 36:45.995
What do you mean, "Thanks, Cass"?

36:46.078 --> 36:49.040
You keep freaking Mom out about our phones
when it's not really a problem.

36:49.373 --> 36:51.167
We don't need our phones to eat dinner!

36:51.250 --> 36:53.878
I get what you're saying.
It's just not that big a deal. It's not.

36:56.047 --> 36:58.382
If it's not that big a deal,
don't use it for a week.

36:59.634 --> 37:00.593
[Ben sighs]

37:01.135 --> 37:06.349
Yeah. Yeah, actually, if you can put
that thing away for, like, a whole week...

37:07.725 --> 37:09.518
I will buy you a new screen.

37:10.978 --> 37:12.897
-Like, starting now?
-[mom] Starting now.

37:15.149 --> 37:16.859
-Okay. You got a deal.
-[mom] Okay.

37:16.943 --> 37:19.111
Okay, you gotta leave it here, though,
buddy.

37:19.862 --> 37:21.364
All right, I'm plugging it in.

37:22.531 --> 37:25.076
Let the record show... I'm backing away.

37:25.159 --> 37:25.993
Okay.

37:27.787 --> 37:29.413
-You're on the clock.
-[Ben] One week.

37:29.497 --> 37:30.331
Oh, my...

37:31.457 --> 37:32.416
Think he can do it?

37:33.000 --> 37:34.252
I don't know. We'll see.

37:35.002 --> 37:36.128
Just eat, okay?

37:44.220 --> 37:45.263
Good family dinner!

37:47.682 --> 37:49.809
[Tristan] These technology products
were not designed

37:49.892 --> 37:53.896
by child psychologists who are trying
to protect and nurture children.

37:53.980 --> 37:56.148
They were just designing
to make these algorithms

37:56.232 --> 37:58.734
that were really good at recommending
the next video to you

37:58.818 --> 38:02.321
or really good at getting you
to take a photo with a filter on it.

38:15.710 --> 38:16.669
[cell phone chimes]

38:16.752 --> 38:18.879
[Tristan] It's not just
that it's controlling

38:18.963 --> 38:20.548
where they spend their attention.

38:21.173 --> 38:26.304
Especially social media starts to dig
deeper and deeper down into the brain stem

38:26.387 --> 38:29.765
and take over kids' sense of self-worth
and identity.

38:41.736 --> 38:42.903
[notifications chiming]

38:52.371 --> 38:56.208
[Tristan] We evolved to care about
whether other people in our tribe...

38:56.751 --> 38:59.128
think well of us or not
'cause it matters.

38:59.837 --> 39:04.550
But were we evolved to be aware
of what 10,000 people think of us?

39:04.633 --> 39:08.763
We were not evolved
to have social approval being dosed to us

39:08.846 --> 39:10.348
every five minutes.

39:10.431 --> 39:13.142
That was not at all what we were built
to experience.

39:15.394 --> 39:19.982
[Chamath] We curate our lives
around this perceived sense of perfection

39:20.733 --> 39:23.527
because we get rewarded
in these short-term signals--

39:23.611 --> 39:25.154
hearts, likes, thumbs-up--

39:25.237 --> 39:28.407
and we conflate that with value,
and we conflate it with truth.

39:29.825 --> 39:33.120
And instead, what it really is
is fake, brittle popularity...

39:33.913 --> 39:37.458
that's short-term and that leaves you
even more, and admit it,

39:37.541 --> 39:39.919
vacant and empty before you did it.

39:41.295 --> 39:43.381
Because then it forces you
into this vicious cycle

39:43.464 --> 39:47.176
where you're like, "What's the next thing
I need to do now?Â 'Cause I need it back."

39:48.260 --> 39:50.846
Think about that compounded
by two billion people,

39:50.930 --> 39:54.767
and then think about how people react then
to the perceptions of others.

39:54.850 --> 39:56.435
It's just a... It's really bad.

39:56.977 --> 39:58.229
It's really, really bad.

40:00.856 --> 40:03.484
[Jonathan] There has been
a gigantic increase

40:03.567 --> 40:06.529
in depression and anxiety
for American teenagers

40:06.612 --> 40:10.950
which began right around...
between 2011 and 2013.

40:11.033 --> 40:15.371
The number of teenage girls out of 100,000
in this country

40:15.454 --> 40:17.123
who were admitted to a hospital every year

40:17.206 --> 40:19.917
because they cut themselves
or otherwise harmed themselves,

40:20.000 --> 40:23.921
that number was pretty stable
until around 2010, 2011,

40:24.004 --> 40:25.756
and then it begins going way up.

40:28.759 --> 40:32.513
It's up 62 percent for older teen girls.

40:33.848 --> 40:38.310
It's up 189 percent for the preteen girls.
That's nearly triple.

40:40.312 --> 40:43.524
Even more horrifying,
we see the same pattern with suicide.

40:44.775 --> 40:47.570
The older teen girls, 15 to 19 years old,

40:47.653 --> 40:49.196
they're up 70 percent,

40:49.280 --> 40:51.699
compared to the first decade
of this century.

40:52.158 --> 40:55.077
The preteen girls,
who have very low rates to begin with,

40:55.161 --> 40:57.663
they are up 151 percent.

40:58.831 --> 41:01.709
And that pattern points to social media.

41:04.044 --> 41:07.214
Gen Z, the kids born after 1996 or so,

41:07.298 --> 41:10.342
those kids are the first generation
in history

41:10.426 --> 41:12.636
that got on social media in middle school.

41:12.720 --> 41:14.722
[thunder rumbling in distance]

41:15.890 --> 41:17.600
[Jonathan] How do they spend their time?

41:19.727 --> 41:22.730
They come home from school,
and they're on their devices.

41:24.315 --> 41:29.195
A whole generation is more anxious,
more fragile, more depressed.

41:29.320 --> 41:30.529
-[thunder rumbles]
-[Isla gasps]

41:30.613 --> 41:33.282
[Jonathan] They're much less comfortable
taking risks.

41:34.325 --> 41:37.536
The rates at which they get
driver's licenses have been dropping.

41:38.954 --> 41:41.081
The number
who have ever gone out on a date

41:41.165 --> 41:44.251
or had any kind of romantic interaction
is dropping rapidly.

41:47.505 --> 41:49.715
This is a real change in a generation.

41:53.177 --> 41:57.306
And remember, for every one of these,
for every hospital admission,

41:57.389 --> 42:00.267
there's a family that is traumatized
and horrified.

42:00.351 --> 42:02.353
"My God, what is happening to our kids?"

42:08.734 --> 42:09.693
[Isla sighs]

42:19.411 --> 42:21.413
[Tim] It's plain as day to me.

42:22.873 --> 42:28.128
These services are killing people...
and causing people to kill themselves.

42:29.088 --> 42:33.300
I don't know any parent who says, "Yeah,
I really want my kids to be growing up

42:33.384 --> 42:36.887
feeling manipulated by tech designers, uh,

42:36.971 --> 42:39.723
manipulating their attention,
making it impossible to do their homework,

42:39.807 --> 42:42.560
making them compare themselves
to unrealistic standards of beauty."

42:42.643 --> 42:44.687
Like, no one wants that. [chuckles]

42:45.104 --> 42:46.355
No one does.

42:46.438 --> 42:48.482
We... We used to have these protections.

42:48.566 --> 42:50.943
When children watched
Saturday morning cartoons,

42:51.026 --> 42:52.778
we cared about protecting children.

42:52.861 --> 42:56.574
We would say, "You can't advertise
to these age children in these ways."

42:57.366 --> 42:58.784
But then you take YouTube for Kids,

42:58.867 --> 43:02.454
and it gobbles up that entire portion
of the attention economy,

43:02.538 --> 43:04.915
and now all kids are exposed
to YouTube for Kids.

43:04.999 --> 43:07.710
And all those protections
and all those regulations are gone.

43:08.210 --> 43:10.212
[tense instrumental music playing]

43:18.304 --> 43:22.141
[Tristan] We're training and conditioning
a whole new generation of people...

43:23.434 --> 43:29.148
that when we are uncomfortable or lonely
or uncertain or afraid,

43:29.231 --> 43:31.775
we have a digital pacifier for ourselves

43:32.234 --> 43:36.488
that is kind of atrophying our own ability
to deal with that.

43:53.881 --> 43:55.674
[Tristan] Photoshop didn't have
1,000 engineers

43:55.758 --> 43:58.969
on the other side of the screen,
using notifications, using your friends,

43:59.053 --> 44:02.431
using AI to predict what's gonna
perfectly addict you, or hook you,

44:02.514 --> 44:04.516
or manipulate you, or allow advertisers

44:04.600 --> 44:08.437
to test 60,000 variations
of text or colors to figure out

44:08.520 --> 44:11.065
what's the perfect manipulation
of your mind.

44:11.148 --> 44:14.985
This is a totally new species
of power and influence.

44:16.070 --> 44:19.156
I... I would say, again, the methods used

44:19.239 --> 44:22.785
to play on people's ability
to be addicted or to be influenced

44:22.868 --> 44:25.204
may be different this time,
and they probably are different.

44:25.287 --> 44:28.749
They were different when newspapers
came in and the printing press came in,

44:28.832 --> 44:31.835
and they were different
when television came in,

44:31.919 --> 44:34.004
and you had three major networks and...

44:34.463 --> 44:36.423
-At the time.
-At the time. That's what I'm saying.

44:36.507 --> 44:38.384
But I'm saying the idea
that there's a new level

44:38.467 --> 44:42.054
and that new level has happened
so many times before.

44:42.137 --> 44:45.099
I mean, this is just the latest new level
that we've seen.

44:45.182 --> 44:48.727
There's this narrative that, you know,
"We'll just adapt to it.

44:48.811 --> 44:51.188
We'll learn how to live
with these devices,

44:51.271 --> 44:53.732
just like we've learned how to live
with everything else."

44:53.816 --> 44:56.694
And what this misses
is there's something distinctly new here.

44:57.486 --> 45:00.155
Perhaps the most dangerous piece
of all this is the fact

45:00.239 --> 45:04.410
that it's driven by technology
that's advancing exponentially.

45:05.869 --> 45:09.081
Roughly, if you say from, like,
the 1960s to today,

45:09.873 --> 45:12.960
processing power has gone up
about a trillion times.

45:13.794 --> 45:18.340
Nothing else that we have has improved
at anything near that rate.

45:18.424 --> 45:22.177
Like, cars are, you know,
roughly twice as fast.

45:22.261 --> 45:25.013
And almost everything else is negligible.

45:25.347 --> 45:27.182
And perhaps most importantly,

45:27.266 --> 45:31.353
our human-- our physiology,
our brains have evolved not at all.

45:37.401 --> 45:41.488
[Tristan] Human beings, at a mind and body
and sort of physical level,

45:41.947 --> 45:43.866
are not gonna fundamentally change.

45:44.825 --> 45:45.868
[indistinct chatter]

45:47.035 --> 45:48.954
[chuckling] I know, but they...

45:49.037 --> 45:51.623
[continues speaking indistinctly]

45:53.584 --> 45:54.752
[camera shutter clicks]

45:56.837 --> 46:00.924
[Tristan] We can do genetic engineering
and develop new kinds of human beings,

46:01.008 --> 46:05.220
but realistically speaking,
you're living inside of hardware, a brain,

46:05.304 --> 46:07.222
that was, like, millions of years old,

46:07.306 --> 46:10.559
and then there's this screen, and then
on the opposite side of the screen,

46:10.642 --> 46:13.562
there's these thousands of engineers
and supercomputers

46:13.645 --> 46:16.106
that have goals that are different
than your goals,

46:16.190 --> 46:19.693
and so, who's gonna win in that game?
Who's gonna win?

46:25.699 --> 46:26.617
How are we losing?

46:27.159 --> 46:29.828
-I don't know.
-Where is he? This is not normal.

46:29.912 --> 46:32.080
Did I overwhelm him
with friends and family content?

46:32.164 --> 46:34.082
-Probably.
-Well, maybe it was all the ads.

46:34.166 --> 46:37.795
No. Something's very wrong.
Let's switch to resurrection mode.

46:39.713 --> 46:44.051
[Tristan] When you think of AI,
you know, an AI's gonna ruin the world,

46:44.134 --> 46:47.221
and you see, like, a Terminator,
and you see Arnold Schwarzenegger.

46:47.638 --> 46:48.680
I'll be back.

46:48.764 --> 46:50.933
[Tristan] You see drones,
and you think, like,

46:51.016 --> 46:52.684
"Oh, we're gonna kill people with AI."

46:53.644 --> 46:59.817
And what people miss is that AI
already runs today's world right now.

46:59.900 --> 47:03.237
Even talking about "an AI"
is just a metaphor.

47:03.320 --> 47:09.451
At these companies like... like Google,
there's just massive, massive rooms,

47:10.327 --> 47:13.121
some of them underground,
some of them underwater,

47:13.205 --> 47:14.498
of just computers.

47:14.581 --> 47:17.835
Tons and tons of computers,
as far as the eye can see.

47:18.460 --> 47:20.504
They're deeply interconnected
with each other

47:20.587 --> 47:22.923
and running
extremely complicated programs,

47:23.006 --> 47:26.009
sending information back and forth
between each other all the time.

47:26.802 --> 47:28.595
And they'll be running
many different programs,

47:28.679 --> 47:31.014
many different products
on those same machines.

47:31.348 --> 47:33.684
Some of those things could be described
as simple algorithms,

47:33.767 --> 47:35.227
some could be described as algorithms

47:35.310 --> 47:37.521
that are so complicated,
you would call them intelligence.

47:39.022 --> 47:39.982
[crew member sighs]

47:40.065 --> 47:42.568
[Cathy]
I like to say that algorithms are opinions

47:42.651 --> 47:43.777
embedded in code...

47:45.070 --> 47:47.656
and that algorithms are not objective.

47:48.365 --> 47:51.577
Algorithms are optimized
to some definition of success.

47:52.244 --> 47:53.370
So, if you can imagine,

47:53.453 --> 47:57.124
if a... if a commercial enterprise builds
an algorithm

47:57.207 --> 47:59.293
to their definition of success,

47:59.835 --> 48:01.211
it's a commercial interest.

48:01.587 --> 48:02.671
It's usually profit.

48:03.130 --> 48:07.384
You are giving the computer
the goal state, "I want this outcome,"

48:07.467 --> 48:10.262
and then the computer itself is learning
how to do it.

48:10.345 --> 48:12.598
That's where the term "machine learning"
comes from.

48:12.681 --> 48:14.850
And so, every day, it gets slightly better

48:14.933 --> 48:16.977
at picking the right posts
in the right order

48:17.060 --> 48:19.438
so that you spend longer and longer
in that product.

48:19.521 --> 48:22.232
And no one really understands
what they're doing

48:22.316 --> 48:23.901
in order to achieve that goal.

48:23.984 --> 48:28.238
The algorithm has a mind of its own,
so even though a person writes it,

48:28.906 --> 48:30.657
it's written in a way

48:30.741 --> 48:35.037
that you kind of build the machine,
and then the machine changes itself.

48:35.120 --> 48:37.873
There's only a handful of people
at these companies,

48:37.956 --> 48:40.000
at Facebook and Twitter
and other companies...

48:40.083 --> 48:43.795
There's only a few people who understand
how those systems work,

48:43.879 --> 48:46.715
and even they don't necessarily
fully understand

48:46.798 --> 48:49.551
what's gonna happen
with a particular piece of content.

48:49.968 --> 48:55.474
So, as humans, we've almost lost control
over these systems.

48:55.891 --> 48:59.603
Because they're controlling, you know,
the information that we see,

48:59.686 --> 49:02.189
they're controlling us more
than we're controlling them.

49:02.522 --> 49:04.733
-[console whirs]
-[Growth AI] Cross-referencing him

49:04.816 --> 49:07.319
against comparables
in his geographic zone.

49:07.402 --> 49:09.571
His psychometricÂ doppelgangers.

49:09.655 --> 49:13.700
There are 13,694 people
behaving just like him in his region.

49:13.784 --> 49:16.370
-What's trending with them?
-We need something actually good

49:16.453 --> 49:17.704
for a proper resurrection,

49:17.788 --> 49:19.957
given that the typical stuff
isn't working.

49:20.040 --> 49:21.875
Not even that cute girl from school.

49:22.334 --> 49:25.253
My analysis shows that going political
with Extreme Center content

49:25.337 --> 49:28.256
has a 62.3 percent chance
of long-term engagement.

49:28.340 --> 49:29.299
That's not bad.

49:29.383 --> 49:32.010
[sighs] It's not good enough to lead with.

49:32.302 --> 49:35.305
Okay, okay, so we've tried notifying him
about tagged photos,

49:35.389 --> 49:39.017
invitations, current events,
even a direct message fromÂ Rebecca.

49:39.101 --> 49:42.813
But what about User 01265923010?

49:42.896 --> 49:44.648
Yeah, Ben loved all of her posts.

49:44.731 --> 49:47.776
For months and, like,
literally all of them, and then nothing.

49:47.859 --> 49:50.445
I calculate a 92.3 percent chance
of resurrection

49:50.529 --> 49:52.030
with a notification about Ana.

49:56.535 --> 49:57.494
And her new friend.

49:59.621 --> 50:01.623
[eerie instrumental music playing]

50:10.590 --> 50:11.675
[cell phone vibrates]

50:25.689 --> 50:27.441
[Ben] Oh, you gotta be kiddin' me.

50:32.404 --> 50:33.613
Uh... [sighs]

50:35.657 --> 50:36.616
Okay.

50:38.869 --> 50:40.996
-What?
-[fanfare plays, fireworks pop]

50:41.413 --> 50:42.789
[claps] Bam! We're back!

50:42.873 --> 50:44.374
Let's get back to making money, boys.

50:44.458 --> 50:46.334
Yes, and connecting Ben
with the entire world.

50:46.418 --> 50:49.087
I'm giving him access
to all the information he might like.

50:49.755 --> 50:53.717
Hey, do you guys ever wonder if, you know,
like, the feed is good for Ben?

50:57.095 --> 50:58.430
-No.
-No. [chuckles slightly]

51:00.307 --> 51:03.268
-[chuckles softly]
-["I Put a Spell on You" playing]

51:17.491 --> 51:19.076
âª<i> I put a spell on youÂ </i>âª

51:25.040 --> 51:26.374
âª<i> 'Cause you're mineÂ </i>âª

51:28.627 --> 51:32.089
[vocalizing] <i>âª Ah! âª</i>

51:34.508 --> 51:36.593
âª<i> You better stop the things you do</i> âª

51:41.181 --> 51:42.265
âª<i> I ain't lyin' </i>âª

51:44.976 --> 51:46.686
âª<i> No, I ain't lyin' </i>âª

51:49.981 --> 51:51.817
âª<i> You know I can't stand it </i>âª

51:53.026 --> 51:54.611
âª<i> You're runnin' aroundÂ </i>âª

51:55.612 --> 51:57.239
âª<i> You know better, DaddyÂ </i>âª

51:58.782 --> 52:02.077
âª<i> I can't stand it</i>
<i>'Cause you put me down</i> <i>âª</i>

52:03.286 --> 52:04.121
âª<i> Yeah, yeahÂ </i>âª

52:06.456 --> 52:08.375
âª<i> I put a spell on youÂ </i>âª

52:12.379 --> 52:14.840
âª<i> Because you're mine </i>âª

52:18.718 --> 52:19.845
<i>âª You're mine âª</i>

52:20.929 --> 52:24.349
[Roger] So, imagine you're on Facebook...

52:24.766 --> 52:29.312
and you're effectively playing
against this artificial intelligence

52:29.396 --> 52:31.314
that knows everything about you,

52:31.398 --> 52:34.568
can anticipate your next move,
and you know literally nothing about it,

52:34.651 --> 52:37.404
except that there are cat videos
and birthdays on it.

52:37.821 --> 52:39.656
That's not a fair fight.

52:41.575 --> 52:43.869
Ben and Jerry, it's time to go, bud!

52:48.039 --> 52:48.874
[sighs]

52:51.126 --> 52:51.960
Ben?

53:01.011 --> 53:02.137
[knocks lightly on door]

53:02.679 --> 53:04.723
-[Cass] Ben.
-[Ben] Mm.

53:05.182 --> 53:06.057
Come on.

53:07.225 --> 53:08.351
School time. [claps]

53:08.435 --> 53:09.269
Let's go.

53:12.189 --> 53:13.148
[Ben sighs]

53:25.118 --> 53:27.120
[excited chatter]

53:31.374 --> 53:33.627
-[tech] How you doing today?
-Oh, I'm... I'm nervous.

53:33.710 --> 53:35.003
-Are ya?
-Yeah. [chuckles]

53:37.380 --> 53:39.132
[Tristan]
We were all looking for the moment

53:39.216 --> 53:42.969
when technology would overwhelm
human strengths and intelligence.

53:43.053 --> 53:47.015
When is it gonna cross the singularity,
replace our jobs, be smarter than humans?

53:48.141 --> 53:50.101
But there's this much earlier moment...

53:50.977 --> 53:55.315
when technology exceeds
and overwhelms human weaknesses.

53:57.484 --> 54:01.780
This point being crossed
is at the root of addiction,

54:02.113 --> 54:04.741
polarization, radicalization,
outrage-ification,

54:04.824 --> 54:06.368
vanity-ification, the entire thing.

54:07.702 --> 54:09.913
This is overpowering human nature,

54:10.538 --> 54:13.500
and this is checkmate on humanity.

54:20.131 --> 54:21.883
-[sighs deeply]
-[door opens]

54:30.558 --> 54:31.851
I'm sorry. [sighs]

54:37.607 --> 54:39.609
-[seat belt clicks]
-[engine starts]

54:41.736 --> 54:44.656
[Jaron] One of the ways
I try to get people to understand

54:45.198 --> 54:49.828
just how wrong feeds from places
like Facebook are

54:49.911 --> 54:51.454
is to think about the Wikipedia.

54:52.956 --> 54:56.209
When you go to a page, you're seeing
the same thing as other people.

54:56.584 --> 55:00.297
So, it's one of the few things online
that we at least hold in common.

55:00.380 --> 55:03.425
Now, just imagine for a second
that Wikipedia said,

55:03.508 --> 55:07.178
"We're gonna give each person
a different customized definition,

55:07.262 --> 55:09.472
and we're gonna be paid by people
for that."

55:09.556 --> 55:13.435
So, Wikipedia would be spying on you.
Wikipedia would calculate,

55:13.518 --> 55:17.188
"What's the thing I can do
to get this person to change a little bit

55:17.272 --> 55:19.899
on behalf of some commercial interest?"
Right?

55:19.983 --> 55:21.818
And then it would change the entry.

55:22.444 --> 55:24.738
Can you imagine that?
Well, you should be able to,

55:24.821 --> 55:26.823
'cause that's exactly what's happening
on Facebook.

55:26.906 --> 55:28.992
It's exactly what's happening
in your YouTube feed.

55:29.075 --> 55:31.786
When you go to Google and type in
"Climate change is,"

55:31.870 --> 55:34.998
you're going to see different results
depending on where you live.

55:36.166 --> 55:38.460
In certain cities,
you're gonna see itÂ autocomplete

55:38.543 --> 55:40.462
with "climate change is a hoax."

55:40.545 --> 55:42.088
In other cases, you're gonna see

55:42.172 --> 55:44.841
"climate change is causing the destruction
of nature."

55:44.924 --> 55:48.428
And that's a function not
of what the truth is about climate change,

55:48.511 --> 55:51.097
but about
where you happen to be Googling from

55:51.181 --> 55:54.100
and the particular things
Google knows about your interests.

55:54.851 --> 55:58.021
Even two friends
who are so close to each other,

55:58.104 --> 56:00.190
who have almost the exact same set
of friends,

56:00.273 --> 56:02.817
they think, you know,
"I'm going to news feeds on Facebook.

56:02.901 --> 56:05.403
I'll see the exact same set of updates."

56:05.487 --> 56:06.738
But it's not like that at all.

56:06.821 --> 56:08.448
They see completely different worlds

56:08.531 --> 56:10.575
because they're based
on these computers calculating

56:10.658 --> 56:12.035
what's perfect for each of them.

56:12.118 --> 56:14.245
[whistling over monitor]

56:14.329 --> 56:18.416
[Roger] The way to think about it
is it's 2.7 billion <i>Truman Shows.</i>

56:18.500 --> 56:21.294
Each person has their own reality,
with their own...

56:22.670 --> 56:23.671
facts.

56:23.755 --> 56:27.008
<i>Why do you think</i>
<i>that, uh, Truman has never come close</i>

56:27.092 --> 56:30.095
<i>to discovering the true nature</i>
<i>of his world until now?</i>

56:31.054 --> 56:34.140
We accept the reality of the world
with which we're presented.

56:34.224 --> 56:35.141
It's as simple as that.

56:36.476 --> 56:41.064
Over time, you have the false sense
that everyone agrees with you,

56:41.147 --> 56:44.067
because everyone in your news feed
sounds just like you.

56:44.567 --> 56:49.072
And that once you're in that state,
it turns out you're easily manipulated,

56:49.155 --> 56:51.741
the same way you would be manipulated
by a magician.

56:51.825 --> 56:55.370
A magician shows you a card trick
and says, "Pick a card, any card."

56:55.453 --> 56:58.164
What you don't realize
was that they've done a set-up,

56:58.456 --> 57:00.583
so you pick the card
they want you to pick.

57:00.667 --> 57:03.169
And that's how Facebook works.
Facebook sits there and says,

57:03.253 --> 57:06.172
"Hey, you pick your friends.
You pick the links that you follow."

57:06.256 --> 57:08.716
But that's all nonsense.
It's just like the magician.

57:08.800 --> 57:11.302
Facebook is in charge of your news feed.

57:11.386 --> 57:14.514
We all simply are operating
on a different set of facts.

57:14.597 --> 57:16.474
When that happens at scale,

57:16.558 --> 57:20.645
you're no longer able to reckon with
or even consume information

57:20.728 --> 57:23.690
that contradicts with that world view
that you've created.

57:23.773 --> 57:26.443
That means we aren't actually being
objective,

57:26.526 --> 57:28.319
constructive individuals. [chuckles]

57:28.403 --> 57:32.449
[crowd chanting] Open up your eyes,
don't believe the lies! Open up...

57:32.532 --> 57:34.701
[Justin] And then you look
over at the other side,

57:35.243 --> 57:38.746
and you start to think,
"How can those people be so stupid?

57:38.830 --> 57:42.125
Look at all of this information
that I'm constantly seeing.

57:42.208 --> 57:44.627
How are they not seeing
that same information?"

57:44.711 --> 57:47.297
And the answer is, "They're not seeing
that same information."

57:47.380 --> 57:50.800
[crowd continues chanting]
Open up your eyes, don't believe the lies!

57:50.884 --> 57:52.010
[shouting indistinctly]

57:52.093 --> 57:55.472
-[interviewer] What are Republicans like?
-People that don't have a clue.

57:55.555 --> 57:58.933
The Democrat Party is a crime syndicate,
not a real political party.

57:59.017 --> 58:03.188
A huge new Pew Research Center study
of 10,000 American adults

58:03.271 --> 58:05.315
finds us more divided than ever,

58:05.398 --> 58:09.152
withÂ personal and political polarization
at a 20-year high.

58:11.738 --> 58:14.199
[pundit] You have
more than a third of Republicans saying

58:14.282 --> 58:16.826
the Democratic Party is a threat
to the nation,

58:16.910 --> 58:20.580
more than a quarter of Democrats saying
the same thing about the Republicans.

58:20.663 --> 58:22.499
So many of the problems
that we're discussing,

58:22.582 --> 58:24.417
like, around political polarization

58:24.501 --> 58:28.046
exist in spades on cable television.

58:28.129 --> 58:31.007
The media has this exact same problem,

58:31.090 --> 58:33.343
where their business model, by and large,

58:33.426 --> 58:35.762
is that they're selling our attention
to advertisers.

58:35.845 --> 58:38.890
And the Internet is just a new,
even more efficient way to do that.

58:40.141 --> 58:44.145
[Guillaume] At YouTube, I was working
on YouTube recommendations.

58:44.229 --> 58:47.148
It worries me that an algorithm
that I worked on

58:47.232 --> 58:50.401
is actually increasing polarization
in society.

58:50.485 --> 58:53.112
But from the point of view of watch time,

58:53.196 --> 58:57.617
this polarization is extremely efficient
at keeping people online.

58:58.785 --> 59:00.870
<i>The only reason</i>
<i>these teachers are teaching this stuff</i>

59:00.954 --> 59:02.288
<i>is 'cause they're getting paid to.</i>

59:02.372 --> 59:04.374
<i>-It's absolutely absurd.</i>
-[Cass] Hey, Benji.

59:04.916 --> 59:06.292
No soccer practice today?

59:06.376 --> 59:08.795
Oh, there is. I'm just catching up
on some news stuff.

59:08.878 --> 59:11.506
[vlogger] <i>Do research. Anything</i>
<i>that sways from the Extreme Center--</i>

59:11.589 --> 59:14.008
Wouldn't exactly call the stuff
that you're watching news.

59:15.552 --> 59:18.846
You're always talking about how messed up
everything is. So are they.

59:19.305 --> 59:21.140
But that stuff is just propaganda.

59:21.224 --> 59:24.060
[vlogger] <i>Neither is true.</i>
<i>It's all about what makes sense.</i>

59:24.769 --> 59:26.938
Ben, I'm serious.
That stuff is bad for you.

59:27.021 --> 59:29.232
-You should go to soccer practice.
-[Ben] Mm.

59:31.109 --> 59:31.943
[Cass sighs]

59:35.154 --> 59:37.490
<i>I share this stuff because I care.</i>

59:37.574 --> 59:41.077
<i>I care that you are being misled,</i>
<i>and it's not okay. All right?</i>

59:41.160 --> 59:43.121
[Guillaume] People think
the algorithm is designed

59:43.204 --> 59:46.833
to give them what they really want,
only it's not.

59:46.916 --> 59:52.589
The algorithm is actually trying to find
a few rabbit holes that are very powerful,

59:52.672 --> 59:56.217
trying to find which rabbit hole
is the closest to your interest.

59:56.301 --> 59:59.262
And then if you start watching
one of those videos,

59:59.846 --> 1:00:02.223
then it will recommend it
over and over again.

1:00:02.682 --> 1:00:04.934
It's not like anybody wants this
to happen.

1:00:05.018 --> 1:00:07.812
It's just that this is
what the recommendation system is doing.

1:00:07.895 --> 1:00:10.815
So much so that Kyrie Irving,
the famous basketball player,

1:00:11.065 --> 1:00:14.235
uh, said he believed the Earth was flat,
and he apologized later

1:00:14.319 --> 1:00:16.154
because he blamed it
on a YouTube rabbit hole.

1:00:16.487 --> 1:00:18.656
You know, like,
you click the YouTube click

1:00:18.740 --> 1:00:21.534
and it goes, like,
how deep the rabbit hole goes.

1:00:21.618 --> 1:00:23.369
When he later came on to NPR to say,

1:00:23.453 --> 1:00:25.955
"I'm sorry for believing this.
I didn't want to mislead people,"

1:00:26.039 --> 1:00:28.291
a bunch of students in a classroom
were interviewed saying,

1:00:28.374 --> 1:00:29.667
"The round-Earthers got to him."

1:00:29.751 --> 1:00:30.960
[audience chuckles]

1:00:31.044 --> 1:00:33.963
The flat-Earth conspiracy theory
was recommended

1:00:34.047 --> 1:00:37.634
hundreds of millions of times
by the algorithm.

1:00:37.717 --> 1:00:43.890
It's easy to think that it's just
a few stupid people who get convinced,

1:00:43.973 --> 1:00:46.893
but the algorithm is getting smarter
and smarter every day.

1:00:46.976 --> 1:00:50.188
So, today, they are convincing the people
that the Earth is flat,

1:00:50.271 --> 1:00:53.983
but tomorrow, they will be convincing <i>you</i>
of something that's false.

1:00:54.317 --> 1:00:57.820
[reporter] <i>On November 7th,</i>
<i>the hashtag "Pizzagate" was born.</i>

1:00:57.904 --> 1:00:59.197
[RenÃ©e] Pizzagate...

1:01:00.114 --> 1:01:01.449
[clicks tongue] Oh, boy.

1:01:01.532 --> 1:01:02.533
Uh... [laughs]

1:01:03.159 --> 1:01:06.913
I still am not 100 percent sure
how this originally came about,

1:01:06.996 --> 1:01:12.377
but the idea that ordering a pizza
meant ordering a trafficked person.

1:01:12.460 --> 1:01:15.046
As the groups got bigger on Facebook,

1:01:15.129 --> 1:01:19.967
Facebook's recommendation engine
started suggesting to regular users

1:01:20.051 --> 1:01:21.761
that they join Pizzagate groups.

1:01:21.844 --> 1:01:27.392
So, if a user was, for example,
anti-vaccine or believed in chemtrails

1:01:27.475 --> 1:01:30.645
or had indicated to Facebook's algorithms
in some way

1:01:30.728 --> 1:01:33.398
that they were prone to belief
in conspiracy theories,

1:01:33.481 --> 1:01:36.859
Facebook's recommendation engine
would serve themÂ Pizzagate groups.

1:01:36.943 --> 1:01:41.072
Eventually, this culminated in
a man showing up with a gun,

1:01:41.155 --> 1:01:44.617
deciding that he was gonna go liberate
the children from the basement

1:01:44.701 --> 1:01:46.911
of the pizza place
that did not have a basement.

1:01:46.994 --> 1:01:48.538
[officer 1] What were you doing?

1:01:48.871 --> 1:01:50.498
[man] Making sure
there was nothing there.

1:01:50.581 --> 1:01:52.458
-[officer 1] Regarding?
-[man] Pedophile ring.

1:01:52.542 --> 1:01:54.293
-[officer 1] What?
-[man] Pedophile ring.

1:01:54.377 --> 1:01:55.962
[officer 2] He's talking about Pizzagate.

1:01:56.045 --> 1:02:00.216
This is an example of a conspiracy theory

1:02:00.299 --> 1:02:03.678
that was propagated
across all social networks.

1:02:03.761 --> 1:02:06.097
The social network's
own recommendation engine

1:02:06.180 --> 1:02:07.974
is voluntarily serving this up to people

1:02:08.057 --> 1:02:10.643
who had never searched
for the term "Pizzagate" in their life.

1:02:12.437 --> 1:02:14.439
[Tristan] There's a study, an MIT study,

1:02:14.522 --> 1:02:19.819
that fake news on Twitter spreads
six times faster than true news.

1:02:19.902 --> 1:02:21.863
What is that world gonna look like

1:02:21.946 --> 1:02:24.741
when one has a six-times advantage
to the other one?

1:02:25.283 --> 1:02:27.660
You can imagine
these things are sort of like...

1:02:27.744 --> 1:02:31.706
they... they tilt the floor
of... of human behavior.

1:02:31.789 --> 1:02:34.709
They make some behavior harder
and some easier.

1:02:34.792 --> 1:02:37.420
And you're always free
to walk up the hill,

1:02:37.503 --> 1:02:38.796
but fewer people do,

1:02:38.880 --> 1:02:43.092
and so, at scale, at society's scale,
you really are just tilting the floor

1:02:43.176 --> 1:02:45.970
and changing what billions of people think
and do.

1:02:46.053 --> 1:02:52.018
We've created a system
that biases towards false information.

1:02:52.643 --> 1:02:54.437
Not because we want to,

1:02:54.520 --> 1:02:58.816
but because false information makes
the companies more money

1:02:59.400 --> 1:03:01.319
than the truth. The truth is boring.

1:03:01.986 --> 1:03:04.489
It's a disinformation-for-profit
business model.

1:03:04.906 --> 1:03:08.159
You make money the more you allow
unregulated messages

1:03:08.701 --> 1:03:11.287
to reach anyone for the best price.

1:03:11.662 --> 1:03:13.956
<i>Because climate change? Yeah.</i>

1:03:14.040 --> 1:03:16.751
<i>It's a hoax. Yeah, it's real.</i>
<i>That's the point.</i>

1:03:16.834 --> 1:03:20.046
<i>The more they talk about it</i>
<i>and the more they divide us,</i>

1:03:20.129 --> 1:03:22.423
<i>the more they have the power,</i>
<i>the more...</i>

1:03:22.507 --> 1:03:25.468
[Tristan] Facebook has trillions
of these news feed posts.

1:03:26.552 --> 1:03:29.180
They can't know what's real
or what's true...

1:03:29.972 --> 1:03:33.726
which is why this conversation
is so critical right now.

1:03:33.810 --> 1:03:37.021
[reporter 1] <i>It's not just COVID-19</i>
<i>that's spreading fast.</i>

1:03:37.104 --> 1:03:40.191
<i>There's a flow of misinformation online</i>
<i>about the virus.</i>

1:03:40.274 --> 1:03:41.818
[reporter 2]<i> The notion</i>
<i>drinking water</i>

1:03:41.901 --> 1:03:43.694
<i>will flush coronavirus from your system</i>

1:03:43.778 --> 1:03:47.490
<i>is one of several myths about the virus</i>
<i>circulating on social media.</i>

1:03:47.573 --> 1:03:50.451
[automated voice] <i>The government planned</i>
<i>this event, created the virus,</i>

1:03:50.535 --> 1:03:53.621
<i>and had a simulation</i>
<i>of how the countries would react.</i>

1:03:53.955 --> 1:03:55.581
Coronavirus is a... a hoax.

1:03:56.165 --> 1:03:57.959
[man] SARS, coronavirus.

1:03:58.376 --> 1:04:01.045
And look at when it was made. 2018.

1:04:01.128 --> 1:04:03.798
I think the US government started
this shit.

1:04:04.215 --> 1:04:09.095
Nobody is sick. Nobody is sick.
Nobody knows anybody who's sick.

1:04:09.512 --> 1:04:13.015
Maybe the government is using
the coronavirus as an excuse

1:04:13.099 --> 1:04:15.643
to get everyone to stay inside
because something else is happening.

1:04:15.726 --> 1:04:18.020
Coronavirus is not killing people,

1:04:18.104 --> 1:04:20.940
it's the 5G radiation
that they're pumping out.

1:04:21.023 --> 1:04:22.525
[crowd shouting]

1:04:22.608 --> 1:04:24.944
[Tristan]
<i>We're being bombarded with rumors.</i>

1:04:25.403 --> 1:04:28.823
<i>People are blowing up</i>
<i>actual physical cell phone towers.</i>

1:04:28.906 --> 1:04:32.201
<i>We see Russia and China spreading rumors</i>
<i>and conspiracy theories.</i>

1:04:32.285 --> 1:04:35.246
[reporter 3] <i>This morning,</i>
<i>panic and protest in Ukraine as...</i>

1:04:35.329 --> 1:04:38.916
[Tristan] <i>People have no idea what's true,</i>
<i>and now it's a matter of life and death.</i>

1:04:39.876 --> 1:04:42.628
[woman] Those sources that are spreading
coronavirus misinformation

1:04:42.712 --> 1:04:45.798
have amassed
something like 52 million engagements.

1:04:45.882 --> 1:04:50.094
You're saying that silver solution
would be effective.

1:04:50.177 --> 1:04:54.140
Well, let's say it hasn't been tested
on this strain of the coronavirus, but...

1:04:54.223 --> 1:04:57.226
[Tristan] <i>What we're seeing with COVID</i>
<i>is just an extreme version</i>

1:04:57.310 --> 1:05:00.521
<i>of what's happening</i>
<i>across our information ecosystem.</i>

1:05:00.938 --> 1:05:05.026
<i>Social media amplifies exponential gossip</i>
<i>and exponential hearsay</i>

1:05:05.109 --> 1:05:07.111
<i>to the point</i>
<i>that we don't know what's true,</i>

1:05:07.194 --> 1:05:08.946
<i>no matter what issue we care about.</i>

1:05:15.161 --> 1:05:16.579
[teacher] He discovers this.

1:05:16.662 --> 1:05:18.664
[continues lecturing indistinctly]

1:05:19.874 --> 1:05:21.292
[Rebecca whispers] Ben.

1:05:26.130 --> 1:05:28.257
-Are you still on the team?
-[Ben] Mm-hmm.

1:05:30.384 --> 1:05:32.678
[Rebecca] Okay, well,
I'm gonna get a snackÂ before practice

1:05:32.762 --> 1:05:34.430
if you... wanna come.

1:05:35.640 --> 1:05:36.515
[Ben] Hm?

1:05:36.974 --> 1:05:38.601
[Rebecca] You know, never mind.

1:05:38.684 --> 1:05:40.686
[footsteps fading]

1:05:45.066 --> 1:05:47.526
[vlogger] <i>Nine out of ten people</i>
<i>are dissatisfied right now.</i>

1:05:47.610 --> 1:05:50.613
<i>The EC is like any political movement</i>
<i>in history, when you think about it.</i>

1:05:50.696 --> 1:05:54.492
<i>We are standing up, and we are...</i>
<i>we are standing up to this noise.</i>

1:05:54.575 --> 1:05:57.036
<i>You are my people. I trust you guys.</i>

1:05:59.246 --> 1:06:02.583
-The Extreme Center content is brilliant.
<i>-</i>He absolutely loves it.

1:06:02.667 --> 1:06:03.626
Running an auction.

1:06:04.627 --> 1:06:08.547
840 bidders. He sold for 4.35 cents
to a weapons manufacturer.

1:06:08.631 --> 1:06:10.800
Let's promote some of these events.

1:06:10.883 --> 1:06:13.511
Upcoming rallies in his geographic zone
later this week.

1:06:13.594 --> 1:06:15.179
I've got a new vlogger lined up, too.

1:06:15.262 --> 1:06:16.263
[chuckles]

1:06:17.765 --> 1:06:22.979
<i>And... and, honestly, I'm telling you,</i>
<i>I'm willing to do whatever it takes.</i>

1:06:23.062 --> 1:06:24.939
<i>And I mean whatever.</i>

1:06:32.154 --> 1:06:33.197
<i>-Subscribe...</i>
-[Cass] Ben?

1:06:33.280 --> 1:06:35.908
<i>...and also come back</i>
<i>because I'm telling you, yo...</i>

1:06:35.992 --> 1:06:38.869
-[knocking on door]
<i>-...I got some real big things comin'.</i>

1:06:38.953 --> 1:06:40.162
<i>Some real big things.</i>

1:06:40.788 --> 1:06:45.292
[Roger] One of the problems with Facebook
is that, as a tool of persuasion,

1:06:45.793 --> 1:06:47.920
it may be the greatest thing ever created.

1:06:48.004 --> 1:06:52.508
Now, imagine what that means in the hands
of a dictator or an authoritarian.

1:06:53.718 --> 1:06:57.638
If you want to control the population
of your country,

1:06:57.722 --> 1:07:01.308
there has never been a tool
as effective as Facebook.

1:07:04.937 --> 1:07:07.398
[Cynthia]
Some of the most troubling implications

1:07:07.481 --> 1:07:10.985
of governments and other bad actors
weaponizing social media,

1:07:11.235 --> 1:07:13.612
um, is that it has led
to real, offline harm.

1:07:13.696 --> 1:07:15.072
I think the most prominent example

1:07:15.156 --> 1:07:17.658
that's gotten a lot of press
is what's happened in Myanmar.

1:07:19.243 --> 1:07:21.203
In Myanmar,
when people think of the Internet,

1:07:21.287 --> 1:07:22.913
what they are thinking about is Facebook.

1:07:22.997 --> 1:07:25.916
And what often happens is
when people buy their cell phone,

1:07:26.000 --> 1:07:29.920
the cell phone shop owner will actually
preload Facebook on there for them

1:07:30.004 --> 1:07:31.505
and open an account for them.

1:07:31.589 --> 1:07:34.884
And so when people get their phone,
the first thing they open

1:07:34.967 --> 1:07:37.595
and the only thing they know how to open
is Facebook.

1:07:38.179 --> 1:07:41.891
Well, a new bombshell investigation
exposes Facebook's growing struggle

1:07:41.974 --> 1:07:43.809
to tackle hate speech in Myanmar.

1:07:43.893 --> 1:07:46.020
[crowd shouting]

1:07:46.103 --> 1:07:49.190
Facebook really gave the military
and other bad actors

1:07:49.273 --> 1:07:51.776
a new way to manipulate public opinion

1:07:51.859 --> 1:07:55.529
and to help incite violence
against the Rohingya Muslims

1:07:55.613 --> 1:07:57.406
that included mass killings,

1:07:58.115 --> 1:07:59.867
burning of entire villages,

1:07:59.950 --> 1:08:03.704
mass rape, and other serious crimes
against humanity

1:08:03.788 --> 1:08:04.955
that have now led

1:08:05.039 --> 1:08:08.209
to 700,000Â Rohingya Muslims
having to flee the country.

1:08:11.170 --> 1:08:14.799
It's not
that highly motivated propagandists

1:08:14.882 --> 1:08:16.550
haven't existed before.

1:08:16.634 --> 1:08:19.762
It's that the platforms make it possible

1:08:19.845 --> 1:08:23.724
to spread manipulative narratives
with phenomenal ease,

1:08:23.808 --> 1:08:25.434
and without very much money.

1:08:25.518 --> 1:08:27.812
If I want to manipulate an election,

1:08:27.895 --> 1:08:30.564
I can now go into
a conspiracy theory group on Facebook,

1:08:30.648 --> 1:08:32.233
and I can find 100 people

1:08:32.316 --> 1:08:34.443
who believe
that the Earth is completely flat

1:08:34.860 --> 1:08:37.780
and think it's all this conspiracy theory
that we landed on the moon,

1:08:37.863 --> 1:08:41.450
and I can tell Facebook,
"Give me 1,000 users who look like that."

1:08:42.118 --> 1:08:46.080
Facebook will happily send me
thousands of users that look like them

1:08:46.163 --> 1:08:49.250
that I can now hit
with more conspiracy theories.

1:08:50.376 --> 1:08:53.087
-[button clicks]
-Sold for 3.4 cents an impression.

1:08:53.379 --> 1:08:56.382
-New EC video to promote.
-[Advertising AI] Another ad teed up.

1:08:58.509 --> 1:09:00.928
[Justin] Algorithms
and manipulative politicians

1:09:01.011 --> 1:09:02.138
are becoming so expert

1:09:02.221 --> 1:09:04.056
at learning how to trigger us,

1:09:04.140 --> 1:09:08.352
getting so good at creating fake news
that we absorb as if it were reality,

1:09:08.435 --> 1:09:10.813
and confusing us into believing
those lies.

1:09:10.896 --> 1:09:12.606
It's as though we have
less and less control

1:09:12.690 --> 1:09:14.150
over who we are and what we believe.

1:09:14.233 --> 1:09:16.235
[ominous instrumental music playing]

1:09:31.375 --> 1:09:32.835
[vlogger] <i>...so they can pick sides.</i>

1:09:32.918 --> 1:09:34.879
<i>There's lies here,</i>
<i>and there's lies over there.</i>

1:09:34.962 --> 1:09:36.338
<i>So they can keep the power,</i>

1:09:36.422 --> 1:09:39.967
<i>-so they can control everything.</i>
-[police siren blaring]

1:09:40.050 --> 1:09:42.553
[vlogger] <i>They can control our minds,</i>

1:09:42.636 --> 1:09:46.390
<i>-so that they can keep their secrets.</i>
-[crowd chanting]

1:09:48.517 --> 1:09:50.895
[Tristan] Imagine a world
where no one believes anything true.

1:09:52.897 --> 1:09:55.649
Everyone believes
the government's lying to them.

1:09:56.317 --> 1:09:58.444
Everything is a conspiracy theory.

1:09:58.527 --> 1:10:01.197
"I shouldn't trust anyone.
I hate the other side."

1:10:01.280 --> 1:10:02.698
That's where all this is heading.

1:10:02.781 --> 1:10:06.160
The political earthquakes in Europe
continue to rumble.

1:10:06.243 --> 1:10:08.412
This time, in Italy and Spain.

1:10:08.495 --> 1:10:11.999
[reporter] <i>Overall, Europe's traditional,</i>
<i>centrist coalition lost its majority</i>

1:10:12.082 --> 1:10:15.002
<i>while far right</i>
<i>and far left populist parties made gains.</i>

1:10:15.085 --> 1:10:16.086
[man shouts]

1:10:16.170 --> 1:10:17.504
[crowd chanting]

1:10:19.757 --> 1:10:20.591
Back up.

1:10:21.300 --> 1:10:22.509
-[radio beeps]
-Okay, let's go.

1:10:24.845 --> 1:10:26.847
[police siren wailing]

1:10:28.390 --> 1:10:31.268
[reporter] <i>These accounts</i>
<i>were deliberately, specifically attempting</i>

1:10:31.352 --> 1:10:34.355
<i>-to sow political discord in Hong Kong.</i>
-[crowd shouting]

1:10:36.440 --> 1:10:37.399
[sighs]

1:10:38.609 --> 1:10:40.361
-All right, Ben.
-[car doors lock]

1:10:42.863 --> 1:10:45.032
What does it look like to be a country

1:10:45.115 --> 1:10:48.410
that's entire diet is Facebook
and social media?

1:10:48.953 --> 1:10:50.871
Democracy crumbled quickly.

1:10:50.955 --> 1:10:51.830
Six months.

1:10:51.914 --> 1:10:53.791
[reporter 1] <i>After that chaos in Chicago,</i>

1:10:53.874 --> 1:10:57.086
<i>violent clashes between protesters</i>
<i>and supporters...</i>

1:10:58.003 --> 1:11:01.632
[reporter 2] <i>Democracy is facing</i>
<i>a crisis of confidence.</i>

1:11:01.715 --> 1:11:04.343
What we're seeing is a global assault
on democracy.

1:11:04.426 --> 1:11:05.427
[crowd shouting]

1:11:05.511 --> 1:11:07.930
[RenÃ©e] Most of the countries
that are targeted are countries

1:11:08.013 --> 1:11:09.723
that run democratic elections.

1:11:10.641 --> 1:11:12.518
[Tristan] This is happening at scale.

1:11:12.601 --> 1:11:15.562
By state actors,
by people with millions of dollars saying,

1:11:15.646 --> 1:11:18.524
"I wanna destabilize Kenya.
I wanna destabilize Cameroon.

1:11:18.607 --> 1:11:20.651
Oh, Angola? That only costs this much."

1:11:20.734 --> 1:11:23.362
[reporter] <i>An extraordinary election</i>
<i>took place Sunday in Brazil.</i>

1:11:23.445 --> 1:11:25.823
With a campaign that's been powered
by social media.

1:11:25.906 --> 1:11:29.702
[crowd chanting in Portuguese]

1:11:31.036 --> 1:11:33.956
[Tristan] We in the tech industry
have created the tools

1:11:34.039 --> 1:11:37.418
to destabilize
and erode the fabric of society

1:11:37.501 --> 1:11:40.254
in every country,Â all at once, everywhere.

1:11:40.337 --> 1:11:44.508
You have this in Germany, Spain, France,
Brazil, Australia.

1:11:44.591 --> 1:11:47.261
Some of the most "developed nations"
in the world

1:11:47.344 --> 1:11:49.221
are now imploding on each other,

1:11:49.305 --> 1:11:50.931
and what do they have in common?

1:11:51.974 --> 1:11:52.975
Knowing what you know now,

1:11:53.058 --> 1:11:56.312
do you believe Facebook impacted
the results of the 2016 election?

1:11:56.770 --> 1:11:58.814
[Mark Zuckerberg]
Oh, that's... that is hard.

1:11:58.897 --> 1:12:00.691
You know,Â it's... the...

1:12:01.275 --> 1:12:04.653
the reality is, well, there
were so many different forces at play.

1:12:04.737 --> 1:12:07.865
Representatives from Facebook, Twitter,
and Google are back on Capitol Hill

1:12:07.948 --> 1:12:09.450
for a second day of testimony

1:12:09.533 --> 1:12:12.578
about Russia's interference
in the 2016 election.

1:12:12.661 --> 1:12:17.291
The manipulation
by third parties is not a hack.

1:12:18.500 --> 1:12:21.462
Right? The Russians didn't hack Facebook.

1:12:21.545 --> 1:12:24.965
What they did was they used the tools
that Facebook created

1:12:25.049 --> 1:12:27.843
for legitimate advertisers
and legitimate users,

1:12:27.926 --> 1:12:30.346
and they applied it
to a nefarious purpose.

1:12:32.014 --> 1:12:34.391
[Tristan]
It's like remote-control warfare.

1:12:34.475 --> 1:12:36.602
One country can manipulate another one

1:12:36.685 --> 1:12:39.229
without actually invading
its physical borders.

1:12:39.605 --> 1:12:42.232
[reporter 1] <i>We're seeing violent images.</i>
<i>It appears to be a dumpster</i>

1:12:42.316 --> 1:12:43.317
<i>being pushed around...</i>

1:12:43.400 --> 1:12:46.028
[Tristan] But it wasn't
about who you wanted to vote for.

1:12:46.362 --> 1:12:50.574
It was about sowing total chaos
and division in society.

1:12:50.657 --> 1:12:53.035
[reporter 2] <i>Now,</i>
<i>this was in Huntington Beach. A march...</i>

1:12:53.118 --> 1:12:54.870
[Tristan] It's about making two sides

1:12:54.953 --> 1:12:56.413
who couldn't hear each other anymore,

1:12:56.497 --> 1:12:58.123
who didn't want to hear each other
anymore,

1:12:58.207 --> 1:12:59.875
who didn't trust each other anymore.

1:12:59.958 --> 1:13:03.212
[reporter 3] <i>This is a city</i>
<i>where hatred was laid bare</i>

1:13:03.295 --> 1:13:05.464
<i>and transformed into racial violence.</i>

1:13:05.547 --> 1:13:07.549
[crowd shouting]

1:13:09.009 --> 1:13:11.178
[indistinct shouting]

1:13:12.471 --> 1:13:14.014
[men grunting]

1:13:17.851 --> 1:13:20.062
[police siren blaring]

1:13:20.145 --> 1:13:20.979
[Cass] Ben!

1:13:21.605 --> 1:13:22.439
Cassandra!

1:13:22.981 --> 1:13:23.816
-Cass!
-Ben!

1:13:23.899 --> 1:13:25.484
[officer 1] Come here! Come here!

1:13:27.486 --> 1:13:31.156
Arms up. Arms up.
Get down on your knees. Now, down.

1:13:31.240 --> 1:13:32.491
[crowd continues shouting]

1:13:36.120 --> 1:13:37.204
-[officer 2] Calm--
-Ben!

1:13:37.287 --> 1:13:38.664
[officer 2] Hey! Hands up!

1:13:39.623 --> 1:13:41.750
Turn around. On the ground.Â On the ground!

1:13:43.710 --> 1:13:46.463
-[crowd echoing]
-[melancholy piano music playing]

1:13:51.969 --> 1:13:54.388
[siren continues wailing]

1:13:56.723 --> 1:14:00.018
[Tristan] Do we want this system for sale
to the highest bidder?

1:14:01.437 --> 1:14:05.399
For democracy to be completely for sale,
where you can reach any mind you want,

1:14:05.482 --> 1:14:09.069
target a lie to that specific population,
and create culture wars?

1:14:09.236 --> 1:14:10.237
Do we want that?

1:14:14.700 --> 1:14:16.577
[Marco Rubio] We are a nation of people...

1:14:16.952 --> 1:14:18.871
that no longer speak to each other.

1:14:19.872 --> 1:14:23.000
We are a nation of people
who have stopped being friends with people

1:14:23.083 --> 1:14:25.461
because of who they voted for
in the last election.

1:14:25.878 --> 1:14:28.422
We are a nation of people
who have isolated ourselves

1:14:28.505 --> 1:14:30.966
to only watch channels
that tell us that we're right.

1:14:32.259 --> 1:14:36.597
My message here today is that tribalism
is ruining us.

1:14:37.347 --> 1:14:39.183
It is tearing our country apart.

1:14:40.267 --> 1:14:42.811
It is no way for sane adults to act.

1:14:43.187 --> 1:14:45.314
If everyone's entitled to their own facts,

1:14:45.397 --> 1:14:49.401
there's really no need for compromise,
no need for people to come together.

1:14:49.485 --> 1:14:51.695
In fact, there's really no need
for people to interact.

1:14:52.321 --> 1:14:53.530
We need to have...

1:14:53.989 --> 1:14:58.410
some shared understanding of reality.
Otherwise, we aren't a country.

1:14:58.952 --> 1:15:02.998
So, uh, long-term, the solution here is
to build more AI tools

1:15:03.081 --> 1:15:08.128
that find patterns of people using
the services that no real person would do.

1:15:08.212 --> 1:15:11.840
We are allowing the technologists
to frame this as a problem

1:15:11.924 --> 1:15:13.884
that they're equipped to solve.

1:15:15.135 --> 1:15:16.470
That is... That's a lie.

1:15:17.679 --> 1:15:20.724
People talk about AI
as if it will know truth.

1:15:21.683 --> 1:15:23.685
AI's not gonna solve these problems.

1:15:24.269 --> 1:15:27.189
AI cannot solve the problem of fake news.

1:15:28.649 --> 1:15:31.026
Google doesn't have the option of saying,

1:15:31.109 --> 1:15:36.240
"Oh, is this conspiracy? Is this truth?"
Because they don't know what truth is.

1:15:36.782 --> 1:15:37.783
They don't have a...

1:15:37.908 --> 1:15:40.827
They don't have a proxy for truth
that's better than a click.

1:15:41.870 --> 1:15:45.123
If we don't agree on what is true

1:15:45.207 --> 1:15:47.584
or that there is such a thing as truth,

1:15:48.293 --> 1:15:49.294
we're toast.

1:15:49.753 --> 1:15:52.089
This is the problem
beneath other problems

1:15:52.172 --> 1:15:54.424
because if we can't agree on what's true,

1:15:55.092 --> 1:15:57.803
then we can't navigate
out of any of our problems.

1:15:57.886 --> 1:16:00.806
-[ominous instrumental music playing]
-[console droning]

1:16:05.435 --> 1:16:07.729
[Growth AI] We should suggest
Flat Earth Football Club.

1:16:07.813 --> 1:16:10.566
[Engagement AI] Don't show him
sports updates. He doesn't engage.

1:16:11.483 --> 1:16:14.027
[AIs speaking indistinctly]

1:16:15.696 --> 1:16:17.698
[music swells]

1:16:39.886 --> 1:16:42.764
[Jaron] A lot of people in Silicon Valley
subscribe to some kind of theory

1:16:42.848 --> 1:16:45.142
that we're building
some global super brain,

1:16:45.309 --> 1:16:48.020
and all of our users
are just interchangeable little neurons,

1:16:48.103 --> 1:16:49.563
no one of which is important.

1:16:50.230 --> 1:16:53.150
And it subjugates people
into this weird role

1:16:53.233 --> 1:16:56.069
where you're just, like,
this little computing element

1:16:56.153 --> 1:16:58.905
that we're programming
through our behavior manipulation

1:16:58.989 --> 1:17:02.367
for the service of this giant brain,
and you don't matter.

1:17:02.451 --> 1:17:04.911
You're not gonna get paid.
You're not gonna get acknowledged.

1:17:04.995 --> 1:17:06.455
You don't have self-determination.

1:17:06.538 --> 1:17:09.416
We'll sneakily just manipulate you
because you're a computing node,

1:17:09.499 --> 1:17:12.336
so we need to program youÂ 'cause that's
what you do with computing nodes.

1:17:14.504 --> 1:17:16.506
[reflective instrumental music playing]

1:17:20.093 --> 1:17:21.845
Oh, man. [sighs]

1:17:21.928 --> 1:17:25.390
[Tristan] When you think about technology
and it being an existential threat,

1:17:25.474 --> 1:17:28.060
you know, that's a big claim, and...

1:17:29.603 --> 1:17:33.982
it's easy to then, in your mind, think,
"Okay, so, there I am with the phone...

1:17:35.609 --> 1:17:37.235
scrolling, clicking, using it.

1:17:37.319 --> 1:17:39.196
Like, where's the existential threat?

1:17:40.280 --> 1:17:41.615
Okay, there's the supercomputer.

1:17:41.698 --> 1:17:43.950
The other side of the screen,
pointed at my brain,

1:17:44.409 --> 1:17:47.537
got me to watch one more video.
Where's the existential threat?"

1:17:47.621 --> 1:17:49.623
[indistinct chatter]

1:17:54.252 --> 1:17:57.631
[Tristan] It's not
about the technology

1:17:57.714 --> 1:17:59.341
being the existential threat.

1:18:03.679 --> 1:18:06.264
It's the technology's ability

1:18:06.348 --> 1:18:09.476
to bring out the worst in society...
[chuckles]

1:18:09.559 --> 1:18:13.522
...and the worst in society
being the existential threat.

1:18:18.819 --> 1:18:20.570
If technology creates...

1:18:21.697 --> 1:18:23.115
mass chaos,

1:18:23.198 --> 1:18:24.533
outrage, incivility,

1:18:24.616 --> 1:18:26.326
lack of trust in each other,

1:18:27.452 --> 1:18:30.414
loneliness, alienation, more polarization,

1:18:30.706 --> 1:18:33.333
more election hacking, more populism,

1:18:33.917 --> 1:18:36.962
more distraction and inability
to focus on the real issues...

1:18:37.963 --> 1:18:39.715
that's just society. [scoffs]

1:18:40.340 --> 1:18:46.388
And now society
is incapable of healing itself

1:18:46.471 --> 1:18:48.515
and just devolving into a kind of chaos.

1:18:51.977 --> 1:18:54.938
This affects everyone,
even if you don't use these products.

1:18:55.397 --> 1:18:57.524
These things have become
digital Frankensteins

1:18:57.607 --> 1:19:00.068
that areÂ terraforming the world
in their image,

1:19:00.152 --> 1:19:01.862
whether it's the mental health of children

1:19:01.945 --> 1:19:04.489
or our politics
and our political discourse,

1:19:04.573 --> 1:19:07.492
without taking responsibility
for taking over the public square.

1:19:07.576 --> 1:19:10.579
-So, again, it comes back to--
-And who do you think's responsible?

1:19:10.662 --> 1:19:13.582
I think we have
to have the platforms be responsible

1:19:13.665 --> 1:19:15.584
for when they take over
election advertising,

1:19:15.667 --> 1:19:17.794
they're responsible
for protecting elections.

1:19:17.878 --> 1:19:20.380
When they take over mental health of kids
or Saturday morning,

1:19:20.464 --> 1:19:22.841
they're responsible
for protecting Saturday morning.

1:19:23.592 --> 1:19:27.929
The race to keep people's attention
isn't going away.

1:19:28.388 --> 1:19:31.850
Our technology's gonna become
more integrated into our lives, not less.

1:19:31.933 --> 1:19:34.895
The AIs are gonna get better at predicting
what keeps us on the screen,

1:19:34.978 --> 1:19:37.105
not worse at predicting
what keeps us on the screen.

1:19:38.940 --> 1:19:42.027
I... I am 62 years old,

1:19:42.110 --> 1:19:44.821
getting older every minute,
the more this conversation goes on...

1:19:44.905 --> 1:19:48.033
-[crowd chuckles]
-...but... but I will tell you that, um...

1:19:48.700 --> 1:19:52.370
I'm probably gonna be dead and gone,
and I'll probably be thankful for it,

1:19:52.454 --> 1:19:54.331
when all this shit comes to fruition.

1:19:54.790 --> 1:19:59.586
Because... Because I think
that this scares me to death.

1:20:00.754 --> 1:20:03.048
Do... Do you...
Do you see it the same way?

1:20:03.548 --> 1:20:06.885
Or am I overreacting to a situation
that I don't know enough about?

1:20:09.805 --> 1:20:11.598
[interviewer]
What are you most worried about?

1:20:13.850 --> 1:20:18.480
[sighs] I think,
in the... in the shortest time horizon...

1:20:19.523 --> 1:20:20.524
civil war.

1:20:24.444 --> 1:20:29.908
If we go down the current status quo
for, let's say, another 20 years...

1:20:31.117 --> 1:20:34.579
we probably destroy our civilization
through willful ignorance.

1:20:34.663 --> 1:20:37.958
We probably fail to meet the challenge
of climate change.

1:20:38.041 --> 1:20:42.087
We probably degrade
the world's democracies

1:20:42.170 --> 1:20:46.132
so that they fall into some sort
of bizarre autocratic dysfunction.

1:20:46.216 --> 1:20:48.426
We probably ruin the global economy.

1:20:48.760 --> 1:20:52.264
Uh, we probably, um, don't survive.

1:20:52.347 --> 1:20:54.808
You know,
I... I really do view it as existential.

1:20:54.891 --> 1:20:56.893
[helicopter blades whirring]

1:21:02.524 --> 1:21:04.985
[Tristan]
Is this the last generation of people

1:21:05.068 --> 1:21:08.488
that are gonna know what it was like
before this illusion took place?

1:21:11.074 --> 1:21:14.578
Like, how do you wake up from the matrix
when you don't know you're in the matrix?

1:21:14.661 --> 1:21:16.538
[ominous instrumental music playing]

1:21:27.382 --> 1:21:30.635
[Tristan] A lot of what we're saying
sounds like it's just this...

1:21:31.511 --> 1:21:33.680
one-sided doom and gloom.

1:21:33.763 --> 1:21:36.808
Like, "Oh, my God,
technology's just ruining the world

1:21:36.892 --> 1:21:38.059
and it's ruining kids,"

1:21:38.143 --> 1:21:40.061
and it's like... "No." [chuckles]

1:21:40.228 --> 1:21:44.065
It's confusing
because it's simultaneous utopia...

1:21:44.608 --> 1:21:45.567
and dystopia.

1:21:45.942 --> 1:21:50.447
Like, I could hit a button on my phone,
and a car shows up in 30 seconds,

1:21:50.530 --> 1:21:52.699
and I can go exactly where I need to go.

1:21:52.782 --> 1:21:55.660
That is magic. That's amazing.

1:21:56.161 --> 1:21:57.662
When we were making the like button,

1:21:57.746 --> 1:22:01.499
our entire motivation was, "Can we spread
positivity and love in the world?"

1:22:01.583 --> 1:22:05.003
The idea that, fast-forward to today,
and teens would be getting depressed

1:22:05.086 --> 1:22:06.421
when they don't have enough likes,

1:22:06.504 --> 1:22:08.632
or it could be leading
to political polarization

1:22:08.715 --> 1:22:09.883
was nowhere on our radar.

1:22:09.966 --> 1:22:12.135
I don't think these guys set out
to be evil.

1:22:13.511 --> 1:22:15.764
It's just the business model
that has a problem.

1:22:15.847 --> 1:22:20.226
You could shut down the service
and destroy whatever it is--

1:22:20.310 --> 1:22:24.522
$20 billion of shareholder value--
and get sued and...

1:22:24.606 --> 1:22:27.108
But you can't, in practice,
put the genie back in the bottle.

1:22:27.192 --> 1:22:30.403
You can make some tweaks,
but at the end of the day,

1:22:30.487 --> 1:22:34.032
you've gotta grow revenue and usage,
quarter over quarter. It's...

1:22:34.658 --> 1:22:37.535
The bigger it gets,
the harder it is for anyone to change.

1:22:38.495 --> 1:22:43.458
What I see is a bunch of people
who are trapped by a business model,

1:22:43.541 --> 1:22:46.169
an economic incentive,
and shareholder pressure

1:22:46.252 --> 1:22:48.922
that makes it almost impossible
to do something else.

1:22:49.005 --> 1:22:50.924
I think we need to accept that it's okay

1:22:51.007 --> 1:22:53.176
for companies to be focused
on making money.

1:22:53.259 --> 1:22:55.637
What's not okay
is when there's no regulation, no rules,

1:22:55.720 --> 1:22:56.888
and no competition,

1:22:56.972 --> 1:23:00.850
and the companies are acting
as sort ofÂ de facto governments.

1:23:00.934 --> 1:23:03.353
And then they're saying,
"Well, we can regulate ourselves."

1:23:03.436 --> 1:23:05.981
I mean, that's just a lie.
That's just ridiculous.

1:23:06.064 --> 1:23:08.650
Financial incentives kind of run
the world,

1:23:08.733 --> 1:23:12.529
so any solution to this problem

1:23:12.612 --> 1:23:15.573
has to realign the financial incentives.

1:23:16.074 --> 1:23:18.785
There's no fiscal reason
for these companies to change.

1:23:18.868 --> 1:23:21.329
And that is why I think
we need regulation.

1:23:21.413 --> 1:23:24.290
The phone company
has tons of sensitive data about you,

1:23:24.374 --> 1:23:27.544
and we have a lot of laws that make sure
they don't do the wrong things.

1:23:27.627 --> 1:23:31.506
We have almost no laws
around digital privacy, for example.

1:23:31.589 --> 1:23:34.426
We could tax data collection
and processing

1:23:34.509 --> 1:23:37.554
the same way that you, for example,
pay your water bill

1:23:37.637 --> 1:23:39.723
by monitoring the amount of water
that you use.

1:23:39.806 --> 1:23:43.226
You tax these companies on the data assets
that they have.

1:23:43.309 --> 1:23:44.769
It gives them a fiscal reason

1:23:44.853 --> 1:23:47.856
to not acquire every piece of data
on the planet.

1:23:47.939 --> 1:23:50.567
The law runs way behind on these things,

1:23:50.650 --> 1:23:55.864
but what I know is the current situation
exists not for the protection of users,

1:23:55.947 --> 1:23:58.700
but for the protection
of the rights and privileges

1:23:58.783 --> 1:24:01.453
of these gigantic,
incredibly wealthy companies.

1:24:02.245 --> 1:24:05.832
Are we always gonna defer to the richest,
most powerful people?

1:24:05.915 --> 1:24:07.417
Or are we ever gonna say,

1:24:07.959 --> 1:24:12.047
"You know, there are times
when there is a national interest.

1:24:12.130 --> 1:24:15.592
There are times
when the interests of people, of users,

1:24:15.675 --> 1:24:17.385
is actually more important

1:24:18.011 --> 1:24:21.473
than the profits of somebody
who's already a billionaire"?

1:24:21.556 --> 1:24:26.603
These markets undermine democracy,
and they undermine freedom,

1:24:26.686 --> 1:24:28.521
and they should be outlawed.

1:24:29.147 --> 1:24:31.816
This is not a radical proposal.

1:24:31.900 --> 1:24:34.194
There are other markets that we outlaw.

1:24:34.277 --> 1:24:36.988
We outlaw markets in human organs.

1:24:37.072 --> 1:24:39.491
We outlaw markets in human slaves.

1:24:39.949 --> 1:24:44.037
Because they have
inevitable destructive consequences.

1:24:44.537 --> 1:24:45.830
We live in a world

1:24:45.914 --> 1:24:50.001
in which a tree is worth more,
financially, dead than alive,

1:24:50.085 --> 1:24:53.838
in a world in which a whale
is worth more dead than alive.

1:24:53.922 --> 1:24:56.341
For so long as our economy works
in that way

1:24:56.424 --> 1:24:58.134
and corporations go unregulated,

1:24:58.218 --> 1:25:00.678
they're going to continue
to destroy trees,

1:25:00.762 --> 1:25:01.763
to kill whales,

1:25:01.846 --> 1:25:06.101
to mine the earth, and to continue
to pull oil out of the ground,

1:25:06.184 --> 1:25:08.394
even though we know
it is destroying the planet

1:25:08.478 --> 1:25:12.148
and we know that it's going to leave
a worse world for future generations.

1:25:12.232 --> 1:25:13.858
This is short-term thinking

1:25:13.942 --> 1:25:16.694
based on this religion of profit
at all costs,

1:25:16.778 --> 1:25:20.156
as if somehow, magically, each corporation
acting in its selfish interest

1:25:20.240 --> 1:25:21.950
is going to produce the best result.

1:25:22.033 --> 1:25:24.494
This has been affecting the environment
for a long time.

1:25:24.577 --> 1:25:27.288
What's frightening,
and what hopefully is the last straw

1:25:27.372 --> 1:25:29.207
that will make us wake up
as a civilization

1:25:29.290 --> 1:25:31.709
to how flawed this theory has been
in the first place

1:25:31.793 --> 1:25:35.004
is to see that now we're the tree,
we're the whale.

1:25:35.088 --> 1:25:37.048
Our attention can be mined.

1:25:37.132 --> 1:25:39.134
We are more profitable to a corporation

1:25:39.217 --> 1:25:41.594
if we're spending time
staring at a screen,

1:25:41.678 --> 1:25:42.971
staring at an ad,

1:25:43.054 --> 1:25:45.890
than if we're spending that time
living our life in a rich way.

1:25:45.974 --> 1:25:47.559
And so, we're seeing the results of that.

1:25:47.642 --> 1:25:50.687
We're seeing corporations using
powerful artificial intelligence

1:25:50.770 --> 1:25:53.648
to outsmart us and figure out
how to pull our attention

1:25:53.731 --> 1:25:55.358
toward the things they want us to look at,

1:25:55.441 --> 1:25:57.277
rather than the things
that are most consistent

1:25:57.360 --> 1:25:59.237
with our goals and our values
and our lives.

1:25:59.320 --> 1:26:01.322
[static crackles]

1:26:02.991 --> 1:26:04.450
[crowd cheering]

1:26:05.535 --> 1:26:06.911
[Steve Jobs] What a computer is,

1:26:06.995 --> 1:26:10.290
is it's the most remarkable tool
that we've ever come up with.

1:26:11.124 --> 1:26:13.877
And it's the equivalent of a bicycle
for our minds.

1:26:15.628 --> 1:26:20.091
The idea of humane technology,
that's where Silicon Valley got its start.

1:26:21.050 --> 1:26:25.722
And we've lost sight of it
because it became the cool thing to do,

1:26:25.805 --> 1:26:27.265
as opposed to the right thing to do.

1:26:27.348 --> 1:26:29.726
The Internet was, like,
a weird, wacky place.

1:26:29.809 --> 1:26:31.394
It was experimental.

1:26:31.477 --> 1:26:34.731
Creative things happened on the Internet,
and certainly, they do still,

1:26:34.814 --> 1:26:38.610
but, like, it just feels like this,
like, giant mall. [chuckles]

1:26:38.693 --> 1:26:42.071
You know, it's just like, "God,
there's gotta be...

1:26:42.155 --> 1:26:44.157
there's gotta be more to it than that."

1:26:44.991 --> 1:26:45.992
[man typing]

1:26:46.659 --> 1:26:48.411
[Bailey] I guess I'm just an optimist.

1:26:48.494 --> 1:26:52.040
'Cause I think we can change
what social media looks like and means.

1:26:54.083 --> 1:26:56.711
[Justin] The way the technology works
is not a law of physics.

1:26:56.794 --> 1:26:57.921
It is not set in stone.

1:26:58.004 --> 1:27:02.175
These are choices that human beings
like myself have been making.

1:27:02.759 --> 1:27:05.345
And human beings can change
those technologies.

1:27:06.971 --> 1:27:09.974
[Tristan] And the question now is
whether or not we're willing to admit

1:27:10.475 --> 1:27:15.438
that those bad outcomes are coming
directly as a product of our work.

1:27:21.027 --> 1:27:24.864
It's that we built these things,
and we have a responsibility to change it.

1:27:28.409 --> 1:27:30.411
[static crackling]

1:27:37.085 --> 1:27:38.711
[Tristan] The attention extraction model

1:27:38.795 --> 1:27:42.298
is not how we want to treat
human beings.

1:27:45.343 --> 1:27:48.137
[distorted] Is it just me or...

1:27:49.722 --> 1:27:51.099
[distorted] Poor sucker.

1:27:51.516 --> 1:27:53.226
[Tristan] The fabric of a healthy society

1:27:53.309 --> 1:27:56.145
depends on us getting off
this corrosive business model.

1:27:56.938 --> 1:27:58.064
[console beeps]

1:27:58.147 --> 1:28:00.149
[gentle instrumental music playing]

1:28:01.526 --> 1:28:04.612
[console whirs, grows quiet]

1:28:04.696 --> 1:28:08.157
[Tristan] We can demand
that these products be designed humanely.

1:28:09.409 --> 1:28:13.121
We can demand to not be treated
as an extractable resource.

1:28:15.164 --> 1:28:18.334
The intention could be:
"How do we make the world better?"

1:28:20.336 --> 1:28:21.504
[Jaron] Throughout history,

1:28:21.587 --> 1:28:23.798
every single time
something's gotten better,

1:28:23.881 --> 1:28:26.342
it's because somebody has come along
to say,

1:28:26.426 --> 1:28:28.428
"This is stupid. We can do better."
[laughs]

1:28:29.178 --> 1:28:32.557
Like, it's the critics
that drive improvement.

1:28:33.141 --> 1:28:35.393
It's the critics
who are the true optimists.

1:28:37.020 --> 1:28:39.147
[sighs] Hello.

1:28:42.984 --> 1:28:44.277
[sighs] Um...

1:28:46.195 --> 1:28:47.697
I mean, it seems kind of crazy, right?

1:28:47.780 --> 1:28:51.534
It's like the fundamental way
that this stuff is designed...

1:28:52.994 --> 1:28:55.163
isn't going in a good direction.
[chuckles]

1:28:55.246 --> 1:28:56.873
Like, the entire thing.

1:28:56.956 --> 1:29:00.626
So, it sounds crazy to say
we need to change all that,

1:29:01.169 --> 1:29:02.670
but that's what we need to do.

1:29:04.297 --> 1:29:05.923
[interviewer] Think we're gonna get there?

1:29:07.383 --> 1:29:08.301
We have to.

1:29:14.515 --> 1:29:16.476
[tense instrumental music playing]

1:29:20.646 --> 1:29:24.942
[interviewer] Um,
it seems like you're very optimistic.

1:29:26.194 --> 1:29:27.570
-Is that how I sound?
-[crew laughs]

1:29:27.653 --> 1:29:28.905
[interviewer] Yeah, I mean...

1:29:28.988 --> 1:29:31.449
I can't believe you keep saying that,
because I'm like, "Really?

1:29:31.532 --> 1:29:33.409
I feel like we're headed toward dystopia.

1:29:33.493 --> 1:29:35.328
I feel like we're on the fast track
to dystopia,

1:29:35.411 --> 1:29:37.830
and it's gonna take a miracle
to get us out of it."

1:29:37.914 --> 1:29:40.291
And that miracle is, of course,
collective will.

1:29:41.000 --> 1:29:44.587
I am optimistic
that we're going to figure it out,

1:29:44.670 --> 1:29:47.048
but I think it's gonna take a long time.

1:29:47.131 --> 1:29:50.385
Because not everybody recognizes
that this is a problem.

1:29:50.468 --> 1:29:55.890
I think one of the big failures
in technology today

1:29:55.973 --> 1:29:58.643
is a real failure of leadership,

1:29:58.726 --> 1:30:01.979
of, like, people coming out
and having these open conversations

1:30:02.063 --> 1:30:05.900
about things that... not just
what went well, but what isn't perfect

1:30:05.983 --> 1:30:08.194
so that someone can come in
and build something new.

1:30:08.277 --> 1:30:10.321
At the end of the day, you know,

1:30:10.405 --> 1:30:14.617
this machine isn't gonna turn around
until there's massive public pressure.

1:30:14.700 --> 1:30:18.329
By having these conversations
and... and voicing your opinion,

1:30:18.413 --> 1:30:21.082
in some cases
through these very technologies,

1:30:21.165 --> 1:30:24.252
we can start to change the tide.
We can start to change the conversation.

1:30:24.335 --> 1:30:27.004
It might sound strange,
but it's my world. It's my community.

1:30:27.088 --> 1:30:29.632
I don't hate them. I don't wanna do
any harm to Google or Facebook.

1:30:29.715 --> 1:30:32.885
I just want to reform them
so they don't destroy the world. You know?

1:30:32.969 --> 1:30:35.513
I've uninstalled a ton of apps
from my phone

1:30:35.596 --> 1:30:37.723
that I felt were just wasting my time.

1:30:37.807 --> 1:30:40.685
All the social media apps,
all the news apps,

1:30:40.768 --> 1:30:42.520
and I've turned off notifications

1:30:42.603 --> 1:30:45.815
on anything that was vibrating my leg
with information

1:30:45.898 --> 1:30:48.943
that wasn't timely and important to me
right now.

1:30:49.026 --> 1:30:51.279
It's for the same reason
I don't keep cookies in my pocket.

1:30:51.362 --> 1:30:53.197
Reduce the number of notifications
you get.

1:30:53.281 --> 1:30:54.449
Turn off notifications.

1:30:54.532 --> 1:30:55.950
Turning off all notifications.

1:30:56.033 --> 1:30:58.536
I'm not using Google anymore,
I'm using Qwant,

1:30:58.619 --> 1:31:01.497
which doesn't store your search history.

1:31:01.581 --> 1:31:04.459
Never accept a video recommended to you
on YouTube.

1:31:04.542 --> 1:31:07.003
Always choose.
That's another way to fight.

1:31:07.086 --> 1:31:12.133
There are tons of Chrome extensions
that remove recommendations.

1:31:12.216 --> 1:31:15.178
[interviewer] You're recommending
something to undo what you made.

1:31:15.261 --> 1:31:16.554
[laughing] Yep.

1:31:16.929 --> 1:31:21.642
Before you share, fact-check,
consider the source, do that extra Google.

1:31:21.726 --> 1:31:25.104
If it seems like it's something designed
to really push your emotional buttons,

1:31:25.188 --> 1:31:26.314
like, it probably is.

1:31:26.397 --> 1:31:29.025
Essentially, you vote with your clicks.

1:31:29.108 --> 1:31:30.359
If you click on clickbait,

1:31:30.443 --> 1:31:33.779
you're creating a financial incentive
that perpetuates this existing system.

1:31:33.863 --> 1:31:36.949
Make sure that you get
lots of different kinds of information

1:31:37.033 --> 1:31:37.909
in your own life.

1:31:37.992 --> 1:31:40.995
I follow people on Twitter
that I disagree with

1:31:41.078 --> 1:31:44.207
because I want to be exposed
to different points of view.

1:31:44.665 --> 1:31:46.584
Notice that many people
in the tech industry

1:31:46.667 --> 1:31:49.045
don't give these devices
to their own children.

1:31:49.128 --> 1:31:51.047
My kids don't use social media at all.

1:31:51.839 --> 1:31:53.549
[interviewer] Is that a rule,
or is that a...

1:31:53.633 --> 1:31:54.509
That's a rule.

1:31:55.092 --> 1:31:57.845
We are zealots about it.

1:31:57.929 --> 1:31:59.222
We're... We're crazy.

1:31:59.305 --> 1:32:05.603
And we don't let our kids have
really any screen time.

1:32:05.686 --> 1:32:08.564
I've worked out
what I think are three simple rules, um,

1:32:08.648 --> 1:32:12.610
that make life a lot easier for families
and that are justified by the research.

1:32:12.693 --> 1:32:15.571
So, the first rule is
all devices out of the bedroom

1:32:15.655 --> 1:32:17.281
at a fixed time every night.

1:32:17.365 --> 1:32:20.535
Whatever the time is, half an hour
before bedtime, all devices out.

1:32:20.618 --> 1:32:24.038
The second rule is no social media
until high school.

1:32:24.121 --> 1:32:26.374
Personally, I think the age should be 16.

1:32:26.457 --> 1:32:28.960
Middle school's hard enough.
Keep it out until high school.

1:32:29.043 --> 1:32:32.964
And the third rule is
work out a time budget with your kid.

1:32:33.047 --> 1:32:34.757
And if you talk with them and say,

1:32:34.840 --> 1:32:37.927
"Well, how many hours a day
do you wanna spend on your device?

1:32:38.010 --> 1:32:39.637
What do you think is a good amount?"

1:32:39.720 --> 1:32:41.597
they'll often say
something pretty reasonable.

1:32:42.056 --> 1:32:44.642
Well, look, I know perfectly well

1:32:44.725 --> 1:32:48.563
that I'm not gonna get everybody
to delete their social media accounts,

1:32:48.646 --> 1:32:50.439
but I think I can get a few.

1:32:50.523 --> 1:32:54.402
And just getting a few people
to delete their accounts matters a lot,

1:32:54.485 --> 1:32:58.406
and the reason why is that that creates
the space for a conversation

1:32:58.489 --> 1:33:00.908
because I want there to be enough people
out in the society

1:33:00.992 --> 1:33:05.204
who are free of the manipulation engines
to have a societal conversation

1:33:05.288 --> 1:33:07.540
that isn't bounded
by the manipulation engines.

1:33:07.623 --> 1:33:10.126
So, do it! Get out of the system.

1:33:10.209 --> 1:33:12.503
Yeah, delete. Get off the stupid stuff.

1:33:13.546 --> 1:33:16.507
The world's beautiful.
Look. Look, it's great out there.

1:33:17.258 --> 1:33:18.384
[laughs]

1:33:21.971 --> 1:33:24.432
-[birds singing]
-[children playing and shouting]
